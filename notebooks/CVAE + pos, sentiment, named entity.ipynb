{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "from keras.layers import Input, Dense, Lambda\n",
    "from keras.layers.merge import concatenate as concat\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### original embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_original_embeddings(file_name):\n",
    "    txt = open(file_name,\"r\") .read().split('\\n')\n",
    "    txt.pop(15000) # remove the last empty object\n",
    "\n",
    "    tokens = []\n",
    "    embeddings = []\n",
    "\n",
    "    for i, line in enumerate(txt):\n",
    "        tk = line.strip().split()\n",
    "        tokens.append(tk[0])\n",
    "        embeddings.append([float(i) for i in tk[1:]])\n",
    "\n",
    "    embeddings = np.array(embeddings)\n",
    "    tokens = np.array(tokens)\n",
    "    return embeddings, tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_embeddings, w2v_tokens = get_original_embeddings(\"../data/external/word2vec_original_15k_300d_train.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glove_embeddings, glove_tokens = get_original_embeddings(\"../data/external/glove_original_15k_300d_train.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spine_w2v_embeddings, spine_w2v_tokens = get_original_embeddings(\"../data/external/SPINE_word2vec.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spine_glove_embeddings, spine_glove_tokens = get_original_embeddings(\"../data/external/SPINE_glove.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_size = int(15000 * .8)\n",
    "test_size = int(15000 - train_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### shuffle indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(33)\n",
    "\n",
    "def shuffle_indices(cond_embeddings, cond_tokens, og_embeddings, og_tokens, train_size):\n",
    "    # Train index\n",
    "    train_inx = np.random.choice(list(range(cond_embeddings.shape[0])), size=train_size, replace=False)\n",
    "    train_word_embed = cond_embeddings[train_inx, ]\n",
    "    train_word_token = cond_tokens[train_inx]\n",
    "\n",
    "    # Test index\n",
    "    test_inx = list(set(np.arange(cond_embeddings.shape[0])) - set(train_inx))\n",
    "    test_word_embed = cond_embeddings[test_inx, ]\n",
    "    test_word_token = cond_tokens[test_inx]\n",
    "\n",
    "    ## Train word2vec original\n",
    "    train_w2v_embed = og_embeddings[train_inx, ]\n",
    "    train_w2v_token = og_tokens[train_inx]\n",
    "    \n",
    "    ## Test word2vec original\n",
    "    test_w2v_embed = og_embeddings[test_inx, ]\n",
    "    test_w2v_token = og_tokens[test_inx]\n",
    "    return train_inx, test_inx, train_word_embed, train_word_token, test_word_embed, test_word_token, train_w2v_embed, train_w2v_token, test_w2v_embed, test_w2v_token "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_conditional_train_test(train_word_token, test_word_token, wordnet_conditioning, wordnet_cond_label):\n",
    "    # train set\n",
    "    train_wordnet_cond_matrix = []\n",
    "    for word in train_word_token:\n",
    "        if word in wordnet_conditioning:\n",
    "            train_wordnet_cond_matrix.append(wordnet_conditioning[word])\n",
    "        else:\n",
    "            train_wordnet_cond_matrix.append([0]*len(wordnet_cond_label))\n",
    "    train_wordnet_cond_matrix = np.array(train_wordnet_cond_matrix)\n",
    "    \n",
    "    train_wordnet_cond_matrix_df = pd.DataFrame(train_wordnet_cond_matrix)\n",
    "    train_wordnet_cond_matrix_df.columns = wordnet_cond_label\n",
    "    train_wordnet_cond_matrix_df.index = train_word_token\n",
    "\n",
    "    # test set\n",
    "    test_wordnet_cond_matrix = []\n",
    "    for word in test_word_token:\n",
    "        if word in wordnet_conditioning:\n",
    "            test_wordnet_cond_matrix.append(wordnet_conditioning[word])\n",
    "        else:\n",
    "            test_wordnet_cond_matrix.append([0]*len(wordnet_cond_label))\n",
    "    test_wordnet_cond_matrix = np.array(test_wordnet_cond_matrix)\n",
    "\n",
    "    test_wordnet_cond_matrix_df = pd.DataFrame(test_wordnet_cond_matrix)\n",
    "    test_wordnet_cond_matrix_df.columns = wordnet_cond_label\n",
    "    test_wordnet_cond_matrix_df.index = test_word_token\n",
    "    return train_wordnet_cond_matrix_df, test_wordnet_cond_matrix_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -> word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# spine_w2v_train_inx, spine_w2v_test_inx, \n",
    "#     train_word_embed,e train_word_token, \n",
    "#     test_word_embed, test_word_token, \n",
    "#     train_w2v_embed, train_w2v_token, \n",
    "#     test_w2v_embed, test_w2v_token =  shuffle_indices(\n",
    "#                                             spine_w2v_embeddings, \n",
    "#                                             spine_w2v_tokens, \n",
    "#                                             w2v_embeddings, \n",
    "#                                             w2v_tokens,\n",
    "#                                             train_size\n",
    "#                                         )\n",
    "spine_w2v_train_inx, spine_w2v_test_inx, train_word_embed, train_word_token, test_word_embed, test_word_token, train_w2v_embed, train_w2v_token,test_w2v_embed, test_w2v_token =  shuffle_indices(spine_w2v_embeddings, spine_w2v_tokens, w2v_embeddings, w2v_tokens, train_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -> glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spine_glove_train_inx, spine_glove_test_inx, sg_train_word_embed, sg_train_word_token, sg_test_word_embed, sg_test_word_token, train_glove_embed, train_glove_token, test_glove_embed, test_glove_token =  shuffle_indices(spine_glove_embeddings, spine_glove_tokens, glove_embeddings, glove_tokens, train_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WordNet Domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordnet_conditioning = pickle.load(open(\"../data/raw/one-hot-categories-spine-word2vec.p\", \"rb\" ) )\n",
    "wordnet_cond_label = pickle.load(open(\"../data/raw/category_labels.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_train_wordnet_cond_matrix_df, w2v_test_wordnet_cond_matrix_df = create_conditional_train_test(train_word_token, test_word_token, wordnet_conditioning, wordnet_cond_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acoustics</th>\n",
       "      <th>administration</th>\n",
       "      <th>agriculture</th>\n",
       "      <th>anatomy</th>\n",
       "      <th>animal_husbandry</th>\n",
       "      <th>animals</th>\n",
       "      <th>anthropology</th>\n",
       "      <th>applied_science</th>\n",
       "      <th>archaeology</th>\n",
       "      <th>archery</th>\n",
       "      <th>...</th>\n",
       "      <th>time_period</th>\n",
       "      <th>topography</th>\n",
       "      <th>tourism</th>\n",
       "      <th>town_planning</th>\n",
       "      <th>transport</th>\n",
       "      <th>university</th>\n",
       "      <th>vehicles</th>\n",
       "      <th>veterinary</th>\n",
       "      <th>volleyball</th>\n",
       "      <th>wrestling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>framework</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dancing</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>needy</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>algae</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missions</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 169 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           acoustics  administration  agriculture  anatomy  animal_husbandry  \\\n",
       "framework          0               0            0        0                 0   \n",
       "dancing            0               0            0        0                 0   \n",
       "needy              0               0            0        0                 0   \n",
       "algae              0               0            0        0                 0   \n",
       "missions           0               0            0        0                 0   \n",
       "\n",
       "           animals  anthropology  applied_science  archaeology  archery  \\\n",
       "framework        0             0                0            0        0   \n",
       "dancing          0             0                0            0        0   \n",
       "needy            0             0                0            0        0   \n",
       "algae            0             0                0            0        0   \n",
       "missions         0             0                0            0        0   \n",
       "\n",
       "             ...      time_period  topography  tourism  town_planning  \\\n",
       "framework    ...                0           0        0              0   \n",
       "dancing      ...                0           0        0              0   \n",
       "needy        ...                0           0        0              0   \n",
       "algae        ...                0           0        0              0   \n",
       "missions     ...                0           0        0              0   \n",
       "\n",
       "           transport  university  vehicles  veterinary  volleyball  wrestling  \n",
       "framework          0           0         0           0           0          0  \n",
       "dancing            0           0         0           0           0          0  \n",
       "needy              0           0         0           0           0          0  \n",
       "algae              0           0         0           0           0          0  \n",
       "missions           0           0         0           0           0          0  \n",
       "\n",
       "[5 rows x 169 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_train_wordnet_cond_matrix_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_train_wordnet_cond_matrix_df, glove_test_wordnet_cond_matrix_df = create_conditional_train_test(sg_train_word_token, sg_test_word_token, wordnet_conditioning, wordnet_cond_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part of Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos = pickle.load(open( \"../data/raw/one-hot-pos.p\", \"rb\" ) )\n",
    "pos_labels = pickle.load(open( \"../data/raw/one-hot-pos_labels.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_train_pos_cond_matrix_df, w2v_test_pos_cond_matrix_df = create_conditional_train_test(train_word_token, test_word_token, pos, pos_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glove_train_pos_cond_matrix_df, glove_test_pos_cond_matrix_df = create_conditional_train_test(sg_train_word_token, sg_test_word_token, pos, pos_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentiment = pickle.load(open( \"../data/raw/one-hot-sentiments.p\", \"rb\" ) )\n",
    "sentiment_labels = pickle.load(open( \"../data/raw/one-hot-sentiments_labels.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_train_sentiment_cond_matrix_df, w2v_test_sentiment_cond_matrix_df = create_conditional_train_test(train_word_token, test_word_token, sentiment, sentiment_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glove_train_sentiment_cond_matrix_df, glove_test_sentiment_cond_matrix_df = create_conditional_train_test(sg_train_word_token, sg_test_word_token, sentiment, sentiment_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Named Entity Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "entities = pickle.load(open( \"../data/raw/one-hot-entities.p\", \"rb\" ) )\n",
    "entities_labels = pickle.load(open( \"../data/raw/one-hot-entities_labels.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_train_entities_cond_matrix_df, w2v_test_entities_cond_matrix_df = create_conditional_train_test(train_word_token, test_word_token, entities, entities_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glove_train_entities_cond_matrix_df, glove_test_entities_cond_matrix_df = create_conditional_train_test(sg_train_word_token, sg_test_word_token, entities, entities_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_z(args):\n",
    "    mu, l_sigma = args\n",
    "    eps = K.random_normal(shape=(m, n_z), mean=0., stddev=1.)\n",
    "    return mu + K.exp(l_sigma / 2) * eps\n",
    "\n",
    "def vae_loss(x, x_decoded_mean):\n",
    "    \"\"\"Defines the VAE loss functions as a combination of MSE and KL-divergence loss.\"\"\"\n",
    "    # -ELBO = MSE + KL\n",
    "    mse_loss = K.mean(keras.losses.mse(x, x_decoded_mean), axis=-1)\n",
    "    kl_loss = - 0.5 * K.mean(1 + l_sigma - K.square(mu) - K.exp(l_sigma), axis=-1)\n",
    "    return mse_loss + kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_closest_word(xhat, train_w2v_embed = train_w2v_embed, train_w2v_token= train_w2v_token, most_similar_n = 1):\n",
    "    \"\"\"Use cosine distance to find the most similar word to the decoder output\"\"\"\n",
    "    # xhat = decoder.predict(sample_word_3)\n",
    "    cos_sim = abs(cosine_similarity(xhat, train_w2v_embed)).flatten() # calculate dist\n",
    "    inx = np.argsort(cos_sim)[::-1][:most_similar_n] # the most similar, index\n",
    "    return train_w2v_token[inx] # most similar word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define variables\n",
    "m = 30 # batch size\n",
    "n_z = 75 # latent space size\n",
    "encoder_dim1 = 128 # dim of encoder hidden layer\n",
    "decoder_dim = 128 # dim of decoder hidden layer\n",
    "activ = 'relu'\n",
    "optim = Adam(lr=0.001)\n",
    "n_epoch = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_46 (InputLayer)           (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_47 (InputLayer)           (None, 1000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 1300)         0           input_46[0][0]                   \n",
      "                                                                 input_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_76 (Dense)                (None, 128)          166528      concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_77 (Dense)                (None, 75)           9675        dense_76[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_78 (Dense)                (None, 75)           9675        dense_76[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 75)           0           dense_77[0][0]                   \n",
      "                                                                 dense_78[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 1075)         0           lambda_16[0][0]                  \n",
      "                                                                 input_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_79 (Dense)                (None, 128)          137728      concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_80 (Dense)                (None, 300)          38700       dense_79[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 362,306\n",
      "Trainable params: 362,306\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 12000 samples, validate on 3000 samples\n",
      "Epoch 1/50\n",
      "12000/12000 [==============================] - 14s 1ms/step - loss: 0.0349 - val_loss: 0.0305\n",
      "Epoch 2/50\n",
      "12000/12000 [==============================] - 8s 628us/step - loss: 0.0303 - val_loss: 0.0302\n",
      "Epoch 3/50\n",
      "12000/12000 [==============================] - 7s 560us/step - loss: 0.0301 - val_loss: 0.0300\n",
      "Epoch 4/50\n",
      "12000/12000 [==============================] - 7s 621us/step - loss: 0.0298 - val_loss: 0.0296\n",
      "Epoch 5/50\n",
      "12000/12000 [==============================] - 8s 639us/step - loss: 0.0294 - val_loss: 0.0293\n",
      "Epoch 6/50\n",
      "12000/12000 [==============================] - 8s 681us/step - loss: 0.0290 - val_loss: 0.0289\n",
      "Epoch 7/50\n",
      "12000/12000 [==============================] - 8s 635us/step - loss: 0.0286 - val_loss: 0.0284\n",
      "Epoch 8/50\n",
      "12000/12000 [==============================] - 7s 576us/step - loss: 0.0281 - val_loss: 0.0280\n",
      "Epoch 9/50\n",
      "12000/12000 [==============================] - 8s 704us/step - loss: 0.0277 - val_loss: 0.0276\n",
      "Epoch 10/50\n",
      "12000/12000 [==============================] - 9s 709us/step - loss: 0.0273 - val_loss: 0.0273\n",
      "Epoch 11/50\n",
      "12000/12000 [==============================] - 8s 652us/step - loss: 0.0270 - val_loss: 0.0270\n",
      "Epoch 12/50\n",
      "12000/12000 [==============================] - 8s 636us/step - loss: 0.0267 - val_loss: 0.0267\n",
      "Epoch 13/50\n",
      "12000/12000 [==============================] - 7s 623us/step - loss: 0.0264 - val_loss: 0.0265\n",
      "Epoch 14/50\n",
      "12000/12000 [==============================] - 7s 608us/step - loss: 0.0261 - val_loss: 0.0263\n",
      "Epoch 15/50\n",
      "12000/12000 [==============================] - 8s 651us/step - loss: 0.0259 - val_loss: 0.0261\n",
      "Epoch 16/50\n",
      "12000/12000 [==============================] - 8s 681us/step - loss: 0.0257 - val_loss: 0.0259\n",
      "Epoch 17/50\n",
      "12000/12000 [==============================] - 8s 662us/step - loss: 0.0255 - val_loss: 0.0258\n",
      "Epoch 18/50\n",
      "12000/12000 [==============================] - 7s 614us/step - loss: 0.0254 - val_loss: 0.0256\n",
      "Epoch 19/50\n",
      "12000/12000 [==============================] - 7s 560us/step - loss: 0.0252 - val_loss: 0.0255\n",
      "Epoch 20/50\n",
      "12000/12000 [==============================] - 6s 538us/step - loss: 0.0251 - val_loss: 0.0254\n",
      "Epoch 21/50\n",
      "12000/12000 [==============================] - 7s 568us/step - loss: 0.0250 - val_loss: 0.0253\n",
      "Epoch 22/50\n",
      "12000/12000 [==============================] - 7s 570us/step - loss: 0.0249 - val_loss: 0.0252\n",
      "Epoch 23/50\n",
      "12000/12000 [==============================] - 7s 582us/step - loss: 0.0248 - val_loss: 0.0251\n",
      "Epoch 24/50\n",
      "12000/12000 [==============================] - 7s 590us/step - loss: 0.0247 - val_loss: 0.0251\n",
      "Epoch 25/50\n",
      "12000/12000 [==============================] - 7s 621us/step - loss: 0.0246 - val_loss: 0.0250\n",
      "Epoch 26/50\n",
      "12000/12000 [==============================] - 7s 609us/step - loss: 0.0245 - val_loss: 0.0249\n",
      "Epoch 27/50\n",
      "12000/12000 [==============================] - 8s 672us/step - loss: 0.0244 - val_loss: 0.0249\n",
      "Epoch 28/50\n",
      "12000/12000 [==============================] - 7s 596us/step - loss: 0.0244 - val_loss: 0.0248\n",
      "Epoch 29/50\n",
      "12000/12000 [==============================] - 8s 661us/step - loss: 0.0243 - val_loss: 0.0248\n",
      "Epoch 30/50\n",
      "12000/12000 [==============================] - 7s 588us/step - loss: 0.0243 - val_loss: 0.0247\n",
      "Epoch 31/50\n",
      "12000/12000 [==============================] - 7s 592us/step - loss: 0.0242 - val_loss: 0.0247\n",
      "Epoch 32/50\n",
      "12000/12000 [==============================] - 7s 624us/step - loss: 0.0241 - val_loss: 0.0246\n",
      "Epoch 33/50\n",
      "12000/12000 [==============================] - 8s 680us/step - loss: 0.0241 - val_loss: 0.0246\n",
      "Epoch 34/50\n",
      "12000/12000 [==============================] - 8s 675us/step - loss: 0.0240 - val_loss: 0.0246\n",
      "Epoch 35/50\n",
      "12000/12000 [==============================] - 7s 583us/step - loss: 0.0240 - val_loss: 0.0245\n",
      "Epoch 36/50\n",
      "12000/12000 [==============================] - 7s 571us/step - loss: 0.0240 - val_loss: 0.0245\n",
      "Epoch 37/50\n",
      "12000/12000 [==============================] - 7s 580us/step - loss: 0.0239 - val_loss: 0.0245\n",
      "Epoch 38/50\n",
      "12000/12000 [==============================] - 7s 581us/step - loss: 0.0239 - val_loss: 0.0245\n",
      "Epoch 39/50\n",
      "12000/12000 [==============================] - 8s 635us/step - loss: 0.0239 - val_loss: 0.0244\n",
      "Epoch 40/50\n",
      "12000/12000 [==============================] - 7s 605us/step - loss: 0.0238 - val_loss: 0.0244\n",
      "Epoch 41/50\n",
      "12000/12000 [==============================] - 6s 498us/step - loss: 0.0238 - val_loss: 0.0244\n",
      "Epoch 42/50\n",
      "12000/12000 [==============================] - 6s 499us/step - loss: 0.0238 - val_loss: 0.0244\n",
      "Epoch 43/50\n",
      "12000/12000 [==============================] - 6s 516us/step - loss: 0.0237 - val_loss: 0.0244\n",
      "Epoch 44/50\n",
      "12000/12000 [==============================] - 7s 603us/step - loss: 0.0237 - val_loss: 0.0243\n",
      "Epoch 45/50\n",
      "12000/12000 [==============================] - 7s 597us/step - loss: 0.0237 - val_loss: 0.0243\n",
      "Epoch 46/50\n",
      "12000/12000 [==============================] - 6s 541us/step - loss: 0.0237 - val_loss: 0.0243\n",
      "Epoch 47/50\n",
      "12000/12000 [==============================] - 7s 563us/step - loss: 0.0236 - val_loss: 0.0243\n",
      "Epoch 48/50\n",
      "12000/12000 [==============================] - 7s 623us/step - loss: 0.0236 - val_loss: 0.0243\n",
      "Epoch 49/50\n",
      "12000/12000 [==============================] - 7s 566us/step - loss: 0.0236 - val_loss: 0.0243\n",
      "Epoch 50/50\n",
      "12000/12000 [==============================] - 6s 506us/step - loss: 0.0236 - val_loss: 0.0243\n"
     ]
    }
   ],
   "source": [
    "### PARAMETERS ###\n",
    "decoder_out_dim = train_w2v_embed.shape[1] # dim of decoder output layer\n",
    "n_x = train_w2v_embed.shape[1]\n",
    "n_y = train_word_embed.shape[1]\n",
    "train_embed = train_w2v_embed\n",
    "train_word = train_word_embed\n",
    "test_embed = test_w2v_embed\n",
    "test_word = test_word_embed\n",
    "### PARAMETERS ###\n",
    "\n",
    "# define encoder\n",
    "X = Input(shape=(n_x,))\n",
    "label = Input(shape=(n_y,))\n",
    "inputs = concat([X, label])\n",
    "encoder_h = Dense(encoder_dim1, activation=activ)(inputs)\n",
    "mu = Dense(n_z, activation='linear')(encoder_h)\n",
    "l_sigma = Dense(n_z, activation='linear')(encoder_h)\n",
    "\n",
    "# sample latent space\n",
    "z = Lambda(sample_z, output_shape = (n_z, ))([mu, l_sigma])\n",
    "zc = concat([z, label])\n",
    "\n",
    "# decoder\n",
    "decoder_hidden = Dense(decoder_dim, activation=activ)\n",
    "decoder_out = Dense(decoder_out_dim, activation='sigmoid')\n",
    "h_p = decoder_hidden(zc)\n",
    "outputs = decoder_out(h_p)\n",
    "\n",
    "# define graphs\n",
    "cvae = Model([X, label], outputs)\n",
    "encoder = Model([X, label], mu)\n",
    "d_in = Input(shape=(n_z+n_y,))\n",
    "d_h = decoder_hidden(d_in)\n",
    "d_out = decoder_out(d_h)\n",
    "decoder = Model(d_in, d_out)\n",
    "\n",
    "# print statistics\n",
    "cvae.compile(optimizer=optim, loss=vae_loss)\n",
    "\n",
    "cvae.summary()\n",
    "\n",
    "cvae_hist = cvae.fit([train_embed, train_word], train_embed, verbose = 1, batch_size=m, \n",
    "                 epochs=n_epoch,\n",
    "                 validation_data = ([test_embed, test_word], test_embed),\n",
    "                 callbacks = [EarlyStopping(patience = 5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decode_words(word, dimension, train_w2v_embed, train_w2v_token, train_word_embed, cond_type=\"spine\"):\n",
    "    # get word index\n",
    "    print(\"WORD: \" + str(word))\n",
    "    word_inx = np.where(train_w2v_token == word)[0][0]\n",
    "    print(word_inx)\n",
    "#     math_w2v = train_w2v_embed[word_inx]\n",
    "    \n",
    "    if cond_type == \"spine\":\n",
    "        math_encoded = encoder.predict([np.repeat(np.expand_dims(train_w2v_embed[word_inx], axis = 0), m, axis=0), \n",
    "                                        np.repeat(np.expand_dims(train_word_embed[word_inx], axis = 0), m, axis=0)],\n",
    "                                   batch_size = m)\n",
    "    else:\n",
    "        math_encoded = encoder.predict([np.repeat(np.expand_dims(train_w2v_embed[word_inx], axis = 0), m, axis=0), \n",
    "                                        np.repeat(np.expand_dims(train_word_embed.iloc[word_inx], axis = 0), m, axis=0)],\n",
    "                                   batch_size = m)\n",
    "    values_to_try = np.linspace(0,5,num=10)\n",
    "    for val in values_to_try:\n",
    "        print(\"VALUE: \" + str(val))\n",
    "        if cond_type == \"spine\":\n",
    "            new_condition = train_word_embed[word_inx].copy()\n",
    "        else:\n",
    "            new_condition = train_word_embed.iloc[word_inx].copy()\n",
    "        print(new_condition.shape)\n",
    "        new_condition[dimension] = val # strengthen the condition, value needs to be higher than 1\n",
    "\n",
    "        decoder_input_z2 = np.concatenate((math_encoded, \n",
    "                                            np.repeat(np.expand_dims(new_condition, axis=0), m, axis=0)),\n",
    "                                          axis=1)\n",
    "        z_decoded2 = decoder.predict(decoder_input_z2)\n",
    "\n",
    "        print(find_closest_word(np.expand_dims(z_decoded2[0], axis=0), most_similar_n=10))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORD: mathematics\n",
      "11730\n",
      "VALUE: 0.0\n",
      "(1000,)\n",
      "['mathematics' 'math' 'physics' 'mathematician' 'linguistics' 'science'\n",
      " 'sociology' 'algebra' 'economics' 'anthropology']\n",
      "VALUE: 0.5555555555555556\n",
      "(1000,)\n",
      "['mathematics' 'math' 'algebra' 'science' 'physics' 'linguistics'\n",
      " 'anthropology' 'sociology' 'economics' 'biology']\n",
      "VALUE: 1.1111111111111112\n",
      "(1000,)\n",
      "['mathematics' 'math' 'algebra' 'anthropology' 'science' 'linguistics'\n",
      " 'sociology' 'physics' 'biology' 'calculus']\n",
      "VALUE: 1.6666666666666667\n",
      "(1000,)\n",
      "['mathematics' 'algebra' 'math' 'anthropology' 'linguistics' 'science'\n",
      " 'curriculum' 'sociology' 'calculus' 'biology']\n",
      "VALUE: 2.2222222222222223\n",
      "(1000,)\n",
      "['algebra' 'mathematics' 'math' 'anthropology' 'curriculum' 'science'\n",
      " 'linguistics' 'calculus' 'biology' 'sociology']\n",
      "VALUE: 2.7777777777777777\n",
      "(1000,)\n",
      "['algebra' 'mathematics' 'math' 'curriculum' 'anthropology' 'calculus'\n",
      " 'biology' 'science' 'linguistics' 'classes']\n",
      "VALUE: 3.3333333333333335\n",
      "(1000,)\n",
      "['algebra' 'mathematics' 'math' 'curriculum' 'anthropology' 'biology'\n",
      " 'calculus' 'classes' 'exam' 'science']\n",
      "VALUE: 3.8888888888888893\n",
      "(1000,)\n",
      "['algebra' 'mathematics' 'math' 'curriculum' 'classes' 'anthropology'\n",
      " 'exam' 'biology' 'calculus' 'teaching']\n",
      "VALUE: 4.444444444444445\n",
      "(1000,)\n",
      "['algebra' 'mathematics' 'math' 'curriculum' 'classes' 'exam' 'teaching'\n",
      " 'anthropology' 'courses' 'biology']\n",
      "VALUE: 5.0\n",
      "(1000,)\n",
      "['algebra' 'mathematics' 'math' 'curriculum' 'classes' 'exam' 'teaching'\n",
      " 'courses' 'diploma' 'vocational']\n",
      "WORD: mathematics\n",
      "11730\n",
      "VALUE: 0.0\n",
      "(1000,)\n",
      "['mathematics' 'math' 'algebra' 'anthropology' 'linguistics' 'sociology'\n",
      " 'science' 'biology' 'physics' 'economics']\n",
      "VALUE: 0.5555555555555556\n",
      "(1000,)\n",
      "['mathematics' 'math' 'algebra' 'physics' 'science' 'linguistics'\n",
      " 'anthropology' 'economics' 'sociology' 'mathematician']\n",
      "VALUE: 1.1111111111111112\n",
      "(1000,)\n",
      "['mathematics' 'math' 'algebra' 'physics' 'science' 'theorem'\n",
      " 'mathematician' 'economics' 'linguistics' 'calculus']\n",
      "VALUE: 1.6666666666666667\n",
      "(1000,)\n",
      "['mathematics' 'math' 'physics' 'algebra' 'theorem' 'science'\n",
      " 'mathematician' 'economics' 'theory' 'calculus']\n",
      "VALUE: 2.2222222222222223\n",
      "(1000,)\n",
      "['mathematics' 'math' 'physics' 'theorem' 'algebra' 'mathematician'\n",
      " 'science' 'theory' 'economics' 'calculus']\n",
      "VALUE: 2.7777777777777777\n",
      "(1000,)\n",
      "['mathematics' 'math' 'theorem' 'physics' 'algebra' 'mathematician'\n",
      " 'theory' 'science' 'myth' 'economics']\n",
      "VALUE: 3.3333333333333335\n",
      "(1000,)\n",
      "['mathematics' 'math' 'theorem' 'physics' 'algebra' 'myth' 'theory'\n",
      " 'mathematician' 'science' 'mysteries']\n",
      "VALUE: 3.8888888888888893\n",
      "(1000,)\n",
      "['mathematics' 'math' 'theorem' 'physics' 'algebra' 'myth' 'theory'\n",
      " 'mathematician' 'science' 'mythology']\n",
      "VALUE: 4.444444444444445\n",
      "(1000,)\n",
      "['mathematics' 'theorem' 'math' 'myth' 'physics' 'algebra' 'theory'\n",
      " 'mathematician' 'mythology' 'mysteries']\n",
      "VALUE: 5.0\n",
      "(1000,)\n",
      "['mathematics' 'theorem' 'math' 'myth' 'physics' 'algebra' 'theory'\n",
      " 'mythology' 'mathematician' 'mysteries']\n",
      "WORD: mathematics\n",
      "11730\n",
      "VALUE: 0.0\n",
      "(1000,)\n",
      "['mathematics' 'math' 'algebra' 'science' 'physics' 'linguistics'\n",
      " 'anthropology' 'calculus' 'economics' 'sociology']\n",
      "VALUE: 0.5555555555555556\n",
      "(1000,)\n",
      "['mathematics' 'math' 'algebra' 'linguistics' 'anthropology' 'physics'\n",
      " 'science' 'sociology' 'economics' 'biology']\n",
      "VALUE: 1.1111111111111112\n",
      "(1000,)\n",
      "['mathematics' 'math' 'anthropology' 'sociology' 'linguistics' 'physics'\n",
      " 'science' 'psychology' 'algebra' 'economics']\n",
      "VALUE: 1.6666666666666667\n",
      "(1000,)\n",
      "['mathematics' 'anthropology' 'sociology' 'linguistics' 'psychology'\n",
      " 'physics' 'math' 'science' 'biology' 'economics']\n",
      "VALUE: 2.2222222222222223\n",
      "(1000,)\n",
      "['sociology' 'anthropology' 'mathematics' 'psychology' 'linguistics'\n",
      " 'physics' 'math' 'science' 'biology' 'economics']\n",
      "VALUE: 2.7777777777777777\n",
      "(1000,)\n",
      "['sociology' 'anthropology' 'psychology' 'mathematics' 'linguistics'\n",
      " 'physics' 'biology' 'science' 'professor' 'math']\n",
      "VALUE: 3.3333333333333335\n",
      "(1000,)\n",
      "['sociology' 'anthropology' 'psychology' 'linguistics' 'mathematics'\n",
      " 'professor' 'biology' 'physics' 'science' 'undergraduate']\n",
      "VALUE: 3.8888888888888893\n",
      "(1000,)\n",
      "['sociology' 'anthropology' 'psychology' 'linguistics' 'professor'\n",
      " 'mathematics' 'biology' 'physics' 'science' 'undergraduate']\n",
      "VALUE: 4.444444444444445\n",
      "(1000,)\n",
      "['sociology' 'anthropology' 'psychology' 'linguistics' 'professor'\n",
      " 'mathematics' 'biology' 'science' 'physics' 'undergraduate']\n",
      "VALUE: 5.0\n",
      "(1000,)\n",
      "['sociology' 'anthropology' 'psychology' 'professor' 'linguistics'\n",
      " 'biology' 'undergraduate' 'doctorate' 'science' 'mathematics']\n",
      "WORD: remote\n",
      "7807\n",
      "VALUE: 0.0\n",
      "(1000,)\n",
      "['remote' 'northern' 'southern' 'western' 'remnants' 'weird' 'isolated'\n",
      " 'hbo' 'rebellious' 'neighboring']\n",
      "VALUE: 0.5555555555555556\n",
      "(1000,)\n",
      "['remote' 'western' 'northern' 'northeastern' 'northwestern' 'southern'\n",
      " 'southwestern' 'rural' 'highlands' 'central']\n",
      "VALUE: 1.1111111111111112\n",
      "(1000,)\n",
      "['remote' 'northeastern' 'western' 'northwestern' 'rural' 'northern'\n",
      " 'southwestern' 'southern' 'highlands' 'northeast']\n",
      "VALUE: 1.6666666666666667\n",
      "(1000,)\n",
      "['northeastern' 'remote' 'rural' 'northwestern' 'western' 'northern'\n",
      " 'southwestern' 'southern' 'highlands' 'hamlet']\n",
      "VALUE: 2.2222222222222223\n",
      "(1000,)\n",
      "['northeastern' 'rural' 'northwestern' 'western' 'northern' 'southwestern'\n",
      " 'hamlet' 'highlands' 'remote' 'southern']\n",
      "VALUE: 2.7777777777777777\n",
      "(1000,)\n",
      "['northeastern' 'rural' 'northwestern' 'western' 'northern' 'southwestern'\n",
      " 'hamlet' 'highlands' 'villages' 'southern']\n",
      "VALUE: 3.3333333333333335\n",
      "(1000,)\n",
      "['northeastern' 'rural' 'northwestern' 'hamlet' 'villages' 'southwestern'\n",
      " 'northern' 'western' 'highlands' 'village']\n",
      "VALUE: 3.8888888888888893\n",
      "(1000,)\n",
      "['northeastern' 'rural' 'hamlet' 'villages' 'northwestern' 'southwestern'\n",
      " 'village' 'northern' 'countryside' 'highlands']\n",
      "VALUE: 4.444444444444445\n",
      "(1000,)\n",
      "['villages' 'northeastern' 'hamlet' 'rural' 'countryside' 'northwestern'\n",
      " 'village' 'southwestern' 'northern' 'highlands']\n",
      "VALUE: 5.0\n",
      "(1000,)\n",
      "['villages' 'hamlet' 'northeastern' 'countryside' 'rural' 'village'\n",
      " 'northwestern' 'southwestern' 'highlands' 'coastal']\n",
      "WORD: remote\n",
      "7807\n",
      "VALUE: 0.0\n",
      "(1000,)\n",
      "['remote' 'northern' 'southern' 'accidentally' 'western' 'drift'\n",
      " 'remnants' 'lunar' 'aol' 'taiwanese']\n",
      "VALUE: 0.5555555555555556\n",
      "(1000,)\n",
      "['remote' 'western' 'northern' 'isolated' 'southern' 'northwestern'\n",
      " 'northeastern' 'northeast' 'mountainous' 'southwestern']\n",
      "VALUE: 1.1111111111111112\n",
      "(1000,)\n",
      "['isolated' 'western' 'remote' 'northern' 'northwestern' 'northeastern'\n",
      " 'southern' 'outlying' 'northeast' 'inhabited']\n",
      "VALUE: 1.6666666666666667\n",
      "(1000,)\n",
      "['isolated' 'western' 'remote' 'inhabited' 'northern' 'outlying'\n",
      " 'bordering' 'northwestern' 'northeastern' 'southern']\n",
      "VALUE: 2.2222222222222223\n",
      "(1000,)\n",
      "['isolated' 'western' 'bordering' 'inhabited' 'outlying' 'populated'\n",
      " 'northern' 'northeastern' 'northwestern' 'northwest']\n",
      "VALUE: 2.7777777777777777\n",
      "(1000,)\n",
      "['isolated' 'western' 'bordering' 'inhabited' 'populated' 'outlying'\n",
      " 'northeastern' 'northwest' 'northwestern' 'northern']\n",
      "VALUE: 3.3333333333333335\n",
      "(1000,)\n",
      "['isolated' 'western' 'bordering' 'populated' 'inhabited' 'outlying'\n",
      " 'northwest' 'northeastern' 'northwestern' 'populous']\n",
      "VALUE: 3.8888888888888893\n",
      "(1000,)\n",
      "['isolated' 'bordering' 'western' 'populated' 'inhabited' 'outlying'\n",
      " 'northwest' 'northeastern' 'northwestern' 'populous']\n",
      "VALUE: 4.444444444444445\n",
      "(1000,)\n",
      "['isolated' 'bordering' 'western' 'populated' 'inhabited' 'northwest'\n",
      " 'northeastern' 'outlying' 'governed' 'northwestern']\n",
      "VALUE: 5.0\n",
      "(1000,)\n",
      "['isolated' 'bordering' 'western' 'populated' 'inhabited' 'northwest'\n",
      " 'northeastern' 'governed' 'northwestern' 'outlying']\n",
      "WORD: remote\n",
      "7807\n",
      "VALUE: 0.0\n",
      "(1000,)\n",
      "['remote' 'northern' 'western' 'southern' 'northwestern' 'northeastern'\n",
      " 'northeast' 'southwestern' 'neighboring' 'mountainous']\n",
      "VALUE: 0.5555555555555556\n",
      "(1000,)\n",
      "['remote' 'northern' 'icons' 'southern' 'rebellious' 'western' 'icon'\n",
      " 'accidentally' 'pornographic' 'rocks']\n",
      "VALUE: 1.1111111111111112\n",
      "(1000,)\n",
      "['remote' 'icons' 'icon' 'button' 'pop' 'chat' 'buttons' 'dial' 'screen'\n",
      " 'flash']\n",
      "VALUE: 1.6666666666666667\n",
      "(1000,)\n",
      "['icons' 'icon' 'button' 'remote' 'pop' 'buttons' 'chat' 'flash' 'dial'\n",
      " 'click']\n",
      "VALUE: 2.2222222222222223\n",
      "(1000,)\n",
      "['icons' 'icon' 'button' 'buttons' 'pop' 'chat' 'remote' 'click' 'aol'\n",
      " 'flash']\n",
      "VALUE: 2.7777777777777777\n",
      "(1000,)\n",
      "['icons' 'icon' 'button' 'buttons' 'chat' 'pop' 'click' 'drag' 'aol'\n",
      " 'flash']\n",
      "VALUE: 3.3333333333333335\n",
      "(1000,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['icons' 'icon' 'button' 'buttons' 'chat' 'click' 'pop' 'drag' 'slides'\n",
      " 'aol']\n",
      "VALUE: 3.8888888888888893\n",
      "(1000,)\n",
      "['icons' 'icon' 'button' 'buttons' 'chat' 'click' 'drag' 'pop' 'slides'\n",
      " 'beaver']\n",
      "VALUE: 4.444444444444445\n",
      "(1000,)\n",
      "['icons' 'icon' 'button' 'buttons' 'drag' 'click' 'chat' 'slides' 'beaver'\n",
      " 'pop']\n",
      "VALUE: 5.0\n",
      "(1000,)\n",
      "['icons' 'icon' 'button' 'buttons' 'drag' 'click' 'chat' 'slides' 'beaver'\n",
      " 'lester']\n",
      "WORD: internet\n",
      "503\n",
      "VALUE: 0.0\n",
      "(1000,)\n",
      "['musicians' 'artists' 'bands' 'concerts' 'ensembles' 'musician' 'music'\n",
      " 'composers' 'violinist' 'pianist']\n",
      "VALUE: 0.5555555555555556\n",
      "(1000,)\n",
      "['musicians' 'artists' 'musician' 'music' 'bands' 'composers' 'concerts'\n",
      " 'artist' 'gigs' 'pianist']\n",
      "VALUE: 1.1111111111111112\n",
      "(1000,)\n",
      "['artists' 'musicians' 'musician' 'music' 'composers' 'blogs' 'gigs'\n",
      " 'artist' 'bands' 'concerts']\n",
      "VALUE: 1.6666666666666667\n",
      "(1000,)\n",
      "['musician' 'artists' 'musicians' 'blogs' 'music' 'websites' 'celebrities'\n",
      " 'chat' 'gigs' 'myspace']\n",
      "VALUE: 2.2222222222222223\n",
      "(1000,)\n",
      "['blogs' 'musician' 'artists' 'websites' 'chat' 'musicians' 'myspace'\n",
      " 'persona' 'celebrities' 'censorship']\n",
      "VALUE: 2.7777777777777777\n",
      "(1000,)\n",
      "['blogs' 'websites' 'musician' 'chat' 'artists' 'myspace' 'persona'\n",
      " 'censorship' 'celebrities' 'journalists']\n",
      "VALUE: 3.3333333333333335\n",
      "(1000,)\n",
      "['blogs' 'chat' 'websites' 'musician' 'censorship' 'myspace' 'persona'\n",
      " 'artists' 'surfing' 'journalists']\n",
      "VALUE: 3.8888888888888893\n",
      "(1000,)\n",
      "['blogs' 'chat' 'websites' 'censorship' 'musician' 'persona' 'myspace'\n",
      " 'surfing' 'journalists' 'media']\n",
      "VALUE: 4.444444444444445\n",
      "(1000,)\n",
      "['blogs' 'chat' 'websites' 'censorship' 'surfing' 'persona' 'journalists'\n",
      " 'myspace' 'musician' 'media']\n",
      "VALUE: 5.0\n",
      "(1000,)\n",
      "['chat' 'blogs' 'censorship' 'websites' 'surfing' 'journalists' 'persona'\n",
      " 'myspace' 'media' 'musician']\n",
      "WORD: internet\n",
      "503\n",
      "VALUE: 0.0\n",
      "(1000,)\n",
      "['musicians' 'artists' 'bands' 'concerts' 'ensembles' 'musician' 'music'\n",
      " 'composers' 'violinist' 'pianist']\n",
      "VALUE: 0.5555555555555556\n",
      "(1000,)\n",
      "['musicians' 'artists' 'music' 'bands' 'concerts' 'ensembles' 'musician'\n",
      " 'composers' 'artist' 'band']\n",
      "VALUE: 1.1111111111111112\n",
      "(1000,)\n",
      "['musicians' 'artists' 'music' 'albums' 'bands' 'musician' 'concerts'\n",
      " 'ensembles' 'artist' 'remixes']\n",
      "VALUE: 1.6666666666666667\n",
      "(1000,)\n",
      "['musicians' 'music' 'albums' 'artists' 'remixes' 'art' 'musician' 'bands'\n",
      " 'songs' 'peoples']\n",
      "VALUE: 2.2222222222222223\n",
      "(1000,)\n",
      "['music' 'albums' 'musicians' 'artists' 'remixes' 'touchdowns' 'art'\n",
      " 'resolutions' 'peoples' 'documentaries']\n",
      "VALUE: 2.7777777777777777\n",
      "(1000,)\n",
      "['music' 'albums' 'touchdowns' 'musicians' 'resolutions' 'motions'\n",
      " 'remixes' 'art' 'artists' 'peoples']\n",
      "VALUE: 3.3333333333333335\n",
      "(1000,)\n",
      "['music' 'albums' 'motions' 'touchdowns' 'resolutions' 'committees'\n",
      " 'online' 'remixes' 'treaties' 'dragging']\n",
      "VALUE: 3.8888888888888893\n",
      "(1000,)\n",
      "['music' 'motions' 'albums' 'resolutions' 'touchdowns' 'online'\n",
      " 'committees' 'dragging' 'treaties' 'media']\n",
      "VALUE: 4.444444444444445\n",
      "(1000,)\n",
      "['motions' 'music' 'online' 'resolutions' 'committees' 'media' 'dragging'\n",
      " 'treaties' 'touchdowns' 'agreements']\n",
      "VALUE: 5.0\n",
      "(1000,)\n",
      "['motions' 'online' 'media' 'treaties' 'agreements' 'committees'\n",
      " 'dragging' 'resolutions' 'music' 'gossip']\n",
      "WORD: internet\n",
      "503\n",
      "VALUE: 0.0\n",
      "(1000,)\n",
      "['musicians' 'artists' 'bands' 'concerts' 'ensembles' 'musician' 'music'\n",
      " 'composers' 'violinist' 'pianist']\n",
      "VALUE: 0.5555555555555556\n",
      "(1000,)\n",
      "['musicians' 'artists' 'ensembles' 'composers' 'celebrities' 'comedians'\n",
      " 'concerts' 'bands' 'performances' 'musician']\n",
      "VALUE: 1.1111111111111112\n",
      "(1000,)\n",
      "['blogs' 'musicians' 'celebrities' 'artists' 'ensembles' 'comedians'\n",
      " 'myspace' 'celebrity' 'performances' 'websites']\n",
      "VALUE: 1.6666666666666667\n",
      "(1000,)\n",
      "['blogs' 'celebrities' 'twitter' 'websites' 'myspace' 'celebrity'\n",
      " 'commentaries' 'gossip' 'musicians' 'newspapers']\n",
      "VALUE: 2.2222222222222223\n",
      "(1000,)\n",
      "['blogs' 'twitter' 'gossip' 'websites' 'celebrities' 'commentaries' 'blog'\n",
      " 'newspapers' 'facebook' 'celebrity']\n",
      "VALUE: 2.7777777777777777\n",
      "(1000,)\n",
      "['blogs' 'twitter' 'gossip' 'websites' 'blog' 'commentaries' 'facebook'\n",
      " 'celebrities' 'newspapers' 'website']\n",
      "VALUE: 3.3333333333333335\n",
      "(1000,)\n",
      "['blogs' 'gossip' 'twitter' 'websites' 'blog' 'facebook' 'commentaries'\n",
      " 'newspapers' 'website' 'celebrities']\n",
      "VALUE: 3.8888888888888893\n",
      "(1000,)\n",
      "['blogs' 'gossip' 'twitter' 'websites' 'facebook' 'blog' 'commentaries'\n",
      " 'newspapers' 'website' 'news']\n",
      "VALUE: 4.444444444444445\n",
      "(1000,)\n",
      "['blogs' 'gossip' 'twitter' 'websites' 'facebook' 'blog' 'commentaries'\n",
      " 'website' 'newspapers' 'news']\n",
      "VALUE: 5.0\n",
      "(1000,)\n",
      "['blogs' 'gossip' 'twitter' 'facebook' 'websites' 'blog' 'news'\n",
      " 'commentaries' 'website' 'newspapers']\n"
     ]
    }
   ],
   "source": [
    "find_top_words(train_w2v_embed, train_w2v_token, test_w2v_embed, test_w2v_token, train_word_embed, \"word2vec\", \"spine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORD: mathematics\n",
      "11730\n",
      "VALUE: 0.0\n",
      "['mathematics' 'math' 'physics' 'economics' 'mathematician' 'science'\n",
      " 'theorem' 'linguistics' 'sociology' 'psychology']\n",
      "VALUE: 0.5555555555555556\n",
      "['mathematics' 'math' 'algebra' 'science' 'linguistics' 'economics'\n",
      " 'physics' 'anthropology' 'sociology' 'theology']\n",
      "VALUE: 1.1111111111111112\n",
      "['mathematics' 'math' 'algebra' 'science' 'linguistics' 'anthropology'\n",
      " 'economics' 'biology' 'calculus' 'physics']\n",
      "VALUE: 1.6666666666666667\n",
      "['mathematics' 'algebra' 'math' 'science' 'linguistics' 'curriculum'\n",
      " 'anthropology' 'biology' 'calculus' 'economics']\n",
      "VALUE: 2.2222222222222223\n",
      "['mathematics' 'algebra' 'math' 'curriculum' 'science' 'biology'\n",
      " 'anthropology' 'linguistics' 'vocational' 'calculus']\n",
      "VALUE: 2.7777777777777777\n",
      "['algebra' 'mathematics' 'math' 'curriculum' 'biology' 'vocational'\n",
      " 'anthropology' 'science' 'linguistics' 'calculus']\n",
      "VALUE: 3.3333333333333335\n",
      "['algebra' 'mathematics' 'math' 'curriculum' 'biology' 'vocational'\n",
      " 'anthropology' 'science' 'linguistics' 'calculus']\n",
      "VALUE: 3.8888888888888893\n",
      "['algebra' 'mathematics' 'math' 'curriculum' 'biology' 'vocational'\n",
      " 'science' 'anthropology' 'courses' 'postgraduate']\n",
      "VALUE: 4.444444444444445\n",
      "['algebra' 'mathematics' 'math' 'curriculum' 'biology' 'vocational'\n",
      " 'courses' 'science' 'postgraduate' 'diploma']\n",
      "VALUE: 5.0\n",
      "['algebra' 'mathematics' 'math' 'curriculum' 'biology' 'vocational'\n",
      " 'courses' 'postgraduate' 'science' 'diploma']\n"
     ]
    }
   ],
   "source": [
    "decode_words(\"mathematics\", 954, train_w2v_embed, train_w2v_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORD: mathematics\n",
      "11730\n",
      "VALUE: 0.0\n",
      "['mathematics' 'math' 'algebra' 'linguistics' 'anthropology' 'sociology'\n",
      " 'science' 'economics' 'theology' 'psychology']\n",
      "VALUE: 0.5555555555555556\n",
      "['mathematics' 'math' 'algebra' 'physics' 'science' 'economics'\n",
      " 'linguistics' 'theorem' 'mathematician' 'anthropology']\n",
      "VALUE: 1.1111111111111112\n",
      "['mathematics' 'math' 'algebra' 'physics' 'science' 'theorem' 'economics'\n",
      " 'mathematician' 'theory' 'calculus']\n",
      "VALUE: 1.6666666666666667\n",
      "['mathematics' 'math' 'physics' 'algebra' 'theorem' 'science'\n",
      " 'mathematician' 'economics' 'theory' 'physicist']\n",
      "VALUE: 2.2222222222222223\n",
      "['mathematics' 'math' 'physics' 'theorem' 'algebra' 'science'\n",
      " 'mathematician' 'theory' 'economics' 'physicist']\n",
      "VALUE: 2.7777777777777777\n",
      "['mathematics' 'math' 'physics' 'theorem' 'science' 'mathematician'\n",
      " 'algebra' 'theory' 'irs' 'physicist']\n",
      "VALUE: 3.3333333333333335\n",
      "['mathematics' 'physics' 'math' 'theorem' 'science' 'mathematician'\n",
      " 'theory' 'irs' 'algebra' 'physicist']\n",
      "VALUE: 3.8888888888888893\n",
      "['mathematics' 'physics' 'math' 'theorem' 'science' 'irs' 'mathematician'\n",
      " 'theory' 'algebra' 'physicist']\n",
      "VALUE: 4.444444444444445\n",
      "['mathematics' 'physics' 'theorem' 'math' 'irs' 'science' 'mathematician'\n",
      " 'theory' 'physicist' 'formulas']\n",
      "VALUE: 5.0\n",
      "['physics' 'mathematics' 'theorem' 'irs' 'math' 'mathematician' 'science'\n",
      " 'theory' 'formulas' 'physicist']\n"
     ]
    }
   ],
   "source": [
    "decode_words(\"mathematics\", 427, train_w2v_embed, train_w2v_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORD: mathematics\n",
      "11730\n",
      "VALUE: 0.0\n",
      "['mathematics' 'math' 'algebra' 'science' 'economics' 'physics'\n",
      " 'linguistics' 'grammar' 'theorem' 'anthropology']\n",
      "VALUE: 0.5555555555555556\n",
      "['mathematics' 'math' 'algebra' 'linguistics' 'science' 'economics'\n",
      " 'physics' 'anthropology' 'sociology' 'theology']\n",
      "VALUE: 1.1111111111111112\n",
      "['mathematics' 'math' 'linguistics' 'sociology' 'economics' 'anthropology'\n",
      " 'physics' 'science' 'thesis' 'psychology']\n",
      "VALUE: 1.6666666666666667\n",
      "['mathematics' 'sociology' 'linguistics' 'anthropology' 'economics'\n",
      " 'undergraduate' 'math' 'thesis' 'physics' 'psychology']\n",
      "VALUE: 2.2222222222222223\n",
      "['mathematics' 'sociology' 'linguistics' 'anthropology' 'undergraduate'\n",
      " 'psychology' 'economics' 'thesis' 'science' 'professors']\n",
      "VALUE: 2.7777777777777777\n",
      "['sociology' 'mathematics' 'linguistics' 'anthropology' 'undergraduate'\n",
      " 'psychology' 'professors' 'thesis' 'science' 'theology']\n",
      "VALUE: 3.3333333333333335\n",
      "['sociology' 'anthropology' 'linguistics' 'undergraduate' 'mathematics'\n",
      " 'professors' 'psychology' 'science' 'theology' 'thesis']\n",
      "VALUE: 3.8888888888888893\n",
      "['sociology' 'anthropology' 'linguistics' 'professors' 'undergraduate'\n",
      " 'psychology' 'mathematics' 'science' 'theology' 'thesis']\n",
      "VALUE: 4.444444444444445\n",
      "['sociology' 'anthropology' 'professors' 'linguistics' 'undergraduate'\n",
      " 'psychology' 'science' 'mathematics' 'theology' 'university']\n",
      "VALUE: 5.0\n",
      "['sociology' 'anthropology' 'professors' 'linguistics' 'undergraduate'\n",
      " 'psychology' 'science' 'theology' 'university' 'mathematics']\n"
     ]
    }
   ],
   "source": [
    "decode_words(\"mathematics\", 206, train_w2v_embed, train_w2v_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORD: remote\n",
      "7807\n",
      "VALUE: 0.0\n",
      "['remote' 'northern' 'southern' 'western' 'aol' 'northwestern' 'northeast'\n",
      " 'neighboring' 'weird' 'hannah']\n",
      "VALUE: 0.5555555555555556\n",
      "['remote' 'northwestern' 'northern' 'northeastern' 'southwestern'\n",
      " 'southern' 'western' 'rural' 'central' 'northeast']\n",
      "VALUE: 1.1111111111111112\n",
      "['remote' 'northeastern' 'northwestern' 'southwestern' 'rural' 'northern'\n",
      " 'western' 'southern' 'central' 'mountainous']\n",
      "VALUE: 1.6666666666666667\n",
      "['remote' 'northeastern' 'rural' 'southwestern' 'northwestern'\n",
      " 'mountainous' 'northern' 'western' 'countryside' 'highlands']\n",
      "VALUE: 2.2222222222222223\n",
      "['northeastern' 'rural' 'southwestern' 'northwestern' 'remote'\n",
      " 'mountainous' 'countryside' 'western' 'mountain' 'northern']\n",
      "VALUE: 2.7777777777777777\n",
      "['northeastern' 'rural' 'southwestern' 'northwestern' 'mountainous'\n",
      " 'remote' 'countryside' 'mountain' 'highlands' 'wilderness']\n",
      "VALUE: 3.3333333333333335\n",
      "['northeastern' 'southwestern' 'rural' 'northwestern' 'mountainous'\n",
      " 'mountain' 'countryside' 'remote' 'highlands' 'wilderness']\n",
      "VALUE: 3.8888888888888893\n",
      "['northeastern' 'southwestern' 'northwestern' 'mountainous' 'rural'\n",
      " 'mountain' 'countryside' 'mountains' 'wilderness' 'highlands']\n",
      "VALUE: 4.444444444444445\n",
      "['northeastern' 'southwestern' 'northwestern' 'mountainous' 'mountain'\n",
      " 'rural' 'countryside' 'mountains' 'wilderness' 'highlands']\n",
      "VALUE: 5.0\n",
      "['northeastern' 'southwestern' 'northwestern' 'mountainous' 'mountain'\n",
      " 'rural' 'countryside' 'mountains' 'wilderness' 'highlands']\n"
     ]
    }
   ],
   "source": [
    "decode_words(\"remote\", 948, train_w2v_embed, train_w2v_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORD: remote\n",
      "7807\n",
      "VALUE: 0.0\n",
      "['remote' 'southern' 'northern' 'aol' 'drift' 'polar' 'northwestern'\n",
      " 'accidentally' 'iceland' 'lunar']\n",
      "VALUE: 0.5555555555555556\n",
      "['remote' 'northern' 'southern' 'western' 'northwestern' 'northeastern'\n",
      " 'northeast' 'southwestern' 'isolated' 'northwest']\n",
      "VALUE: 1.1111111111111112\n",
      "['northern' 'remote' 'southern' 'northwestern' 'western' 'outlying'\n",
      " 'isolated' 'northeastern' 'northeast' 'southwestern']\n",
      "VALUE: 1.6666666666666667\n",
      "['northern' 'outlying' 'southern' 'northeastern' 'northwestern' 'western'\n",
      " 'remote' 'isolated' 'northeast' 'populated']\n",
      "VALUE: 2.2222222222222223\n",
      "['northern' 'outlying' 'southern' 'northeastern' 'northwestern' 'western'\n",
      " 'northeast' 'isolated' 'neighboring' 'populated']\n",
      "VALUE: 2.7777777777777777\n",
      "['northern' 'outlying' 'southern' 'northeastern' 'northwestern' 'western'\n",
      " 'northeast' 'neighboring' 'isolated' 'bordering']\n",
      "VALUE: 3.3333333333333335\n",
      "['northern' 'outlying' 'northeastern' 'southern' 'northwestern' 'western'\n",
      " 'neighboring' 'northeast' 'northwest' 'populated']\n",
      "VALUE: 3.8888888888888893\n",
      "['outlying' 'northern' 'northeastern' 'southern' 'northwestern'\n",
      " 'neighboring' 'western' 'northeast' 'northwest' 'populated']\n",
      "VALUE: 4.444444444444445\n",
      "['outlying' 'northern' 'northeastern' 'southern' 'northwestern'\n",
      " 'neighboring' 'western' 'northeast' 'northwest' 'populated']\n",
      "VALUE: 5.0\n",
      "['outlying' 'northern' 'northeastern' 'southern' 'northwestern'\n",
      " 'neighboring' 'northeast' 'western' 'northwest' 'populated']\n"
     ]
    }
   ],
   "source": [
    "decode_words(\"remote\", 473, train_w2v_embed, train_w2v_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORD: remote\n",
      "7807\n",
      "VALUE: 0.0\n",
      "['remote' 'northern' 'southern' 'northwestern' 'western' 'southwestern'\n",
      " 'northeastern' 'northeast' 'polar' 'northwest']\n",
      "VALUE: 0.5555555555555556\n",
      "['remote' 'northern' 'southern' 'icons' 'hop' 'drag' 'drift' 'aol'\n",
      " 'button' 'icon']\n",
      "VALUE: 1.1111111111111112\n",
      "['icons' 'button' 'remote' 'icon' 'hop' 'buttons' 'lets' 'flash' 'aol'\n",
      " 'drag']\n",
      "VALUE: 1.6666666666666667\n",
      "['button' 'icons' 'buttons' 'icon' 'hop' 'lets' 'chat' 'armenian' 'ping'\n",
      " 'remote']\n",
      "VALUE: 2.2222222222222223\n",
      "['button' 'icons' 'buttons' 'icon' 'hop' 'lets' 'chat' 'aol' 'armenian'\n",
      " 'ping']\n",
      "VALUE: 2.7777777777777777\n",
      "['button' 'icons' 'icon' 'buttons' 'hop' 'lets' 'chat' 'aol' 'settings'\n",
      " 'flash']\n",
      "VALUE: 3.3333333333333335\n",
      "['button' 'icons' 'icon' 'hop' 'buttons' 'aol' 'flash' 'lets' 'baltic'\n",
      " 'chat']\n",
      "VALUE: 3.8888888888888893\n",
      "['button' 'icons' 'icon' 'hop' 'buttons' 'aol' 'baltic' 'flash' 'lets'\n",
      " 'instantly']\n",
      "VALUE: 4.444444444444445\n",
      "['button' 'icons' 'icon' 'hop' 'buttons' 'aol' 'baltic' 'flash' 'spinning'\n",
      " 'instantly']\n",
      "VALUE: 5.0\n",
      "['button' 'icons' 'icon' 'aol' 'hop' 'buttons' 'baltic' 'flash' 'spinning'\n",
      " 'instantly']\n"
     ]
    }
   ],
   "source": [
    "decode_words(\"remote\", 777, train_w2v_embed, train_w2v_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORD: internet\n",
      "503\n",
      "VALUE: 0.0\n",
      "['musicians' 'artists' 'ensembles' 'concerts' 'bands' 'pianist'\n",
      " 'violinist' 'composers' 'music' 'dancers']\n",
      "VALUE: 0.5555555555555556\n",
      "['musicians' 'artists' 'concerts' 'music' 'bands' 'musician' 'ensembles'\n",
      " 'composers' 'pianist' 'painters']\n",
      "VALUE: 1.1111111111111112\n",
      "['artists' 'musicians' 'music' 'musician' 'bands' 'concerts' 'galleries'\n",
      " 'gigs' 'painters' 'folk']\n",
      "VALUE: 1.6666666666666667\n",
      "['artists' 'musicians' 'websites' 'music' 'blogs' 'galleries'\n",
      " 'contemporary' 'surf' 'musician' 'surfing']\n",
      "VALUE: 2.2222222222222223\n",
      "['artists' 'websites' 'blogs' 'contemporary' 'surf' 'chat' 'galleries'\n",
      " 'surfing' 'music' 'musicians']\n",
      "VALUE: 2.7777777777777777\n",
      "['chat' 'websites' 'blogs' 'surf' 'artists' 'contemporary' 'hacker'\n",
      " 'surfing' 'galleries' 'myspace']\n",
      "VALUE: 3.3333333333333335\n",
      "['chat' 'blogs' 'surf' 'websites' 'hacker' 'contemporary' 'surfing'\n",
      " 'artists' 'cafe' 'cafes']\n",
      "VALUE: 3.8888888888888893\n",
      "['chat' 'surf' 'blogs' 'hacker' 'websites' 'surfing' 'contemporary' 'cafe'\n",
      " 'cafes' 'myspace']\n",
      "VALUE: 4.444444444444445\n",
      "['chat' 'surf' 'hacker' 'blogs' 'surfing' 'websites' 'cafe' 'contemporary'\n",
      " 'cafes' 'bohemian']\n",
      "VALUE: 5.0\n",
      "['chat' 'hacker' 'surf' 'blogs' 'surfing' 'cafe' 'bohemian' 'cafes'\n",
      " 'websites' 'contemporary']\n"
     ]
    }
   ],
   "source": [
    "decode_words(\"internet\", 995, test_w2v_embed, test_w2v_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORD: internet\n",
      "503\n",
      "VALUE: 0.0\n",
      "['musicians' 'artists' 'ensembles' 'concerts' 'bands' 'pianist'\n",
      " 'violinist' 'composers' 'music' 'dancers']\n",
      "VALUE: 0.5555555555555556\n",
      "['musicians' 'artists' 'concerts' 'ensembles' 'bands' 'music' 'composers'\n",
      " 'band' 'choral' 'folk']\n",
      "VALUE: 1.1111111111111112\n",
      "['musicians' 'music' 'artists' 'concerts' 'bands' 'ensembles' 'band'\n",
      " 'choral' 'rehearsals' 'folk']\n",
      "VALUE: 1.6666666666666667\n",
      "['music' 'musicians' 'concerts' 'bands' 'ensembles' 'artists' 'choral'\n",
      " 'band' 'rehearsals' 'instruments']\n",
      "VALUE: 2.2222222222222223\n",
      "['music' 'musicians' 'ensembles' 'concerts' 'instruments' 'bands' 'choral'\n",
      " 'rehearsals' 'rituals' 'band']\n",
      "VALUE: 2.7777777777777777\n",
      "['music' 'rituals' 'scientific' 'instruments' 'networks' 'ensembles'\n",
      " 'musicians' 'ncaa' 'manipulating' 'choral']\n",
      "VALUE: 3.3333333333333335\n",
      "['music' 'scientific' 'rituals' 'fitzgerald' 'jealous' 'networks' 'ncaa'\n",
      " 'grange' 'manipulating' 'media']\n",
      "VALUE: 3.8888888888888893\n",
      "['music' 'scientific' 'fitzgerald' 'jealous' 'rituals' 'mohammed' 'grange'\n",
      " 'ncaa' 'colbert' 'spencer']\n",
      "VALUE: 4.444444444444445\n",
      "['fitzgerald' 'scientific' 'mohammed' 'colbert' 'jealous' 'spencer'\n",
      " 'hezbollah' 'music' 'facebook' 'political']\n",
      "VALUE: 5.0\n",
      "['fitzgerald' 'colbert' 'mohammed' 'scientific' 'spencer' 'syria'\n",
      " 'hezbollah' 'facebook' 'jealous' 'lebanon']\n"
     ]
    }
   ],
   "source": [
    "decode_words(\"internet\", 555, test_w2v_embed, test_w2v_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORD: internet\n",
      "503\n",
      "VALUE: 0.0\n",
      "['musicians' 'artists' 'ensembles' 'concerts' 'bands' 'pianist'\n",
      " 'violinist' 'composers' 'music' 'dancers']\n",
      "VALUE: 0.5555555555555556\n",
      "['musicians' 'artists' 'ensembles' 'concerts' 'composers' 'dancers'\n",
      " 'comedians' 'pianist' 'music' 'bands']\n",
      "VALUE: 1.1111111111111112\n",
      "['musicians' 'artists' 'blogs' 'comedians' 'composers' 'concerts'\n",
      " 'ensembles' 'performances' 'ambassadors' 'canucks']\n",
      "VALUE: 1.6666666666666667\n",
      "['blogs' 'website' 'blog' 'twitter' 'comedians' 'musicians' 'journalists'\n",
      " 'websites' 'ambassadors' 'eurovision']\n",
      "VALUE: 2.2222222222222223\n",
      "['blogs' 'blog' 'website' 'websites' 'twitter' 'commentaries' 'facebook'\n",
      " 'journalists' 'newspapers' 'gossip']\n",
      "VALUE: 2.7777777777777777\n",
      "['blogs' 'blog' 'twitter' 'websites' 'website' 'commentaries' 'facebook'\n",
      " 'newspapers' 'gossip' 'journalists']\n",
      "VALUE: 3.3333333333333335\n",
      "['blogs' 'blog' 'twitter' 'websites' 'website' 'commentaries' 'facebook'\n",
      " 'newspapers' 'gossip' 'columns']\n",
      "VALUE: 3.8888888888888893\n",
      "['blogs' 'blog' 'twitter' 'websites' 'website' 'facebook' 'commentaries'\n",
      " 'newspapers' 'gossip' 'columns']\n",
      "VALUE: 4.444444444444445\n",
      "['blogs' 'blog' 'twitter' 'websites' 'website' 'facebook' 'commentaries'\n",
      " 'newspapers' 'columns' 'gossip']\n",
      "VALUE: 5.0\n",
      "['blogs' 'blog' 'twitter' 'websites' 'facebook' 'website' 'commentaries'\n",
      " 'columns' 'gossip' 'newspapers']\n"
     ]
    }
   ],
   "source": [
    "decode_words(\"internet\", 76, test_w2v_embed, test_w2v_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wordnet domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_16 (InputLayer)           (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_17 (InputLayer)           (None, 169)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 469)          0           input_16[0][0]                   \n",
      "                                                                 input_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 128)          60160       concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 75)           9675        dense_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 75)           9675        dense_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 75)           0           dense_27[0][0]                   \n",
      "                                                                 dense_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 244)          0           lambda_6[0][0]                   \n",
      "                                                                 input_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 128)          31360       concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 300)          38700       dense_29[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 149,570\n",
      "Trainable params: 149,570\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 12000 samples, validate on 3000 samples\n",
      "Epoch 1/50\n",
      " - 4s - loss: 0.0342 - val_loss: 0.0304\n",
      "Epoch 2/50\n",
      " - 3s - loss: 0.0302 - val_loss: 0.0302\n",
      "Epoch 3/50\n",
      " - 3s - loss: 0.0302 - val_loss: 0.0302\n",
      "Epoch 4/50\n",
      " - 2s - loss: 0.0301 - val_loss: 0.0301\n",
      "Epoch 5/50\n",
      " - 2s - loss: 0.0300 - val_loss: 0.0300\n",
      "Epoch 6/50\n",
      " - 2s - loss: 0.0300 - val_loss: 0.0300\n",
      "Epoch 7/50\n",
      " - 2s - loss: 0.0299 - val_loss: 0.0299\n",
      "Epoch 8/50\n",
      " - 2s - loss: 0.0299 - val_loss: 0.0299\n",
      "Epoch 9/50\n",
      " - 2s - loss: 0.0298 - val_loss: 0.0298\n",
      "Epoch 10/50\n",
      " - 2s - loss: 0.0298 - val_loss: 0.0298\n",
      "Epoch 11/50\n",
      " - 2s - loss: 0.0297 - val_loss: 0.0298\n",
      "Epoch 12/50\n",
      " - 2s - loss: 0.0297 - val_loss: 0.0297\n",
      "Epoch 13/50\n",
      " - 2s - loss: 0.0297 - val_loss: 0.0297\n",
      "Epoch 14/50\n",
      " - 2s - loss: 0.0296 - val_loss: 0.0297\n",
      "Epoch 15/50\n",
      " - 2s - loss: 0.0296 - val_loss: 0.0296\n",
      "Epoch 16/50\n",
      " - 2s - loss: 0.0296 - val_loss: 0.0296\n",
      "Epoch 17/50\n",
      " - 2s - loss: 0.0295 - val_loss: 0.0296\n",
      "Epoch 18/50\n",
      " - 2s - loss: 0.0295 - val_loss: 0.0296\n",
      "Epoch 19/50\n",
      " - 2s - loss: 0.0295 - val_loss: 0.0295\n",
      "Epoch 20/50\n",
      " - 2s - loss: 0.0295 - val_loss: 0.0295\n",
      "Epoch 21/50\n",
      " - 3s - loss: 0.0294 - val_loss: 0.0295\n",
      "Epoch 22/50\n",
      " - 2s - loss: 0.0294 - val_loss: 0.0295\n",
      "Epoch 23/50\n",
      " - 3s - loss: 0.0294 - val_loss: 0.0295\n",
      "Epoch 24/50\n",
      " - 3s - loss: 0.0294 - val_loss: 0.0295\n",
      "Epoch 25/50\n",
      " - 2s - loss: 0.0294 - val_loss: 0.0295\n",
      "Epoch 26/50\n",
      " - 2s - loss: 0.0294 - val_loss: 0.0294\n",
      "Epoch 27/50\n",
      " - 3s - loss: 0.0294 - val_loss: 0.0294\n",
      "Epoch 28/50\n",
      " - 2s - loss: 0.0294 - val_loss: 0.0294\n",
      "Epoch 29/50\n",
      " - 2s - loss: 0.0293 - val_loss: 0.0294\n",
      "Epoch 30/50\n",
      " - 2s - loss: 0.0293 - val_loss: 0.0294\n",
      "Epoch 31/50\n",
      " - 2s - loss: 0.0293 - val_loss: 0.0294\n",
      "Epoch 32/50\n",
      " - 2s - loss: 0.0293 - val_loss: 0.0294\n",
      "Epoch 33/50\n",
      " - 2s - loss: 0.0293 - val_loss: 0.0294\n",
      "Epoch 34/50\n",
      " - 2s - loss: 0.0293 - val_loss: 0.0294\n",
      "Epoch 35/50\n",
      " - 2s - loss: 0.0293 - val_loss: 0.0294\n",
      "Epoch 36/50\n",
      " - 3s - loss: 0.0293 - val_loss: 0.0294\n",
      "Epoch 37/50\n",
      " - 3s - loss: 0.0293 - val_loss: 0.0294\n",
      "Epoch 38/50\n",
      " - 3s - loss: 0.0293 - val_loss: 0.0294\n",
      "Epoch 39/50\n",
      " - 2s - loss: 0.0293 - val_loss: 0.0294\n",
      "Epoch 40/50\n",
      " - 3s - loss: 0.0293 - val_loss: 0.0294\n",
      "Epoch 41/50\n",
      " - 2s - loss: 0.0293 - val_loss: 0.0294\n",
      "Epoch 42/50\n",
      " - 2s - loss: 0.0292 - val_loss: 0.0294\n",
      "Epoch 43/50\n",
      " - 2s - loss: 0.0292 - val_loss: 0.0294\n",
      "Epoch 44/50\n",
      " - 2s - loss: 0.0292 - val_loss: 0.0294\n",
      "Epoch 45/50\n",
      " - 3s - loss: 0.0292 - val_loss: 0.0294\n",
      "Epoch 46/50\n",
      " - 2s - loss: 0.0292 - val_loss: 0.0294\n",
      "Epoch 47/50\n",
      " - 2s - loss: 0.0292 - val_loss: 0.0294\n",
      "Epoch 48/50\n",
      " - 2s - loss: 0.0292 - val_loss: 0.0294\n",
      "Epoch 49/50\n",
      " - 3s - loss: 0.0292 - val_loss: 0.0293\n",
      "Epoch 50/50\n",
      " - 2s - loss: 0.0292 - val_loss: 0.0293\n"
     ]
    }
   ],
   "source": [
    "### PARAMETERS ###\n",
    "decoder_out_dim = train_w2v_embed.shape[1] # dim of decoder output layer\n",
    "n_x = train_w2v_embed.shape[1]\n",
    "n_y = w2v_train_wordnet_cond_matrix_df.shape[1]\n",
    "train_embed = train_w2v_embed\n",
    "train_word = w2v_train_wordnet_cond_matrix_df\n",
    "test_embed = test_w2v_embed\n",
    "test_word = w2v_test_wordnet_cond_matrix_df\n",
    "### PARAMETERS ###\n",
    "\n",
    "# define encoder\n",
    "X = Input(shape=(n_x,))\n",
    "label = Input(shape=(n_y,))\n",
    "inputs = concat([X, label])\n",
    "encoder_h = Dense(encoder_dim1, activation=activ)(inputs)\n",
    "mu = Dense(n_z, activation='linear')(encoder_h)\n",
    "l_sigma = Dense(n_z, activation='linear')(encoder_h)\n",
    "\n",
    "# sample latent space\n",
    "z = Lambda(sample_z, output_shape = (n_z, ))([mu, l_sigma])\n",
    "zc = concat([z, label])\n",
    "\n",
    "# decoder\n",
    "decoder_hidden = Dense(decoder_dim, activation=activ)\n",
    "decoder_out = Dense(decoder_out_dim, activation='sigmoid')\n",
    "h_p = decoder_hidden(zc)\n",
    "outputs = decoder_out(h_p)\n",
    "\n",
    "# define graphs\n",
    "cvae = Model([X, label], outputs)\n",
    "encoder = Model([X, label], mu)\n",
    "d_in = Input(shape=(n_z+n_y,))\n",
    "d_h = decoder_hidden(d_in)\n",
    "d_out = decoder_out(d_h)\n",
    "decoder = Model(d_in, d_out)\n",
    "\n",
    "# print statistics\n",
    "cvae.compile(optimizer=optim, loss=vae_loss)\n",
    "\n",
    "cvae.summary()\n",
    "\n",
    "cvae_hist = cvae.fit([train_embed, train_word], train_embed, verbose = 2, batch_size=m, \n",
    "                 epochs=n_epoch,\n",
    "                 validation_data = ([test_embed, test_word], test_embed),\n",
    "                 callbacks = [EarlyStopping(patience = 5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(sum(train_w2v_token == \"mathematics\"))\n",
    "print(sum(test_w2v_token == \"mathematics\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acoustics</th>\n",
       "      <th>administration</th>\n",
       "      <th>agriculture</th>\n",
       "      <th>anatomy</th>\n",
       "      <th>animal_husbandry</th>\n",
       "      <th>animals</th>\n",
       "      <th>anthropology</th>\n",
       "      <th>applied_science</th>\n",
       "      <th>archaeology</th>\n",
       "      <th>archery</th>\n",
       "      <th>...</th>\n",
       "      <th>time_period</th>\n",
       "      <th>topography</th>\n",
       "      <th>tourism</th>\n",
       "      <th>town_planning</th>\n",
       "      <th>transport</th>\n",
       "      <th>university</th>\n",
       "      <th>vehicles</th>\n",
       "      <th>veterinary</th>\n",
       "      <th>volleyball</th>\n",
       "      <th>wrestling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>framework</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dancing</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>needy</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>algae</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missions</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 169 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           acoustics  administration  agriculture  anatomy  animal_husbandry  \\\n",
       "framework          0               0            0        0                 0   \n",
       "dancing            0               0            0        0                 0   \n",
       "needy              0               0            0        0                 0   \n",
       "algae              0               0            0        0                 0   \n",
       "missions           0               0            0        0                 0   \n",
       "\n",
       "           animals  anthropology  applied_science  archaeology  archery  \\\n",
       "framework        0             0                0            0        0   \n",
       "dancing          0             0                0            0        0   \n",
       "needy            0             0                0            0        0   \n",
       "algae            0             0                0            0        0   \n",
       "missions         0             0                0            0        0   \n",
       "\n",
       "             ...      time_period  topography  tourism  town_planning  \\\n",
       "framework    ...                0           0        0              0   \n",
       "dancing      ...                0           0        0              0   \n",
       "needy        ...                0           0        0              0   \n",
       "algae        ...                0           0        0              0   \n",
       "missions     ...                0           0        0              0   \n",
       "\n",
       "           transport  university  vehicles  veterinary  volleyball  wrestling  \n",
       "framework          0           0         0           0           0          0  \n",
       "dancing            0           0         0           0           0          0  \n",
       "needy              0           0         0           0           0          0  \n",
       "algae              0           0         0           0           0          0  \n",
       "missions           0           0         0           0           0          0  \n",
       "\n",
       "[5 rows x 169 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_train_wordnet_cond_matrix_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(np.array(wordnet_cond_label) == 'computer_science')[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ORG'"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities_labels[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(np.array(entities_labels) == 'PRODUCT')[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NOUN'"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_labels[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(np.array(sentiment_labels) == 'compound')[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg', 'neu', 'pos', 'compound']"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_top_words(train_w2v_embed, train_w2v_token, test_w2v_embed, test_w2v_token, train_word_embed, embed_type, cond_type):\n",
    "    words = [\"mathematics\", \"remote\", \"internet\"]\n",
    "    if embed_type == \"word2vec\" and cond_type == \"spine\":\n",
    "        dimensions = [[954,427,206],[948,473,777],[995,555,400]]\n",
    "    elif embed_type == \"glove\" and cond_type == \"spine\":\n",
    "        dimensions = [[635,486,513],[873,793,484],[737,403,125]]\n",
    "    elif cond_type == \"wordnet\":\n",
    "        dimensions = [[89], [17, 90, 94], [37]]\n",
    "    elif cond_type == \"pos\":\n",
    "        dimensions = [[8],[0, 8],[8]]\n",
    "    elif cond_type == \"entity\":\n",
    "        dimensions = [[5, 6, 10],[5, 6],[2, 3, 5, 6]]\n",
    "    elif cond_type == \"sentiment\":\n",
    "        dimensions = [[0,1,2,3], [0,1,2,3], [0,1,2,3]]\n",
    "    else:\n",
    "        print(\"error\")\n",
    "    for index in range(len(words)):\n",
    "        for d in dimensions[index]:\n",
    "            if sum(train_w2v_token == words[index]) == 1:\n",
    "                decode_words(words[index], d, train_w2v_embed, train_w2v_token, train_word_embed, cond_type)\n",
    "            else:\n",
    "                decode_words(words[index], d, test_w2v_embed, test_w2v_token, train_word_embed, cond_type)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORD: mathematics\n",
      "11730\n",
      "VALUE: 0.0\n",
      "(169,)\n",
      "['nikki' 'whitman' 'lindsey' 'greer' 'mcmahon' 'rupert' 'colbert'\n",
      " 'catholicism' 'hyde' 'williamson']\n",
      "VALUE: 0.5555555555555556\n",
      "(169,)\n",
      "['nikki' 'whitman' 'lindsey' 'greer' 'mcmahon' 'rupert' 'colbert'\n",
      " 'catholicism' 'hyde' 'williamson']\n",
      "VALUE: 1.1111111111111112\n",
      "(169,)\n",
      "['calculation' 'variables' 'logic' 'strategy' 'hypothetical'\n",
      " 'calculations' 'calculating' 'equals' 'mathematical' 'calculated']\n",
      "VALUE: 1.6666666666666667\n",
      "(169,)\n",
      "['calculation' 'variables' 'logic' 'strategy' 'hypothetical'\n",
      " 'calculations' 'calculating' 'equals' 'mathematical' 'calculated']\n",
      "VALUE: 2.2222222222222223\n",
      "(169,)\n",
      "['calculation' 'variables' 'logic' 'methodology' 'calculations'\n",
      " 'measurement' 'parameter' 'parameters' 'algorithms' 'mathematical']\n",
      "VALUE: 2.7777777777777777\n",
      "(169,)\n",
      "['calculation' 'variables' 'logic' 'methodology' 'calculations'\n",
      " 'measurement' 'parameter' 'parameters' 'algorithms' 'mathematical']\n",
      "VALUE: 3.3333333333333335\n",
      "(169,)\n",
      "['calculation' 'methodology' 'parameter' 'parameters' 'algorithms' 'logic'\n",
      " 'variables' 'measurement' 'calculations' 'algorithm']\n",
      "VALUE: 3.8888888888888893\n",
      "(169,)\n",
      "['calculation' 'methodology' 'parameter' 'parameters' 'algorithms' 'logic'\n",
      " 'variables' 'measurement' 'calculations' 'algorithm']\n",
      "VALUE: 4.444444444444445\n",
      "(169,)\n",
      "['calculation' 'methodology' 'parameter' 'parameters' 'algorithms'\n",
      " 'algorithm' 'logic' 'interfaces' 'conversion' 'synthesis']\n",
      "VALUE: 5.0\n",
      "(169,)\n",
      "['calculation' 'parameter' 'methodology' 'parameters' 'algorithms'\n",
      " 'interfaces' 'synthesis' 'algorithm' 'conversion' 'computational']\n",
      "WORD: remote\n",
      "7807\n",
      "VALUE: 0.0\n",
      "(169,)\n",
      "['torpedo' 'warships' 'torpedoes' 'soldiers' 'drag' 'marines' 'navy'\n",
      " 'warship' 'artillery' 'troops']\n",
      "VALUE: 0.5555555555555556\n",
      "(169,)\n",
      "['torpedo' 'warships' 'torpedoes' 'soldiers' 'drag' 'marines' 'navy'\n",
      " 'warship' 'artillery' 'troops']\n",
      "VALUE: 1.1111111111111112\n",
      "(169,)\n",
      "['grenade' 'unarmed' 'rifle' 'pistol' 'drag' 'murder' 'killings' 'fishing'\n",
      " 'ambush' 'explosives']\n",
      "VALUE: 1.6666666666666667\n",
      "(169,)\n",
      "['grenade' 'unarmed' 'rifle' 'pistol' 'drag' 'murder' 'killings' 'fishing'\n",
      " 'ambush' 'explosives']\n",
      "VALUE: 2.2222222222222223\n",
      "(169,)\n",
      "['grenade' 'murder' 'explosives' 'bomb' 'murdering' 'suicide' 'murders'\n",
      " 'murdered' 'killings' 'bombs']\n",
      "VALUE: 2.7777777777777777\n",
      "(169,)\n",
      "['grenade' 'murder' 'explosives' 'bomb' 'murdering' 'suicide' 'murders'\n",
      " 'murdered' 'killings' 'bombs']\n",
      "VALUE: 3.3333333333333335\n",
      "(169,)\n",
      "['grenade' 'murder' 'explosives' 'suicide' 'murdering' 'bomb' 'murders'\n",
      " 'bombs' 'murdered' 'killings']\n",
      "VALUE: 3.8888888888888893\n",
      "(169,)\n",
      "['grenade' 'murder' 'explosives' 'suicide' 'murdering' 'bomb' 'murders'\n",
      " 'bombs' 'murdered' 'killings']\n",
      "VALUE: 4.444444444444445\n",
      "(169,)\n",
      "['grenade' 'murder' 'suicide' 'explosives' 'murdering' 'bomb' 'bombs'\n",
      " 'murders' 'murdered' 'wounding']\n",
      "VALUE: 5.0\n",
      "(169,)\n",
      "['grenade' 'murder' 'suicide' 'explosives' 'murdering' 'bomb' 'bombs'\n",
      " 'murders' 'murdered' 'pointing']\n",
      "WORD: remote\n",
      "7807\n",
      "VALUE: 0.0\n",
      "(169,)\n",
      "['grenade' 'murder' 'murdering' 'rifle' 'murdered' 'explosives' 'bombs'\n",
      " 'civilians' 'bomb' 'unarmed']\n",
      "VALUE: 0.5555555555555556\n",
      "(169,)\n",
      "['grenade' 'murder' 'murdering' 'rifle' 'murdered' 'explosives' 'bombs'\n",
      " 'civilians' 'bomb' 'unarmed']\n",
      "VALUE: 1.1111111111111112\n",
      "(169,)\n",
      "['grenade' 'unarmed' 'rifle' 'pistol' 'drag' 'murder' 'killings' 'fishing'\n",
      " 'ambush' 'explosives']\n",
      "VALUE: 1.6666666666666667\n",
      "(169,)\n",
      "['grenade' 'unarmed' 'rifle' 'pistol' 'drag' 'murder' 'killings' 'fishing'\n",
      " 'ambush' 'explosives']\n",
      "VALUE: 2.2222222222222223\n",
      "(169,)\n",
      "['drag' 'torpedo' 'gear' 'propeller' 'gears' 'grenade' 'turbo' 'pistol'\n",
      " 'fishing' 'unarmed']\n",
      "VALUE: 2.7777777777777777\n",
      "(169,)\n",
      "['drag' 'torpedo' 'gear' 'propeller' 'gears' 'grenade' 'turbo' 'pistol'\n",
      " 'fishing' 'unarmed']\n",
      "VALUE: 3.3333333333333335\n",
      "(169,)\n",
      "['pedal' 'turbo' 'gears' 'gear' 'propeller' 'torpedo' 'drag' 'cam' 'motor'\n",
      " 'modem']\n",
      "VALUE: 3.8888888888888893\n",
      "(169,)\n",
      "['pedal' 'turbo' 'gears' 'gear' 'propeller' 'torpedo' 'drag' 'cam' 'motor'\n",
      " 'modem']\n",
      "VALUE: 4.444444444444445\n",
      "(169,)\n",
      "['pedal' 'turbo' 'cam' 'gears' 'gear' 'engine' 'twin' 'modem' 'propeller'\n",
      " 'snap']\n",
      "VALUE: 5.0\n",
      "(169,)\n",
      "['pedal' 'turbo' 'cam' 'twin' 'snap' 'screen' 'restart' 'engine' 'gears'\n",
      " 'vent']\n",
      "WORD: remote\n",
      "7807\n",
      "VALUE: 0.0\n",
      "(169,)\n",
      "['drag' 'economic' 'gears' 'currents' 'grenade' 'fishing' 'propeller'\n",
      " 'cable' 'murder' 'television']\n",
      "VALUE: 0.5555555555555556\n",
      "(169,)\n",
      "['drag' 'economic' 'gears' 'currents' 'grenade' 'fishing' 'propeller'\n",
      " 'cable' 'murder' 'television']\n",
      "VALUE: 1.1111111111111112\n",
      "(169,)\n",
      "['grenade' 'unarmed' 'rifle' 'pistol' 'drag' 'murder' 'killings' 'fishing'\n",
      " 'ambush' 'explosives']\n",
      "VALUE: 1.6666666666666667\n",
      "(169,)\n",
      "['grenade' 'unarmed' 'rifle' 'pistol' 'drag' 'murder' 'killings' 'fishing'\n",
      " 'ambush' 'explosives']\n",
      "VALUE: 2.2222222222222223\n",
      "(169,)\n",
      "['grenade' 'unarmed' 'rifle' 'rifles' 'soldiers' 'bullets' 'policemen'\n",
      " 'ambush' 'pistol' 'platoon']\n",
      "VALUE: 2.7777777777777777\n",
      "(169,)\n",
      "['grenade' 'unarmed' 'rifle' 'rifles' 'soldiers' 'bullets' 'policemen'\n",
      " 'ambush' 'pistol' 'platoon']\n",
      "VALUE: 3.3333333333333335\n",
      "(169,)\n",
      "['soldiers' 'platoon' 'marines' 'infantry' 'grenade' 'policemen' 'unarmed'\n",
      " 'battalions' 'comrades' 'rifles']\n",
      "VALUE: 3.8888888888888893\n",
      "(169,)\n",
      "['soldiers' 'platoon' 'marines' 'infantry' 'grenade' 'policemen' 'unarmed'\n",
      " 'battalions' 'comrades' 'rifles']\n",
      "VALUE: 4.444444444444445\n",
      "(169,)\n",
      "['soldiers' 'platoon' 'marines' 'infantry' 'squadron' 'battalions'\n",
      " 'warships' 'comrades' 'convoy' 'policemen']\n",
      "VALUE: 5.0\n",
      "(169,)\n",
      "['squadron' 'soldiers' 'platoon' 'infantry' 'marines' 'battalions'\n",
      " 'warships' 'convoy' 'comrades' 'commandos']\n",
      "WORD: internet\n",
      "503\n",
      "VALUE: 0.0\n",
      "(169,)\n",
      "['cello' 'piano' 'violin' 'pianist' 'melodies' 'saxophone' 'guitar'\n",
      " 'melodic' 'orchestral' 'violinist']\n",
      "VALUE: 0.5555555555555556\n",
      "(169,)\n",
      "['cello' 'piano' 'violin' 'pianist' 'melodies' 'saxophone' 'guitar'\n",
      " 'melodic' 'orchestral' 'violinist']\n",
      "VALUE: 1.1111111111111112\n",
      "(169,)\n",
      "['music' 'motown' 'songs' 'piano' 'eminem' 'carrie' 'lyrics' 'tunes'\n",
      " 'remixes' 'peyton']\n",
      "VALUE: 1.6666666666666667\n",
      "(169,)\n",
      "['music' 'motown' 'songs' 'piano' 'eminem' 'carrie' 'lyrics' 'tunes'\n",
      " 'remixes' 'peyton']\n",
      "VALUE: 2.2222222222222223\n",
      "(169,)\n",
      "['sirius' 'carrie' 'eminem' 'fcc' 'xml' 'hannah' 'eugene' 'ericsson' 'vhs'\n",
      " 'interfaces']\n",
      "VALUE: 2.7777777777777777\n",
      "(169,)\n",
      "['sirius' 'carrie' 'eminem' 'fcc' 'xml' 'hannah' 'eugene' 'ericsson' 'vhs'\n",
      " 'interfaces']\n",
      "VALUE: 3.3333333333333335\n",
      "(169,)\n",
      "['fcc' 'interfaces' 'dalton' 'aol' 'brennan' 'xml' 'ericsson' 'nbc'\n",
      " 'pearson' 'cpu']\n",
      "VALUE: 3.8888888888888893\n",
      "(169,)\n",
      "['fcc' 'interfaces' 'dalton' 'aol' 'brennan' 'xml' 'ericsson' 'nbc'\n",
      " 'pearson' 'cpu']\n",
      "VALUE: 4.444444444444445\n",
      "(169,)\n",
      "['dalton' 'interfaces' 'fcc' 'specification' 'nbc' 'v8' 'aol' 'utilizing'\n",
      " 'brennan' 'xml']\n",
      "VALUE: 5.0\n",
      "(169,)\n",
      "['dalton' 'utilizing' 'specification' 'interfaces' 'v8' 'nbc' 'aol' 'fcc'\n",
      " 'wb' 'configuration']\n"
     ]
    }
   ],
   "source": [
    "find_top_words(train_w2v_embed, train_w2v_token, test_w2v_embed, test_w2v_token, w2v_train_wordnet_cond_matrix_df, \"word2vec\", \"wordnet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_19 (InputLayer)           (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_20 (InputLayer)           (None, 19)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 319)          0           input_19[0][0]                   \n",
      "                                                                 input_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 128)          40960       concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_32 (Dense)                (None, 75)           9675        dense_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_33 (Dense)                (None, 75)           9675        dense_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 75)           0           dense_32[0][0]                   \n",
      "                                                                 dense_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 94)           0           lambda_7[0][0]                   \n",
      "                                                                 input_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_34 (Dense)                (None, 128)          12160       concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_35 (Dense)                (None, 300)          38700       dense_34[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 111,170\n",
      "Trainable params: 111,170\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 12000 samples, validate on 3000 samples\n",
      "Epoch 1/50\n",
      " - 4s - loss: 0.0340 - val_loss: 0.0304\n",
      "Epoch 2/50\n",
      " - 2s - loss: 0.0303 - val_loss: 0.0302\n",
      "Epoch 3/50\n",
      " - 2s - loss: 0.0302 - val_loss: 0.0302\n",
      "Epoch 4/50\n",
      " - 2s - loss: 0.0301 - val_loss: 0.0301\n",
      "Epoch 5/50\n",
      " - 2s - loss: 0.0301 - val_loss: 0.0301\n",
      "Epoch 6/50\n",
      " - 2s - loss: 0.0300 - val_loss: 0.0300\n",
      "Epoch 7/50\n",
      " - 2s - loss: 0.0300 - val_loss: 0.0300\n",
      "Epoch 8/50\n",
      " - 2s - loss: 0.0300 - val_loss: 0.0300\n",
      "Epoch 9/50\n",
      " - 2s - loss: 0.0299 - val_loss: 0.0300\n",
      "Epoch 10/50\n",
      " - 2s - loss: 0.0299 - val_loss: 0.0299\n",
      "Epoch 11/50\n",
      " - 2s - loss: 0.0299 - val_loss: 0.0299\n",
      "Epoch 12/50\n",
      " - 2s - loss: 0.0299 - val_loss: 0.0299\n",
      "Epoch 13/50\n",
      " - 2s - loss: 0.0299 - val_loss: 0.0299\n",
      "Epoch 14/50\n",
      " - 2s - loss: 0.0299 - val_loss: 0.0299\n",
      "Epoch 15/50\n",
      " - 2s - loss: 0.0299 - val_loss: 0.0299\n",
      "Epoch 16/50\n",
      " - 2s - loss: 0.0298 - val_loss: 0.0299\n",
      "Epoch 17/50\n",
      " - 2s - loss: 0.0298 - val_loss: 0.0299\n",
      "Epoch 18/50\n",
      " - 2s - loss: 0.0298 - val_loss: 0.0299\n",
      "Epoch 19/50\n",
      " - 2s - loss: 0.0298 - val_loss: 0.0299\n",
      "Epoch 20/50\n",
      " - 2s - loss: 0.0298 - val_loss: 0.0298\n",
      "Epoch 21/50\n",
      " - 2s - loss: 0.0298 - val_loss: 0.0298\n",
      "Epoch 22/50\n",
      " - 2s - loss: 0.0298 - val_loss: 0.0298\n",
      "Epoch 23/50\n",
      " - 2s - loss: 0.0298 - val_loss: 0.0298\n",
      "Epoch 24/50\n",
      " - 2s - loss: 0.0298 - val_loss: 0.0298\n",
      "Epoch 25/50\n",
      " - 2s - loss: 0.0298 - val_loss: 0.0298\n",
      "Epoch 26/50\n",
      " - 2s - loss: 0.0298 - val_loss: 0.0298\n",
      "Epoch 27/50\n",
      " - 2s - loss: 0.0298 - val_loss: 0.0298\n",
      "Epoch 28/50\n",
      " - 2s - loss: 0.0298 - val_loss: 0.0298\n",
      "Epoch 29/50\n",
      " - 2s - loss: 0.0298 - val_loss: 0.0298\n",
      "Epoch 30/50\n",
      " - 2s - loss: 0.0298 - val_loss: 0.0298\n",
      "Epoch 31/50\n",
      " - 2s - loss: 0.0298 - val_loss: 0.0298\n",
      "Epoch 32/50\n",
      " - 2s - loss: 0.0298 - val_loss: 0.0298\n",
      "Epoch 33/50\n",
      " - 2s - loss: 0.0298 - val_loss: 0.0298\n",
      "Epoch 34/50\n",
      " - 2s - loss: 0.0298 - val_loss: 0.0298\n",
      "Epoch 35/50\n",
      " - 2s - loss: 0.0298 - val_loss: 0.0298\n",
      "Epoch 36/50\n",
      " - 2s - loss: 0.0298 - val_loss: 0.0298\n",
      "Epoch 37/50\n",
      " - 2s - loss: 0.0298 - val_loss: 0.0298\n",
      "Epoch 38/50\n",
      " - 2s - loss: 0.0298 - val_loss: 0.0298\n",
      "Epoch 39/50\n",
      " - 2s - loss: 0.0298 - val_loss: 0.0298\n",
      "Epoch 40/50\n",
      " - 2s - loss: 0.0298 - val_loss: 0.0298\n",
      "Epoch 41/50\n",
      " - 2s - loss: 0.0298 - val_loss: 0.0298\n",
      "Epoch 42/50\n",
      " - 2s - loss: 0.0298 - val_loss: 0.0298\n",
      "Epoch 43/50\n",
      " - 2s - loss: 0.0298 - val_loss: 0.0298\n",
      "Epoch 44/50\n",
      " - 2s - loss: 0.0298 - val_loss: 0.0298\n",
      "Epoch 45/50\n",
      " - 2s - loss: 0.0298 - val_loss: 0.0298\n",
      "Epoch 46/50\n",
      " - 2s - loss: 0.0298 - val_loss: 0.0298\n",
      "Epoch 47/50\n",
      " - 2s - loss: 0.0298 - val_loss: 0.0298\n",
      "Epoch 48/50\n",
      " - 2s - loss: 0.0298 - val_loss: 0.0298\n",
      "Epoch 49/50\n",
      " - 2s - loss: 0.0298 - val_loss: 0.0298\n",
      "Epoch 50/50\n",
      " - 2s - loss: 0.0298 - val_loss: 0.0298\n"
     ]
    }
   ],
   "source": [
    "### PARAMETERS ###\n",
    "decoder_out_dim = train_w2v_embed.shape[1] # dim of decoder output layer\n",
    "n_x = train_w2v_embed.shape[1]\n",
    "n_y = w2v_train_pos_cond_matrix_df.shape[1]\n",
    "train_embed = train_w2v_embed\n",
    "train_word = w2v_train_pos_cond_matrix_df\n",
    "test_embed = test_w2v_embed\n",
    "test_word = w2v_test_pos_cond_matrix_df\n",
    "### PARAMETERS ###\n",
    "\n",
    "# define encoder\n",
    "X = Input(shape=(n_x,))\n",
    "label = Input(shape=(n_y,))\n",
    "inputs = concat([X, label])\n",
    "encoder_h = Dense(encoder_dim1, activation=activ)(inputs)\n",
    "mu = Dense(n_z, activation='linear')(encoder_h)\n",
    "l_sigma = Dense(n_z, activation='linear')(encoder_h)\n",
    "\n",
    "# sample latent space\n",
    "z = Lambda(sample_z, output_shape = (n_z, ))([mu, l_sigma])\n",
    "zc = concat([z, label])\n",
    "\n",
    "# decoder\n",
    "decoder_hidden = Dense(decoder_dim, activation=activ)\n",
    "decoder_out = Dense(decoder_out_dim, activation='sigmoid')\n",
    "h_p = decoder_hidden(zc)\n",
    "outputs = decoder_out(h_p)\n",
    "\n",
    "# define graphs\n",
    "cvae = Model([X, label], outputs)\n",
    "encoder = Model([X, label], mu)\n",
    "d_in = Input(shape=(n_z+n_y,))\n",
    "d_h = decoder_hidden(d_in)\n",
    "d_out = decoder_out(d_h)\n",
    "decoder = Model(d_in, d_out)\n",
    "\n",
    "# print statistics\n",
    "cvae.compile(optimizer=optim, loss=vae_loss)\n",
    "\n",
    "cvae.summary()\n",
    "\n",
    "cvae_hist = cvae.fit([train_embed, train_word], train_embed, verbose = 2, batch_size=m, \n",
    "                 epochs=n_epoch,\n",
    "                 validation_data = ([test_embed, test_word], test_embed),\n",
    "                 callbacks = [EarlyStopping(patience = 5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORD: mathematics\n",
      "11730\n",
      "VALUE: 0.0\n",
      "(19,)\n",
      "['lindsey' 'nikki' 'arnold' 'armstrong' 'meyers' 'williamson' 'pete'\n",
      " 'nigel' 'gerald' 'carlson']\n",
      "VALUE: 0.5555555555555556\n",
      "(19,)\n",
      "['lindsey' 'nikki' 'arnold' 'armstrong' 'meyers' 'williamson' 'pete'\n",
      " 'nigel' 'gerald' 'carlson']\n",
      "VALUE: 1.1111111111111112\n",
      "(19,)\n",
      "['colbert' 'nikki' 'arnold' 'rupert' 'williamson' 'lindsey' 'mcmahon'\n",
      " 'norman' 'greer' 'pete']\n",
      "VALUE: 1.6666666666666667\n",
      "(19,)\n",
      "['colbert' 'nikki' 'arnold' 'rupert' 'williamson' 'lindsey' 'mcmahon'\n",
      " 'norman' 'greer' 'pete']\n",
      "VALUE: 2.2222222222222223\n",
      "(19,)\n",
      "['catholicism' 'colbert' 'filipinos' 'rupert' 'debates' 'bills'\n",
      " 'politicians' 'teachings' 'buddha' 'stories']\n",
      "VALUE: 2.7777777777777777\n",
      "(19,)\n",
      "['catholicism' 'colbert' 'filipinos' 'rupert' 'debates' 'bills'\n",
      " 'politicians' 'teachings' 'buddha' 'stories']\n",
      "VALUE: 3.3333333333333335\n",
      "(19,)\n",
      "['legislators' 'bills' 'politicians' 'polls' 'pornography' 'auctions'\n",
      " 'teachings' 'proposals' 'legislature' 'debates']\n",
      "VALUE: 3.8888888888888893\n",
      "(19,)\n",
      "['legislators' 'bills' 'politicians' 'polls' 'pornography' 'auctions'\n",
      " 'teachings' 'proposals' 'legislature' 'debates']\n",
      "VALUE: 4.444444444444445\n",
      "(19,)\n",
      "['legislators' 'auctions' 'polls' 'reports' 'pornography' 'gasoline'\n",
      " 'items' 'automobiles' 'bicycles' 'belongings']\n",
      "VALUE: 5.0\n",
      "(19,)\n",
      "['auctions' 'legislators' 'reports' 'luggage' 'motorcycles' 'bicycles'\n",
      " 'inspections' 'automobiles' 'polls' 'authorities']\n",
      "WORD: remote\n",
      "7807\n",
      "VALUE: 0.0\n",
      "(19,)\n",
      "['nikki' 'greer' 'colbert' 'mcmahon' 'lindsey' 'carlson' 'williamson'\n",
      " 'peyton' 'jonas' 'whitman']\n",
      "VALUE: 0.5555555555555556\n",
      "(19,)\n",
      "['nikki' 'greer' 'colbert' 'mcmahon' 'lindsey' 'carlson' 'williamson'\n",
      " 'peyton' 'jonas' 'whitman']\n",
      "VALUE: 1.1111111111111112\n",
      "(19,)\n",
      "['foolish' 'cynical' 'absurd' 'painful' 'peculiar' 'silly' 'embarrassing'\n",
      " 'logical' 'disastrous' 'problematic']\n",
      "VALUE: 1.6666666666666667\n",
      "(19,)\n",
      "['foolish' 'cynical' 'absurd' 'painful' 'peculiar' 'silly' 'embarrassing'\n",
      " 'logical' 'disastrous' 'problematic']\n",
      "VALUE: 2.2222222222222223\n",
      "(19,)\n",
      "['cynical' 'absurd' 'foolish' 'problematic' 'painful' 'logical' 'unhappy'\n",
      " 'embarrassing' 'unacceptable' 'noteworthy']\n",
      "VALUE: 2.7777777777777777\n",
      "(19,)\n",
      "['cynical' 'absurd' 'foolish' 'problematic' 'painful' 'logical' 'unhappy'\n",
      " 'embarrassing' 'unacceptable' 'noteworthy']\n",
      "VALUE: 3.3333333333333335\n",
      "(19,)\n",
      "['cynical' 'blunt' 'unacceptable' 'likely' 'absurd' 'unhappy'\n",
      " 'problematic' 'noteworthy' 'reluctant' 'shocking']\n",
      "VALUE: 3.8888888888888893\n",
      "(19,)\n",
      "['cynical' 'blunt' 'unacceptable' 'likely' 'absurd' 'unhappy'\n",
      " 'problematic' 'noteworthy' 'reluctant' 'shocking']\n",
      "VALUE: 4.444444444444445\n",
      "(19,)\n",
      "['blunt' 'cynical' 'undoubtedly' 'unacceptable' 'harsh' 'likely'\n",
      " 'profound' 'shocking' 'recent' 'generous']\n",
      "VALUE: 5.0\n",
      "(19,)\n",
      "['blunt' 'undoubtedly' 'importantly' 'highlighted' 'harsh' 'unacceptable'\n",
      " 'cynical' 'profound' 'illustrate' 'generous']\n",
      "WORD: remote\n",
      "7807\n",
      "VALUE: 0.0\n",
      "(19,)\n",
      "['foolish' 'cynical' 'absurd' 'painful' 'peculiar' 'silly' 'embarrassing'\n",
      " 'logical' 'disastrous' 'problematic']\n",
      "VALUE: 0.5555555555555556\n",
      "(19,)\n",
      "['foolish' 'cynical' 'absurd' 'painful' 'peculiar' 'silly' 'embarrassing'\n",
      " 'logical' 'disastrous' 'problematic']\n",
      "VALUE: 1.1111111111111112\n",
      "(19,)\n",
      "['painful' 'cynical' 'unhappy' 'disastrous' 'deliberate' 'costly' 'sad'\n",
      " 'unacceptable' 'grim' 'embarrassing']\n",
      "VALUE: 1.6666666666666667\n",
      "(19,)\n",
      "['painful' 'cynical' 'unhappy' 'disastrous' 'deliberate' 'costly' 'sad'\n",
      " 'unacceptable' 'grim' 'embarrassing']\n",
      "VALUE: 2.2222222222222223\n",
      "(19,)\n",
      "['legislators' 'randolph' 'groups' 'samuel' 'costly' 'leroy' 'holland'\n",
      " 'jacob' 'increasingly' 'gasoline']\n",
      "VALUE: 2.7777777777777777\n",
      "(19,)\n",
      "['legislators' 'randolph' 'groups' 'samuel' 'costly' 'leroy' 'holland'\n",
      " 'jacob' 'increasingly' 'gasoline']\n",
      "VALUE: 3.3333333333333335\n",
      "(19,)\n",
      "['jacob' 'andre' 'rodney' 'samuel' 'felix' 'bailey' 'leroy' 'ricky'\n",
      " 'sheffield' 'forrest']\n",
      "VALUE: 3.8888888888888893\n",
      "(19,)\n",
      "['jacob' 'andre' 'rodney' 'samuel' 'felix' 'bailey' 'leroy' 'ricky'\n",
      " 'sheffield' 'forrest']\n",
      "VALUE: 4.444444444444445\n",
      "(19,)\n",
      "['jacob' 'forrest' 'rodney' 'andre' 'felix' 'sheffield' 'bailey' 'angeles'\n",
      " 'bernard' 'lewis']\n",
      "VALUE: 5.0\n",
      "(19,)\n",
      "['jacob' 'forrest' 'rodney' 'andre' 'sheffield' 'felix' 'angeles'\n",
      " 'bernard' 'pollard' 'southampton']\n",
      "WORD: internet\n",
      "503\n",
      "VALUE: 0.0\n",
      "(19,)\n",
      "['nikki' 'greer' 'colbert' 'mcmahon' 'lindsey' 'carlson' 'williamson'\n",
      " 'peyton' 'jonas' 'whitman']\n",
      "VALUE: 0.5555555555555556\n",
      "(19,)\n",
      "['nikki' 'greer' 'colbert' 'mcmahon' 'lindsey' 'carlson' 'williamson'\n",
      " 'peyton' 'jonas' 'whitman']\n",
      "VALUE: 1.1111111111111112\n",
      "(19,)\n",
      "['newspapers' 'politicians' 'proposals' 'legislators' 'debates' 'things'\n",
      " 'bills' 'taxation' 'governments' 'legislature']\n",
      "VALUE: 1.6666666666666667\n",
      "(19,)\n",
      "['newspapers' 'politicians' 'proposals' 'legislators' 'debates' 'things'\n",
      " 'bills' 'taxation' 'governments' 'legislature']\n",
      "VALUE: 2.2222222222222223\n",
      "(19,)\n",
      "['legislators' 'politicians' 'proposals' 'bills' 'polls' 'revelations'\n",
      " 'items' 'reports' 'belongings' 'auctions']\n",
      "VALUE: 2.7777777777777777\n",
      "(19,)\n",
      "['legislators' 'politicians' 'proposals' 'bills' 'polls' 'revelations'\n",
      " 'items' 'reports' 'belongings' 'auctions']\n",
      "VALUE: 3.3333333333333335\n",
      "(19,)\n",
      "['legislators' 'reports' 'items' 'auctions' 'revelations' 'motorcycles'\n",
      " 'ways' 'polls' 'bicycles' 'belongings']\n",
      "VALUE: 3.8888888888888893\n",
      "(19,)\n",
      "['legislators' 'reports' 'items' 'auctions' 'revelations' 'motorcycles'\n",
      " 'ways' 'polls' 'bicycles' 'belongings']\n",
      "VALUE: 4.444444444444445\n",
      "(19,)\n",
      "['legislators' 'jacob' 'reports' 'motorcycles' 'auctions' 'inspections'\n",
      " 'bernard' 'items' 'luggage' 'revelations']\n",
      "VALUE: 5.0\n",
      "(19,)\n",
      "['jacob' 'bernard' 'pollard' 'forrest' 'inspections' 'sheffield'\n",
      " 'sutherland' 'caldwell' 'motorcycles' 'reports']\n"
     ]
    }
   ],
   "source": [
    "find_top_words(train_w2v_embed, train_w2v_token, test_w2v_embed, test_w2v_token, w2v_train_pos_cond_matrix_df, \"word2vec\", \"pos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_43 (InputLayer)           (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_44 (InputLayer)           (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 304)          0           input_43[0][0]                   \n",
      "                                                                 input_44[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_71 (Dense)                (None, 128)          39040       concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_72 (Dense)                (None, 75)           9675        dense_71[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_73 (Dense)                (None, 75)           9675        dense_71[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 75)           0           dense_72[0][0]                   \n",
      "                                                                 dense_73[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 79)           0           lambda_15[0][0]                  \n",
      "                                                                 input_44[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_74 (Dense)                (None, 128)          10240       concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_75 (Dense)                (None, 300)          38700       dense_74[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 107,330\n",
      "Trainable params: 107,330\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 12000 samples, validate on 3000 samples\n",
      "Epoch 1/50\n",
      " - 3s - loss: 0.0338 - val_loss: 0.0304\n",
      "Epoch 2/50\n",
      " - 2s - loss: 0.0303 - val_loss: 0.0303\n",
      "Epoch 3/50\n",
      " - 2s - loss: 0.0302 - val_loss: 0.0302\n",
      "Epoch 4/50\n",
      " - 2s - loss: 0.0302 - val_loss: 0.0302\n",
      "Epoch 5/50\n",
      " - 2s - loss: 0.0301 - val_loss: 0.0302\n",
      "Epoch 6/50\n",
      " - 2s - loss: 0.0301 - val_loss: 0.0302\n",
      "Epoch 7/50\n",
      " - 2s - loss: 0.0301 - val_loss: 0.0301\n",
      "Epoch 8/50\n",
      " - 2s - loss: 0.0301 - val_loss: 0.0301\n",
      "Epoch 9/50\n",
      " - 2s - loss: 0.0301 - val_loss: 0.0301\n",
      "Epoch 10/50\n",
      " - 2s - loss: 0.0301 - val_loss: 0.0301\n",
      "Epoch 11/50\n",
      " - 2s - loss: 0.0301 - val_loss: 0.0301\n",
      "Epoch 12/50\n",
      " - 2s - loss: 0.0300 - val_loss: 0.0301\n",
      "Epoch 13/50\n",
      " - 2s - loss: 0.0300 - val_loss: 0.0301\n",
      "Epoch 14/50\n",
      " - 2s - loss: 0.0300 - val_loss: 0.0301\n",
      "Epoch 15/50\n",
      " - 2s - loss: 0.0300 - val_loss: 0.0301\n",
      "Epoch 16/50\n",
      " - 2s - loss: 0.0300 - val_loss: 0.0301\n",
      "Epoch 17/50\n",
      " - 2s - loss: 0.0300 - val_loss: 0.0301\n",
      "Epoch 18/50\n",
      " - 2s - loss: 0.0300 - val_loss: 0.0301\n",
      "Epoch 19/50\n",
      " - 2s - loss: 0.0300 - val_loss: 0.0301\n",
      "Epoch 20/50\n",
      " - 3s - loss: 0.0300 - val_loss: 0.0301\n",
      "Epoch 21/50\n",
      " - 2s - loss: 0.0300 - val_loss: 0.0301\n",
      "Epoch 22/50\n",
      " - 2s - loss: 0.0300 - val_loss: 0.0301\n",
      "Epoch 23/50\n",
      " - 2s - loss: 0.0300 - val_loss: 0.0301\n",
      "Epoch 24/50\n",
      " - 2s - loss: 0.0300 - val_loss: 0.0300\n",
      "Epoch 25/50\n",
      " - 2s - loss: 0.0300 - val_loss: 0.0300\n",
      "Epoch 26/50\n",
      " - 2s - loss: 0.0300 - val_loss: 0.0300\n",
      "Epoch 27/50\n",
      " - 2s - loss: 0.0300 - val_loss: 0.0300\n",
      "Epoch 28/50\n",
      " - 2s - loss: 0.0300 - val_loss: 0.0300\n",
      "Epoch 29/50\n",
      " - 2s - loss: 0.0300 - val_loss: 0.0300\n",
      "Epoch 30/50\n",
      " - 2s - loss: 0.0300 - val_loss: 0.0300\n",
      "Epoch 31/50\n",
      " - 2s - loss: 0.0300 - val_loss: 0.0300\n",
      "Epoch 32/50\n",
      " - 2s - loss: 0.0300 - val_loss: 0.0300\n",
      "Epoch 33/50\n",
      " - 2s - loss: 0.0300 - val_loss: 0.0300\n",
      "Epoch 34/50\n",
      " - 2s - loss: 0.0300 - val_loss: 0.0300\n",
      "Epoch 35/50\n",
      " - 2s - loss: 0.0300 - val_loss: 0.0300\n",
      "Epoch 36/50\n",
      " - 2s - loss: 0.0300 - val_loss: 0.0300\n",
      "Epoch 37/50\n",
      " - 2s - loss: 0.0300 - val_loss: 0.0300\n",
      "Epoch 38/50\n",
      " - 2s - loss: 0.0300 - val_loss: 0.0300\n",
      "Epoch 39/50\n",
      " - 2s - loss: 0.0300 - val_loss: 0.0300\n",
      "Epoch 40/50\n",
      " - 2s - loss: 0.0300 - val_loss: 0.0300\n",
      "Epoch 41/50\n",
      " - 2s - loss: 0.0300 - val_loss: 0.0300\n",
      "Epoch 42/50\n",
      " - 2s - loss: 0.0300 - val_loss: 0.0300\n",
      "Epoch 43/50\n",
      " - 2s - loss: 0.0300 - val_loss: 0.0300\n",
      "Epoch 44/50\n",
      " - 2s - loss: 0.0300 - val_loss: 0.0300\n",
      "Epoch 45/50\n",
      " - 2s - loss: 0.0300 - val_loss: 0.0300\n",
      "Epoch 46/50\n",
      " - 2s - loss: 0.0300 - val_loss: 0.0300\n",
      "Epoch 47/50\n",
      " - 2s - loss: 0.0300 - val_loss: 0.0300\n"
     ]
    }
   ],
   "source": [
    "### PARAMETERS ###\n",
    "decoder_out_dim = train_w2v_embed.shape[1] # dim of decoder output layer\n",
    "n_x = train_w2v_embed.shape[1]\n",
    "n_y = w2v_train_sentiment_cond_matrix_df.shape[1]\n",
    "train_embed = train_w2v_embed\n",
    "train_word = w2v_train_sentiment_cond_matrix_df\n",
    "test_embed = test_w2v_embed\n",
    "test_word = w2v_test_sentiment_cond_matrix_df\n",
    "### PARAMETERS ###\n",
    "\n",
    "# define encoder\n",
    "X = Input(shape=(n_x,))\n",
    "label = Input(shape=(n_y,))\n",
    "inputs = concat([X, label])\n",
    "encoder_h = Dense(encoder_dim1, activation=activ)(inputs)\n",
    "mu = Dense(n_z, activation='linear')(encoder_h)\n",
    "l_sigma = Dense(n_z, activation='linear')(encoder_h)\n",
    "\n",
    "# sample latent space\n",
    "z = Lambda(sample_z, output_shape = (n_z, ))([mu, l_sigma])\n",
    "zc = concat([z, label])\n",
    "\n",
    "# decoder\n",
    "decoder_hidden = Dense(decoder_dim, activation=activ)\n",
    "decoder_out = Dense(decoder_out_dim, activation='sigmoid')\n",
    "h_p = decoder_hidden(zc)\n",
    "outputs = decoder_out(h_p)\n",
    "\n",
    "# define graphs\n",
    "cvae = Model([X, label], outputs)\n",
    "encoder = Model([X, label], mu)\n",
    "d_in = Input(shape=(n_z+n_y,))\n",
    "d_h = decoder_hidden(d_in)\n",
    "d_out = decoder_out(d_h)\n",
    "decoder = Model(d_in, d_out)\n",
    "\n",
    "# print statistics\n",
    "cvae.compile(optimizer=optim, loss=vae_loss)\n",
    "\n",
    "cvae.summary()\n",
    "\n",
    "cvae_hist = cvae.fit([train_embed, train_word], train_embed, verbose = 2, batch_size=m, \n",
    "                 epochs=n_epoch,\n",
    "                 validation_data = ([test_embed, test_word], test_embed),\n",
    "                 callbacks = [EarlyStopping(patience = 5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg', 'neu', 'pos', 'compound']"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORD: mathematics\n",
      "11730\n",
      "VALUE: 0.0\n",
      "(4,)\n",
      "['nikki' 'whitman' 'greer' 'williamson' 'lindsey' 'colbert' 'hyde' 'pete'\n",
      " 'mcmahon' 'hilary']\n",
      "VALUE: 0.5555555555555556\n",
      "(4,)\n",
      "['foolish' 'stupid' 'whitman' 'hate' 'ought' 'immoral' 'silly' 'ugly'\n",
      " 'embarrassed' 'horrible']\n",
      "VALUE: 1.1111111111111112\n",
      "(4,)\n",
      "['embarrassed' 'foolish' 'cynical' 'embarrassing' 'infuriated' 'unhappy'\n",
      " 'punish' 'sad' 'stupid' 'afraid']\n",
      "VALUE: 1.6666666666666667\n",
      "(4,)\n",
      "['unhappy' 'infuriated' 'embarrassed' 'cynical' 'foolish' 'fearful'\n",
      " 'angered' 'punish' 'embarrassing' 'unacceptable']\n",
      "VALUE: 2.2222222222222223\n",
      "(4,)\n",
      "['unhappy' 'infuriated' 'cynical' 'fearful' 'embarrassed' 'angered'\n",
      " 'unacceptable' 'wary' 'punish' 'foolish']\n",
      "VALUE: 2.7777777777777777\n",
      "(4,)\n",
      "['unhappy' 'infuriated' 'cynical' 'fearful' 'angered' 'embarrassed' 'wary'\n",
      " 'unacceptable' 'punish' 'concerned']\n",
      "VALUE: 3.3333333333333335\n",
      "(4,)\n",
      "['unhappy' 'infuriated' 'cynical' 'fearful' 'angered' 'wary'\n",
      " 'unacceptable' 'embarrassed' 'concerned' 'punish']\n",
      "VALUE: 3.8888888888888893\n",
      "(4,)\n",
      "['unhappy' 'infuriated' 'cynical' 'fearful' 'angered' 'wary' 'concerned'\n",
      " 'unacceptable' 'punish' 'embarrassed']\n",
      "VALUE: 4.444444444444445\n",
      "(4,)\n",
      "['unhappy' 'infuriated' 'cynical' 'fearful' 'angered' 'wary' 'concerned'\n",
      " 'unaware' 'satisfied' 'unacceptable']\n",
      "VALUE: 5.0\n",
      "(4,)\n",
      "['unhappy' 'infuriated' 'cynical' 'fearful' 'angered' 'wary' 'concerned'\n",
      " 'satisfied' 'unaware' 'disappointed']\n",
      "WORD: mathematics\n",
      "11730\n",
      "VALUE: 0.0\n",
      "(4,)\n",
      "['nikki' 'greer' 'whitman' 'williamson' 'mcmahon' 'lindsey' 'colbert'\n",
      " 'hyde' 'burke' 'pete']\n",
      "VALUE: 0.5555555555555556\n",
      "(4,)\n",
      "['nikki' 'whitman' 'greer' 'williamson' 'lindsey' 'colbert' 'hyde' 'pete'\n",
      " 'mcmahon' 'burke']\n",
      "VALUE: 1.1111111111111112\n",
      "(4,)\n",
      "['nikki' 'whitman' 'greer' 'williamson' 'hyde' 'lindsey' 'colbert' 'pete'\n",
      " 'hilary' 'mcmahon']\n",
      "VALUE: 1.6666666666666667\n",
      "(4,)\n",
      "['nikki' 'whitman' 'greer' 'williamson' 'hyde' 'colbert' 'lindsey' 'pete'\n",
      " 'hilary' 'mcmahon']\n",
      "VALUE: 2.2222222222222223\n",
      "(4,)\n",
      "['nikki' 'whitman' 'williamson' 'greer' 'hyde' 'colbert' 'lindsey' 'pete'\n",
      " 'hilary' 'mcmahon']\n",
      "VALUE: 2.7777777777777777\n",
      "(4,)\n",
      "['nikki' 'whitman' 'williamson' 'greer' 'hyde' 'colbert' 'lindsey' 'pete'\n",
      " 'hilary' 'carlson']\n",
      "VALUE: 3.3333333333333335\n",
      "(4,)\n",
      "['nikki' 'whitman' 'williamson' 'greer' 'hyde' 'colbert' 'lindsey' 'pete'\n",
      " 'carlson' 'hilary']\n",
      "VALUE: 3.8888888888888893\n",
      "(4,)\n",
      "['nikki' 'whitman' 'williamson' 'greer' 'hyde' 'colbert' 'carlson'\n",
      " 'lindsey' 'pete' 'fk']\n",
      "VALUE: 4.444444444444445\n",
      "(4,)\n",
      "['nikki' 'whitman' 'williamson' 'greer' 'hyde' 'fk' 'carlson' 'colbert'\n",
      " 'lindsey' 'pete']\n",
      "VALUE: 5.0\n",
      "(4,)\n",
      "['nikki' 'whitman' 'williamson' 'greer' 'hyde' 'fk' 'carlson' 'colbert'\n",
      " 'lindsey' 'scarborough']\n",
      "WORD: mathematics\n",
      "11730\n",
      "VALUE: 0.0\n",
      "(4,)\n",
      "['nikki' 'whitman' 'greer' 'williamson' 'lindsey' 'colbert' 'hyde' 'pete'\n",
      " 'mcmahon' 'hilary']\n",
      "VALUE: 0.5555555555555556\n",
      "(4,)\n",
      "['foolish' 'ought' 'whitman' 'stupid' 'hate' 'silly' 'democratic' 'sort'\n",
      " 'political' 'horrible']\n",
      "VALUE: 1.1111111111111112\n",
      "(4,)\n",
      "['foolish' 'ought' 'cynical' 'sad' 'embarrassed' 'constructive' 'hate'\n",
      " 'stupid' 'democratic' 'painful']\n",
      "VALUE: 1.6666666666666667\n",
      "(4,)\n",
      "['cynical' 'ought' 'foolish' 'unhappy' 'sad' 'embarrassed' 'infuriated'\n",
      " 'arrogant' 'happy' 'punish']\n",
      "VALUE: 2.2222222222222223\n",
      "(4,)\n",
      "['cynical' 'unhappy' 'infuriated' 'ought' 'arrogant' 'happy' 'foolish'\n",
      " 'believe' 'punish' 'sad']\n",
      "VALUE: 2.7777777777777777\n",
      "(4,)\n",
      "['cynical' 'unhappy' 'infuriated' 'arrogant' 'believe' 'ought' 'happy'\n",
      " 'deserved' 'angered' 'alienated']\n",
      "VALUE: 3.3333333333333335\n",
      "(4,)\n",
      "['cynical' 'unhappy' 'infuriated' 'arrogant' 'believe' 'deserved'\n",
      " 'alienated' 'angered' 'grateful' 'ought']\n",
      "VALUE: 3.8888888888888893\n",
      "(4,)\n",
      "['cynical' 'unhappy' 'infuriated' 'arrogant' 'believe' 'deserved'\n",
      " 'alienated' 'critics' 'angered' 'believing']\n",
      "VALUE: 4.444444444444445\n",
      "(4,)\n",
      "['cynical' 'infuriated' 'unhappy' 'arrogant' 'deserved' 'believe'\n",
      " 'already' 'critics' 'bowie' 'alienated']\n",
      "VALUE: 5.0\n",
      "(4,)\n",
      "['cynical' 'infuriated' 'unhappy' 'already' 'bowie' 'deserved' 'a1' 'ms'\n",
      " 'arrogant' 'critics']\n",
      "WORD: mathematics\n",
      "11730\n",
      "VALUE: 0.0\n",
      "(4,)\n",
      "['nikki' 'whitman' 'greer' 'williamson' 'lindsey' 'colbert' 'hyde' 'pete'\n",
      " 'mcmahon' 'hilary']\n",
      "VALUE: 0.5555555555555556\n",
      "(4,)\n",
      "['nikki' 'lovely' 'guinness' 'howell' 'ought' 'rowe' 'jonas' 'disneyland'\n",
      " 'norman' 'baird']\n",
      "VALUE: 1.1111111111111112\n",
      "(4,)\n",
      "['lovely' 'brilliant' 'beautiful' 'characteristic' 'splendid' 'virtues'\n",
      " 'glorious' 'liked' 'fascinating' 'madison']\n",
      "VALUE: 1.6666666666666667\n",
      "(4,)\n",
      "['brilliant' 'lovely' 'splendid' 'characteristic' 'beautiful'\n",
      " 'fascinating' 'inspiring' 'fantastic' 'amazing' 'glorious']\n",
      "VALUE: 2.2222222222222223\n",
      "(4,)\n",
      "['brilliant' 'splendid' 'characteristic' 'inspiring' 'lovely'\n",
      " 'fascinating' 'fantastic' 'amazing' 'finishes' 'beautiful']\n",
      "VALUE: 2.7777777777777777\n",
      "(4,)\n",
      "['brilliant' 'splendid' 'inspiring' 'characteristic' 'finishes'\n",
      " 'fantastic' 'fascinating' 'pleasing' 'impressive' 'amazing']\n",
      "VALUE: 3.3333333333333335\n",
      "(4,)\n",
      "['brilliant' 'pleasing' 'inspiring' 'finishes' 'splendid' 'fantastic'\n",
      " 'impressive' 'fascinating' 'characteristic' 'amazing']\n",
      "VALUE: 3.8888888888888893\n",
      "(4,)\n",
      "['brilliant' 'pleasing' 'finishes' 'inspiring' 'impressive' 'fantastic'\n",
      " 'splendid' 'fascinating' 'notable' 'eminent']\n",
      "VALUE: 4.444444444444445\n",
      "(4,)\n",
      "['brilliant' 'pleasing' 'finishes' 'impressive' 'inspiring' 'fantastic'\n",
      " 'fascinating' 'notable' 'splendid' 'inaugural']\n",
      "VALUE: 5.0\n",
      "(4,)\n",
      "['pleasing' 'brilliant' 'finishes' 'impressive' 'thanks' 'inaugural'\n",
      " 'notable' 'fantastic' 'aspects' 'inspiring']\n",
      "WORD: remote\n",
      "7807\n",
      "VALUE: 0.0\n",
      "(4,)\n",
      "['nikki' 'whitman' 'greer' 'williamson' 'lindsey' 'colbert' 'hyde' 'pete'\n",
      " 'mcmahon' 'hilary']\n",
      "VALUE: 0.5555555555555556\n",
      "(4,)\n",
      "['foolish' 'stupid' 'whitman' 'hate' 'ought' 'immoral' 'silly' 'ugly'\n",
      " 'embarrassed' 'horrible']\n",
      "VALUE: 1.1111111111111112\n",
      "(4,)\n",
      "['embarrassed' 'foolish' 'cynical' 'embarrassing' 'infuriated' 'unhappy'\n",
      " 'punish' 'sad' 'stupid' 'afraid']\n",
      "VALUE: 1.6666666666666667\n",
      "(4,)\n",
      "['unhappy' 'infuriated' 'embarrassed' 'cynical' 'foolish' 'fearful'\n",
      " 'angered' 'punish' 'embarrassing' 'unacceptable']\n",
      "VALUE: 2.2222222222222223\n",
      "(4,)\n",
      "['unhappy' 'infuriated' 'cynical' 'fearful' 'embarrassed' 'angered'\n",
      " 'unacceptable' 'wary' 'punish' 'foolish']\n",
      "VALUE: 2.7777777777777777\n",
      "(4,)\n",
      "['unhappy' 'infuriated' 'cynical' 'fearful' 'angered' 'embarrassed' 'wary'\n",
      " 'unacceptable' 'punish' 'concerned']\n",
      "VALUE: 3.3333333333333335\n",
      "(4,)\n",
      "['unhappy' 'infuriated' 'cynical' 'fearful' 'angered' 'wary'\n",
      " 'unacceptable' 'embarrassed' 'concerned' 'punish']\n",
      "VALUE: 3.8888888888888893\n",
      "(4,)\n",
      "['unhappy' 'infuriated' 'cynical' 'fearful' 'angered' 'wary' 'concerned'\n",
      " 'unacceptable' 'punish' 'embarrassed']\n",
      "VALUE: 4.444444444444445\n",
      "(4,)\n",
      "['unhappy' 'infuriated' 'cynical' 'fearful' 'angered' 'wary' 'concerned'\n",
      " 'unaware' 'satisfied' 'unacceptable']\n",
      "VALUE: 5.0\n",
      "(4,)\n",
      "['unhappy' 'infuriated' 'cynical' 'fearful' 'angered' 'wary' 'concerned'\n",
      " 'satisfied' 'unaware' 'disappointed']\n",
      "WORD: remote\n",
      "7807\n",
      "VALUE: 0.0\n",
      "(4,)\n",
      "['nikki' 'greer' 'whitman' 'williamson' 'mcmahon' 'lindsey' 'colbert'\n",
      " 'hyde' 'burke' 'pete']\n",
      "VALUE: 0.5555555555555556\n",
      "(4,)\n",
      "['nikki' 'whitman' 'greer' 'williamson' 'lindsey' 'colbert' 'hyde' 'pete'\n",
      " 'mcmahon' 'burke']\n",
      "VALUE: 1.1111111111111112\n",
      "(4,)\n",
      "['nikki' 'whitman' 'greer' 'williamson' 'hyde' 'lindsey' 'colbert' 'pete'\n",
      " 'hilary' 'mcmahon']\n",
      "VALUE: 1.6666666666666667\n",
      "(4,)\n",
      "['nikki' 'whitman' 'greer' 'williamson' 'hyde' 'colbert' 'lindsey' 'pete'\n",
      " 'hilary' 'mcmahon']\n",
      "VALUE: 2.2222222222222223\n",
      "(4,)\n",
      "['nikki' 'whitman' 'williamson' 'greer' 'hyde' 'colbert' 'lindsey' 'pete'\n",
      " 'hilary' 'mcmahon']\n",
      "VALUE: 2.7777777777777777\n",
      "(4,)\n",
      "['nikki' 'whitman' 'williamson' 'greer' 'hyde' 'colbert' 'lindsey' 'pete'\n",
      " 'hilary' 'carlson']\n",
      "VALUE: 3.3333333333333335\n",
      "(4,)\n",
      "['nikki' 'whitman' 'williamson' 'greer' 'hyde' 'colbert' 'lindsey' 'pete'\n",
      " 'carlson' 'hilary']\n",
      "VALUE: 3.8888888888888893\n",
      "(4,)\n",
      "['nikki' 'whitman' 'williamson' 'greer' 'hyde' 'colbert' 'carlson'\n",
      " 'lindsey' 'pete' 'fk']\n",
      "VALUE: 4.444444444444445\n",
      "(4,)\n",
      "['nikki' 'whitman' 'williamson' 'greer' 'hyde' 'fk' 'carlson' 'colbert'\n",
      " 'lindsey' 'pete']\n",
      "VALUE: 5.0\n",
      "(4,)\n",
      "['nikki' 'whitman' 'williamson' 'greer' 'hyde' 'fk' 'carlson' 'colbert'\n",
      " 'lindsey' 'scarborough']\n",
      "WORD: remote\n",
      "7807\n",
      "VALUE: 0.0\n",
      "(4,)\n",
      "['nikki' 'whitman' 'greer' 'williamson' 'lindsey' 'colbert' 'hyde' 'pete'\n",
      " 'mcmahon' 'hilary']\n",
      "VALUE: 0.5555555555555556\n",
      "(4,)\n",
      "['foolish' 'ought' 'whitman' 'stupid' 'hate' 'silly' 'democratic' 'sort'\n",
      " 'political' 'horrible']\n",
      "VALUE: 1.1111111111111112\n",
      "(4,)\n",
      "['foolish' 'ought' 'cynical' 'sad' 'embarrassed' 'constructive' 'hate'\n",
      " 'stupid' 'democratic' 'painful']\n",
      "VALUE: 1.6666666666666667\n",
      "(4,)\n",
      "['cynical' 'ought' 'foolish' 'unhappy' 'sad' 'embarrassed' 'infuriated'\n",
      " 'arrogant' 'happy' 'punish']\n",
      "VALUE: 2.2222222222222223\n",
      "(4,)\n",
      "['cynical' 'unhappy' 'infuriated' 'ought' 'arrogant' 'happy' 'foolish'\n",
      " 'believe' 'punish' 'sad']\n",
      "VALUE: 2.7777777777777777\n",
      "(4,)\n",
      "['cynical' 'unhappy' 'infuriated' 'arrogant' 'believe' 'ought' 'happy'\n",
      " 'deserved' 'angered' 'alienated']\n",
      "VALUE: 3.3333333333333335\n",
      "(4,)\n",
      "['cynical' 'unhappy' 'infuriated' 'arrogant' 'believe' 'deserved'\n",
      " 'alienated' 'angered' 'grateful' 'ought']\n",
      "VALUE: 3.8888888888888893\n",
      "(4,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cynical' 'unhappy' 'infuriated' 'arrogant' 'believe' 'deserved'\n",
      " 'alienated' 'critics' 'angered' 'believing']\n",
      "VALUE: 4.444444444444445\n",
      "(4,)\n",
      "['cynical' 'infuriated' 'unhappy' 'arrogant' 'deserved' 'believe'\n",
      " 'already' 'critics' 'bowie' 'alienated']\n",
      "VALUE: 5.0\n",
      "(4,)\n",
      "['cynical' 'infuriated' 'unhappy' 'already' 'bowie' 'deserved' 'a1' 'ms'\n",
      " 'arrogant' 'critics']\n",
      "WORD: remote\n",
      "7807\n",
      "VALUE: 0.0\n",
      "(4,)\n",
      "['nikki' 'whitman' 'greer' 'williamson' 'lindsey' 'colbert' 'hyde' 'pete'\n",
      " 'mcmahon' 'hilary']\n",
      "VALUE: 0.5555555555555556\n",
      "(4,)\n",
      "['nikki' 'lovely' 'guinness' 'howell' 'ought' 'rowe' 'jonas' 'disneyland'\n",
      " 'norman' 'baird']\n",
      "VALUE: 1.1111111111111112\n",
      "(4,)\n",
      "['lovely' 'brilliant' 'beautiful' 'characteristic' 'splendid' 'virtues'\n",
      " 'glorious' 'liked' 'fascinating' 'madison']\n",
      "VALUE: 1.6666666666666667\n",
      "(4,)\n",
      "['brilliant' 'lovely' 'splendid' 'characteristic' 'beautiful'\n",
      " 'fascinating' 'inspiring' 'fantastic' 'amazing' 'glorious']\n",
      "VALUE: 2.2222222222222223\n",
      "(4,)\n",
      "['brilliant' 'splendid' 'characteristic' 'inspiring' 'lovely'\n",
      " 'fascinating' 'fantastic' 'amazing' 'finishes' 'beautiful']\n",
      "VALUE: 2.7777777777777777\n",
      "(4,)\n",
      "['brilliant' 'splendid' 'inspiring' 'characteristic' 'finishes'\n",
      " 'fantastic' 'fascinating' 'pleasing' 'impressive' 'amazing']\n",
      "VALUE: 3.3333333333333335\n",
      "(4,)\n",
      "['brilliant' 'pleasing' 'inspiring' 'finishes' 'splendid' 'fantastic'\n",
      " 'impressive' 'fascinating' 'characteristic' 'amazing']\n",
      "VALUE: 3.8888888888888893\n",
      "(4,)\n",
      "['brilliant' 'pleasing' 'finishes' 'inspiring' 'impressive' 'fantastic'\n",
      " 'splendid' 'fascinating' 'notable' 'eminent']\n",
      "VALUE: 4.444444444444445\n",
      "(4,)\n",
      "['brilliant' 'pleasing' 'finishes' 'impressive' 'inspiring' 'fantastic'\n",
      " 'fascinating' 'notable' 'splendid' 'inaugural']\n",
      "VALUE: 5.0\n",
      "(4,)\n",
      "['pleasing' 'brilliant' 'finishes' 'impressive' 'thanks' 'inaugural'\n",
      " 'notable' 'fantastic' 'aspects' 'inspiring']\n",
      "WORD: internet\n",
      "503\n",
      "VALUE: 0.0\n",
      "(4,)\n",
      "['nikki' 'whitman' 'greer' 'williamson' 'lindsey' 'colbert' 'hyde' 'pete'\n",
      " 'mcmahon' 'hilary']\n",
      "VALUE: 0.5555555555555556\n",
      "(4,)\n",
      "['foolish' 'stupid' 'whitman' 'hate' 'ought' 'immoral' 'silly' 'ugly'\n",
      " 'embarrassed' 'horrible']\n",
      "VALUE: 1.1111111111111112\n",
      "(4,)\n",
      "['embarrassed' 'foolish' 'cynical' 'embarrassing' 'infuriated' 'unhappy'\n",
      " 'punish' 'sad' 'stupid' 'afraid']\n",
      "VALUE: 1.6666666666666667\n",
      "(4,)\n",
      "['unhappy' 'infuriated' 'embarrassed' 'cynical' 'foolish' 'fearful'\n",
      " 'angered' 'punish' 'embarrassing' 'unacceptable']\n",
      "VALUE: 2.2222222222222223\n",
      "(4,)\n",
      "['unhappy' 'infuriated' 'cynical' 'fearful' 'embarrassed' 'angered'\n",
      " 'unacceptable' 'wary' 'punish' 'foolish']\n",
      "VALUE: 2.7777777777777777\n",
      "(4,)\n",
      "['unhappy' 'infuriated' 'cynical' 'fearful' 'angered' 'embarrassed' 'wary'\n",
      " 'unacceptable' 'punish' 'concerned']\n",
      "VALUE: 3.3333333333333335\n",
      "(4,)\n",
      "['unhappy' 'infuriated' 'cynical' 'fearful' 'angered' 'wary'\n",
      " 'unacceptable' 'embarrassed' 'concerned' 'punish']\n",
      "VALUE: 3.8888888888888893\n",
      "(4,)\n",
      "['unhappy' 'infuriated' 'cynical' 'fearful' 'angered' 'wary' 'concerned'\n",
      " 'unacceptable' 'punish' 'embarrassed']\n",
      "VALUE: 4.444444444444445\n",
      "(4,)\n",
      "['unhappy' 'infuriated' 'cynical' 'fearful' 'angered' 'wary' 'concerned'\n",
      " 'unaware' 'satisfied' 'unacceptable']\n",
      "VALUE: 5.0\n",
      "(4,)\n",
      "['unhappy' 'infuriated' 'cynical' 'fearful' 'angered' 'wary' 'concerned'\n",
      " 'satisfied' 'unaware' 'disappointed']\n",
      "WORD: internet\n",
      "503\n",
      "VALUE: 0.0\n",
      "(4,)\n",
      "['nikki' 'greer' 'whitman' 'williamson' 'mcmahon' 'lindsey' 'colbert'\n",
      " 'hyde' 'burke' 'pete']\n",
      "VALUE: 0.5555555555555556\n",
      "(4,)\n",
      "['nikki' 'whitman' 'greer' 'williamson' 'lindsey' 'colbert' 'hyde' 'pete'\n",
      " 'mcmahon' 'burke']\n",
      "VALUE: 1.1111111111111112\n",
      "(4,)\n",
      "['nikki' 'whitman' 'greer' 'williamson' 'hyde' 'lindsey' 'colbert' 'pete'\n",
      " 'hilary' 'mcmahon']\n",
      "VALUE: 1.6666666666666667\n",
      "(4,)\n",
      "['nikki' 'whitman' 'greer' 'williamson' 'hyde' 'colbert' 'lindsey' 'pete'\n",
      " 'hilary' 'mcmahon']\n",
      "VALUE: 2.2222222222222223\n",
      "(4,)\n",
      "['nikki' 'whitman' 'williamson' 'greer' 'hyde' 'colbert' 'lindsey' 'pete'\n",
      " 'hilary' 'mcmahon']\n",
      "VALUE: 2.7777777777777777\n",
      "(4,)\n",
      "['nikki' 'whitman' 'williamson' 'greer' 'hyde' 'colbert' 'lindsey' 'pete'\n",
      " 'hilary' 'carlson']\n",
      "VALUE: 3.3333333333333335\n",
      "(4,)\n",
      "['nikki' 'whitman' 'williamson' 'greer' 'hyde' 'colbert' 'lindsey' 'pete'\n",
      " 'carlson' 'hilary']\n",
      "VALUE: 3.8888888888888893\n",
      "(4,)\n",
      "['nikki' 'whitman' 'williamson' 'greer' 'hyde' 'colbert' 'carlson'\n",
      " 'lindsey' 'pete' 'fk']\n",
      "VALUE: 4.444444444444445\n",
      "(4,)\n",
      "['nikki' 'whitman' 'williamson' 'greer' 'hyde' 'fk' 'carlson' 'colbert'\n",
      " 'lindsey' 'pete']\n",
      "VALUE: 5.0\n",
      "(4,)\n",
      "['nikki' 'whitman' 'williamson' 'greer' 'hyde' 'fk' 'carlson' 'colbert'\n",
      " 'lindsey' 'scarborough']\n",
      "WORD: internet\n",
      "503\n",
      "VALUE: 0.0\n",
      "(4,)\n",
      "['nikki' 'whitman' 'greer' 'williamson' 'lindsey' 'colbert' 'hyde' 'pete'\n",
      " 'mcmahon' 'hilary']\n",
      "VALUE: 0.5555555555555556\n",
      "(4,)\n",
      "['foolish' 'ought' 'whitman' 'stupid' 'hate' 'silly' 'democratic' 'sort'\n",
      " 'political' 'horrible']\n",
      "VALUE: 1.1111111111111112\n",
      "(4,)\n",
      "['foolish' 'ought' 'cynical' 'sad' 'embarrassed' 'constructive' 'hate'\n",
      " 'stupid' 'democratic' 'painful']\n",
      "VALUE: 1.6666666666666667\n",
      "(4,)\n",
      "['cynical' 'ought' 'foolish' 'unhappy' 'sad' 'embarrassed' 'infuriated'\n",
      " 'arrogant' 'happy' 'punish']\n",
      "VALUE: 2.2222222222222223\n",
      "(4,)\n",
      "['cynical' 'unhappy' 'infuriated' 'ought' 'arrogant' 'happy' 'foolish'\n",
      " 'believe' 'punish' 'sad']\n",
      "VALUE: 2.7777777777777777\n",
      "(4,)\n",
      "['cynical' 'unhappy' 'infuriated' 'arrogant' 'believe' 'ought' 'happy'\n",
      " 'deserved' 'angered' 'alienated']\n",
      "VALUE: 3.3333333333333335\n",
      "(4,)\n",
      "['cynical' 'unhappy' 'infuriated' 'arrogant' 'believe' 'deserved'\n",
      " 'alienated' 'angered' 'grateful' 'ought']\n",
      "VALUE: 3.8888888888888893\n",
      "(4,)\n",
      "['cynical' 'unhappy' 'infuriated' 'arrogant' 'believe' 'deserved'\n",
      " 'alienated' 'critics' 'angered' 'believing']\n",
      "VALUE: 4.444444444444445\n",
      "(4,)\n",
      "['cynical' 'infuriated' 'unhappy' 'arrogant' 'deserved' 'believe'\n",
      " 'already' 'critics' 'bowie' 'alienated']\n",
      "VALUE: 5.0\n",
      "(4,)\n",
      "['cynical' 'infuriated' 'unhappy' 'already' 'bowie' 'deserved' 'a1' 'ms'\n",
      " 'arrogant' 'critics']\n",
      "WORD: internet\n",
      "503\n",
      "VALUE: 0.0\n",
      "(4,)\n",
      "['nikki' 'whitman' 'greer' 'williamson' 'lindsey' 'colbert' 'hyde' 'pete'\n",
      " 'mcmahon' 'hilary']\n",
      "VALUE: 0.5555555555555556\n",
      "(4,)\n",
      "['nikki' 'lovely' 'guinness' 'howell' 'ought' 'rowe' 'jonas' 'disneyland'\n",
      " 'norman' 'baird']\n",
      "VALUE: 1.1111111111111112\n",
      "(4,)\n",
      "['lovely' 'brilliant' 'beautiful' 'characteristic' 'splendid' 'virtues'\n",
      " 'glorious' 'liked' 'fascinating' 'madison']\n",
      "VALUE: 1.6666666666666667\n",
      "(4,)\n",
      "['brilliant' 'lovely' 'splendid' 'characteristic' 'beautiful'\n",
      " 'fascinating' 'inspiring' 'fantastic' 'amazing' 'glorious']\n",
      "VALUE: 2.2222222222222223\n",
      "(4,)\n",
      "['brilliant' 'splendid' 'characteristic' 'inspiring' 'lovely'\n",
      " 'fascinating' 'fantastic' 'amazing' 'finishes' 'beautiful']\n",
      "VALUE: 2.7777777777777777\n",
      "(4,)\n",
      "['brilliant' 'splendid' 'inspiring' 'characteristic' 'finishes'\n",
      " 'fantastic' 'fascinating' 'pleasing' 'impressive' 'amazing']\n",
      "VALUE: 3.3333333333333335\n",
      "(4,)\n",
      "['brilliant' 'pleasing' 'inspiring' 'finishes' 'splendid' 'fantastic'\n",
      " 'impressive' 'fascinating' 'characteristic' 'amazing']\n",
      "VALUE: 3.8888888888888893\n",
      "(4,)\n",
      "['brilliant' 'pleasing' 'finishes' 'inspiring' 'impressive' 'fantastic'\n",
      " 'splendid' 'fascinating' 'notable' 'eminent']\n",
      "VALUE: 4.444444444444445\n",
      "(4,)\n",
      "['brilliant' 'pleasing' 'finishes' 'impressive' 'inspiring' 'fantastic'\n",
      " 'fascinating' 'notable' 'splendid' 'inaugural']\n",
      "VALUE: 5.0\n",
      "(4,)\n",
      "['pleasing' 'brilliant' 'finishes' 'impressive' 'thanks' 'inaugural'\n",
      " 'notable' 'fantastic' 'aspects' 'inspiring']\n"
     ]
    }
   ],
   "source": [
    "find_top_words(train_w2v_embed, train_w2v_token, test_w2v_embed, test_w2v_token, w2v_train_sentiment_cond_matrix_df, \"word2vec\", \"sentiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "named entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_25 (InputLayer)           (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_26 (InputLayer)           (None, 17)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 317)          0           input_25[0][0]                   \n",
      "                                                                 input_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_41 (Dense)                (None, 128)          40704       concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_42 (Dense)                (None, 75)           9675        dense_41[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_43 (Dense)                (None, 75)           9675        dense_41[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 75)           0           dense_42[0][0]                   \n",
      "                                                                 dense_43[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 92)           0           lambda_9[0][0]                   \n",
      "                                                                 input_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_44 (Dense)                (None, 128)          11904       concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_45 (Dense)                (None, 300)          38700       dense_44[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 110,658\n",
      "Trainable params: 110,658\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 12000 samples, validate on 3000 samples\n",
      "Epoch 1/50\n",
      " - 3s - loss: 0.0338 - val_loss: 0.0304\n",
      "Epoch 2/50\n",
      " - 3s - loss: 0.0303 - val_loss: 0.0303\n",
      "Epoch 3/50\n",
      " - 2s - loss: 0.0302 - val_loss: 0.0302\n",
      "Epoch 4/50\n",
      " - 2s - loss: 0.0302 - val_loss: 0.0302\n",
      "Epoch 5/50\n",
      " - 3s - loss: 0.0301 - val_loss: 0.0302\n",
      "Epoch 6/50\n",
      " - 3s - loss: 0.0301 - val_loss: 0.0302\n",
      "Epoch 7/50\n",
      " - 2s - loss: 0.0301 - val_loss: 0.0302\n",
      "Epoch 8/50\n",
      " - 2s - loss: 0.0301 - val_loss: 0.0302\n",
      "Epoch 9/50\n",
      " - 2s - loss: 0.0301 - val_loss: 0.0302\n",
      "Epoch 10/50\n",
      " - 2s - loss: 0.0301 - val_loss: 0.0302\n",
      "Epoch 11/50\n",
      " - 3s - loss: 0.0301 - val_loss: 0.0301\n",
      "Epoch 12/50\n",
      " - 2s - loss: 0.0301 - val_loss: 0.0301\n",
      "Epoch 13/50\n",
      " - 2s - loss: 0.0301 - val_loss: 0.0301\n",
      "Epoch 14/50\n",
      " - 2s - loss: 0.0301 - val_loss: 0.0301\n",
      "Epoch 15/50\n",
      " - 2s - loss: 0.0301 - val_loss: 0.0301\n",
      "Epoch 16/50\n",
      " - 2s - loss: 0.0301 - val_loss: 0.0301\n",
      "Epoch 17/50\n",
      " - 2s - loss: 0.0301 - val_loss: 0.0301\n",
      "Epoch 18/50\n",
      " - 2s - loss: 0.0301 - val_loss: 0.0301\n",
      "Epoch 19/50\n",
      " - 2s - loss: 0.0301 - val_loss: 0.0301\n",
      "Epoch 20/50\n",
      " - 2s - loss: 0.0301 - val_loss: 0.0301\n",
      "Epoch 21/50\n",
      " - 2s - loss: 0.0301 - val_loss: 0.0301\n",
      "Epoch 22/50\n",
      " - 2s - loss: 0.0301 - val_loss: 0.0301\n",
      "Epoch 23/50\n",
      " - 2s - loss: 0.0301 - val_loss: 0.0301\n",
      "Epoch 24/50\n",
      " - 2s - loss: 0.0301 - val_loss: 0.0301\n",
      "Epoch 25/50\n",
      " - 2s - loss: 0.0301 - val_loss: 0.0301\n",
      "Epoch 26/50\n",
      " - 2s - loss: 0.0301 - val_loss: 0.0301\n",
      "Epoch 27/50\n",
      " - 2s - loss: 0.0301 - val_loss: 0.0301\n",
      "Epoch 28/50\n",
      " - 2s - loss: 0.0301 - val_loss: 0.0301\n",
      "Epoch 29/50\n",
      " - 2s - loss: 0.0301 - val_loss: 0.0301\n",
      "Epoch 30/50\n",
      " - 2s - loss: 0.0301 - val_loss: 0.0301\n",
      "Epoch 31/50\n",
      " - 2s - loss: 0.0301 - val_loss: 0.0301\n",
      "Epoch 32/50\n",
      " - 2s - loss: 0.0301 - val_loss: 0.0301\n",
      "Epoch 33/50\n",
      " - 2s - loss: 0.0301 - val_loss: 0.0301\n",
      "Epoch 34/50\n",
      " - 2s - loss: 0.0301 - val_loss: 0.0301\n",
      "Epoch 35/50\n",
      " - 2s - loss: 0.0301 - val_loss: 0.0301\n",
      "Epoch 36/50\n",
      " - 2s - loss: 0.0301 - val_loss: 0.0301\n",
      "Epoch 37/50\n",
      " - 2s - loss: 0.0301 - val_loss: 0.0301\n",
      "Epoch 38/50\n",
      " - 2s - loss: 0.0301 - val_loss: 0.0301\n",
      "Epoch 39/50\n",
      " - 2s - loss: 0.0301 - val_loss: 0.0301\n",
      "Epoch 40/50\n",
      " - 2s - loss: 0.0301 - val_loss: 0.0301\n",
      "Epoch 41/50\n",
      " - 2s - loss: 0.0301 - val_loss: 0.0301\n",
      "Epoch 42/50\n",
      " - 2s - loss: 0.0301 - val_loss: 0.0301\n",
      "Epoch 43/50\n",
      " - 2s - loss: 0.0301 - val_loss: 0.0301\n"
     ]
    }
   ],
   "source": [
    "### PARAMETERS ###\n",
    "decoder_out_dim = train_w2v_embed.shape[1] # dim of decoder output layer\n",
    "n_x = train_w2v_embed.shape[1]\n",
    "n_y = w2v_train_entities_cond_matrix_df.shape[1]\n",
    "train_embed = train_w2v_embed\n",
    "train_word = w2v_train_entities_cond_matrix_df\n",
    "test_embed = test_w2v_embed\n",
    "test_word = w2v_test_entities_cond_matrix_df\n",
    "### PARAMETERS ###\n",
    "\n",
    "# define encoder\n",
    "X = Input(shape=(n_x,))\n",
    "label = Input(shape=(n_y,))\n",
    "inputs = concat([X, label])\n",
    "encoder_h = Dense(encoder_dim1, activation=activ)(inputs)\n",
    "mu = Dense(n_z, activation='linear')(encoder_h)\n",
    "l_sigma = Dense(n_z, activation='linear')(encoder_h)\n",
    "\n",
    "# sample latent space\n",
    "z = Lambda(sample_z, output_shape = (n_z, ))([mu, l_sigma])\n",
    "zc = concat([z, label])\n",
    "\n",
    "# decoder\n",
    "decoder_hidden = Dense(decoder_dim, activation=activ)\n",
    "decoder_out = Dense(decoder_out_dim, activation='sigmoid')\n",
    "h_p = decoder_hidden(zc)\n",
    "outputs = decoder_out(h_p)\n",
    "\n",
    "# define graphs\n",
    "cvae = Model([X, label], outputs)\n",
    "encoder = Model([X, label], mu)\n",
    "d_in = Input(shape=(n_z+n_y,))\n",
    "d_h = decoder_hidden(d_in)\n",
    "d_out = decoder_out(d_h)\n",
    "decoder = Model(d_in, d_out)\n",
    "\n",
    "# print statistics\n",
    "cvae.compile(optimizer=optim, loss=vae_loss)\n",
    "\n",
    "cvae.summary()\n",
    "\n",
    "cvae_hist = cvae.fit([train_embed, train_word], train_embed, verbose = 2, batch_size=m, \n",
    "                 epochs=n_epoch,\n",
    "                 validation_data = ([test_embed, test_word], test_embed),\n",
    "                 callbacks = [EarlyStopping(patience = 5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORD: mathematics\n",
      "11730\n",
      "VALUE: 0.0\n",
      "(17,)\n",
      "['nikki' 'greer' 'lindsey' 'whitman' 'colbert' 'mcmahon' 'jonas' 'peyton'\n",
      " 'pete' 'carlson']\n",
      "VALUE: 0.5555555555555556\n",
      "(17,)\n",
      "['nikki' 'greer' 'lindsey' 'whitman' 'colbert' 'mcmahon' 'jonas' 'peyton'\n",
      " 'pete' 'carlson']\n",
      "VALUE: 1.1111111111111112\n",
      "(17,)\n",
      "['nikki' 'greer' 'lindsey' 'whitman' 'colbert' 'mcmahon' 'jonas' 'peyton'\n",
      " 'hyde' 'pete']\n",
      "VALUE: 1.6666666666666667\n",
      "(17,)\n",
      "['nikki' 'greer' 'lindsey' 'whitman' 'colbert' 'mcmahon' 'jonas' 'peyton'\n",
      " 'hyde' 'pete']\n",
      "VALUE: 2.2222222222222223\n",
      "(17,)\n",
      "['nikki' 'greer' 'whitman' 'lindsey' 'colbert' 'mcmahon' 'jonas' 'peyton'\n",
      " 'hyde' 'pete']\n",
      "VALUE: 2.7777777777777777\n",
      "(17,)\n",
      "['nikki' 'greer' 'whitman' 'lindsey' 'colbert' 'mcmahon' 'jonas' 'peyton'\n",
      " 'hyde' 'pete']\n",
      "VALUE: 3.3333333333333335\n",
      "(17,)\n",
      "['nikki' 'greer' 'whitman' 'lindsey' 'mcmahon' 'colbert' 'peyton' 'hyde'\n",
      " 'jonas' 'williamson']\n",
      "VALUE: 3.8888888888888893\n",
      "(17,)\n",
      "['nikki' 'greer' 'whitman' 'lindsey' 'mcmahon' 'colbert' 'peyton' 'hyde'\n",
      " 'jonas' 'williamson']\n",
      "VALUE: 4.444444444444445\n",
      "(17,)\n",
      "['nikki' 'greer' 'whitman' 'lindsey' 'mcmahon' 'colbert' 'hyde' 'peyton'\n",
      " 'jonas' 'williamson']\n",
      "VALUE: 5.0\n",
      "(17,)\n",
      "['nikki' 'greer' 'whitman' 'lindsey' 'mcmahon' 'colbert' 'hyde' 'peyton'\n",
      " 'williamson' 'jonas']\n",
      "WORD: mathematics\n",
      "11730\n",
      "VALUE: 0.0\n",
      "(17,)\n",
      "['nikki' 'greer' 'lindsey' 'whitman' 'colbert' 'mcmahon' 'jonas' 'peyton'\n",
      " 'pete' 'carlson']\n",
      "VALUE: 0.5555555555555556\n",
      "(17,)\n",
      "['nikki' 'greer' 'lindsey' 'whitman' 'colbert' 'mcmahon' 'jonas' 'peyton'\n",
      " 'pete' 'carlson']\n",
      "VALUE: 1.1111111111111112\n",
      "(17,)\n",
      "['nikki' 'greer' 'lindsey' 'whitman' 'colbert' 'mcmahon' 'jonas' 'peyton'\n",
      " 'pete' 'carlson']\n",
      "VALUE: 1.6666666666666667\n",
      "(17,)\n",
      "['nikki' 'greer' 'lindsey' 'whitman' 'colbert' 'mcmahon' 'jonas' 'peyton'\n",
      " 'pete' 'carlson']\n",
      "VALUE: 2.2222222222222223\n",
      "(17,)\n",
      "['nikki' 'greer' 'lindsey' 'whitman' 'colbert' 'mcmahon' 'jonas' 'peyton'\n",
      " 'pete' 'carlson']\n",
      "VALUE: 2.7777777777777777\n",
      "(17,)\n",
      "['nikki' 'greer' 'lindsey' 'whitman' 'colbert' 'mcmahon' 'jonas' 'peyton'\n",
      " 'pete' 'carlson']\n",
      "VALUE: 3.3333333333333335\n",
      "(17,)\n",
      "['nikki' 'greer' 'lindsey' 'whitman' 'colbert' 'mcmahon' 'jonas' 'peyton'\n",
      " 'williamson' 'pete']\n",
      "VALUE: 3.8888888888888893\n",
      "(17,)\n",
      "['nikki' 'greer' 'lindsey' 'whitman' 'colbert' 'mcmahon' 'jonas' 'peyton'\n",
      " 'williamson' 'pete']\n",
      "VALUE: 4.444444444444445\n",
      "(17,)\n",
      "['nikki' 'greer' 'whitman' 'lindsey' 'colbert' 'mcmahon' 'williamson'\n",
      " 'peyton' 'hyde' 'jonas']\n",
      "VALUE: 5.0\n",
      "(17,)\n",
      "['nikki' 'greer' 'whitman' 'lindsey' 'colbert' 'mcmahon' 'williamson'\n",
      " 'hyde' 'peyton' 'carlson']\n",
      "WORD: mathematics\n",
      "11730\n",
      "VALUE: 0.0\n",
      "(17,)\n",
      "['nikki' 'greer' 'lindsey' 'whitman' 'colbert' 'mcmahon' 'jonas' 'peyton'\n",
      " 'pete' 'carlson']\n",
      "VALUE: 0.5555555555555556\n",
      "(17,)\n",
      "['nikki' 'greer' 'lindsey' 'whitman' 'colbert' 'mcmahon' 'jonas' 'peyton'\n",
      " 'pete' 'carlson']\n",
      "VALUE: 1.1111111111111112\n",
      "(17,)\n",
      "['nikki' 'greer' 'lindsey' 'whitman' 'colbert' 'mcmahon' 'jonas' 'pete'\n",
      " 'peyton' 'carlson']\n",
      "VALUE: 1.6666666666666667\n",
      "(17,)\n",
      "['nikki' 'greer' 'lindsey' 'whitman' 'colbert' 'mcmahon' 'jonas' 'pete'\n",
      " 'peyton' 'carlson']\n",
      "VALUE: 2.2222222222222223\n",
      "(17,)\n",
      "['nikki' 'greer' 'lindsey' 'whitman' 'colbert' 'mcmahon' 'williamson'\n",
      " 'jonas' 'carlson' 'pete']\n",
      "VALUE: 2.7777777777777777\n",
      "(17,)\n",
      "['nikki' 'greer' 'lindsey' 'whitman' 'colbert' 'mcmahon' 'williamson'\n",
      " 'jonas' 'carlson' 'pete']\n",
      "VALUE: 3.3333333333333335\n",
      "(17,)\n",
      "['nikki' 'greer' 'lindsey' 'whitman' 'colbert' 'mcmahon' 'williamson'\n",
      " 'carlson' 'hyde' 'pete']\n",
      "VALUE: 3.8888888888888893\n",
      "(17,)\n",
      "['nikki' 'greer' 'lindsey' 'whitman' 'colbert' 'mcmahon' 'williamson'\n",
      " 'carlson' 'hyde' 'pete']\n",
      "VALUE: 4.444444444444445\n",
      "(17,)\n",
      "['nikki' 'greer' 'lindsey' 'whitman' 'mcmahon' 'colbert' 'williamson'\n",
      " 'carlson' 'hyde' 'pete']\n",
      "VALUE: 5.0\n",
      "(17,)\n",
      "['nikki' 'greer' 'lindsey' 'whitman' 'mcmahon' 'colbert' 'carlson'\n",
      " 'williamson' 'hyde' 'pete']\n",
      "WORD: remote\n",
      "7807\n",
      "VALUE: 0.0\n",
      "(17,)\n",
      "['nikki' 'greer' 'lindsey' 'whitman' 'colbert' 'mcmahon' 'jonas' 'peyton'\n",
      " 'pete' 'carlson']\n",
      "VALUE: 0.5555555555555556\n",
      "(17,)\n",
      "['nikki' 'greer' 'lindsey' 'whitman' 'colbert' 'mcmahon' 'jonas' 'peyton'\n",
      " 'pete' 'carlson']\n",
      "VALUE: 1.1111111111111112\n",
      "(17,)\n",
      "['nikki' 'greer' 'lindsey' 'whitman' 'colbert' 'mcmahon' 'jonas' 'peyton'\n",
      " 'hyde' 'pete']\n",
      "VALUE: 1.6666666666666667\n",
      "(17,)\n",
      "['nikki' 'greer' 'lindsey' 'whitman' 'colbert' 'mcmahon' 'jonas' 'peyton'\n",
      " 'hyde' 'pete']\n",
      "VALUE: 2.2222222222222223\n",
      "(17,)\n",
      "['nikki' 'greer' 'whitman' 'lindsey' 'colbert' 'mcmahon' 'jonas' 'peyton'\n",
      " 'hyde' 'pete']\n",
      "VALUE: 2.7777777777777777\n",
      "(17,)\n",
      "['nikki' 'greer' 'whitman' 'lindsey' 'colbert' 'mcmahon' 'jonas' 'peyton'\n",
      " 'hyde' 'pete']\n",
      "VALUE: 3.3333333333333335\n",
      "(17,)\n",
      "['nikki' 'greer' 'whitman' 'lindsey' 'mcmahon' 'colbert' 'peyton' 'hyde'\n",
      " 'jonas' 'williamson']\n",
      "VALUE: 3.8888888888888893\n",
      "(17,)\n",
      "['nikki' 'greer' 'whitman' 'lindsey' 'mcmahon' 'colbert' 'peyton' 'hyde'\n",
      " 'jonas' 'williamson']\n",
      "VALUE: 4.444444444444445\n",
      "(17,)\n",
      "['nikki' 'greer' 'whitman' 'lindsey' 'mcmahon' 'colbert' 'hyde' 'peyton'\n",
      " 'jonas' 'williamson']\n",
      "VALUE: 5.0\n",
      "(17,)\n",
      "['nikki' 'greer' 'whitman' 'lindsey' 'mcmahon' 'colbert' 'hyde' 'peyton'\n",
      " 'williamson' 'jonas']\n",
      "WORD: remote\n",
      "7807\n",
      "VALUE: 0.0\n",
      "(17,)\n",
      "['nikki' 'greer' 'lindsey' 'whitman' 'colbert' 'mcmahon' 'jonas' 'peyton'\n",
      " 'pete' 'carlson']\n",
      "VALUE: 0.5555555555555556\n",
      "(17,)\n",
      "['nikki' 'greer' 'lindsey' 'whitman' 'colbert' 'mcmahon' 'jonas' 'peyton'\n",
      " 'pete' 'carlson']\n",
      "VALUE: 1.1111111111111112\n",
      "(17,)\n",
      "['nikki' 'greer' 'lindsey' 'whitman' 'colbert' 'mcmahon' 'jonas' 'peyton'\n",
      " 'pete' 'carlson']\n",
      "VALUE: 1.6666666666666667\n",
      "(17,)\n",
      "['nikki' 'greer' 'lindsey' 'whitman' 'colbert' 'mcmahon' 'jonas' 'peyton'\n",
      " 'pete' 'carlson']\n",
      "VALUE: 2.2222222222222223\n",
      "(17,)\n",
      "['nikki' 'greer' 'lindsey' 'whitman' 'colbert' 'mcmahon' 'jonas' 'peyton'\n",
      " 'pete' 'carlson']\n",
      "VALUE: 2.7777777777777777\n",
      "(17,)\n",
      "['nikki' 'greer' 'lindsey' 'whitman' 'colbert' 'mcmahon' 'jonas' 'peyton'\n",
      " 'pete' 'carlson']\n",
      "VALUE: 3.3333333333333335\n",
      "(17,)\n",
      "['nikki' 'greer' 'lindsey' 'whitman' 'colbert' 'mcmahon' 'jonas' 'peyton'\n",
      " 'williamson' 'pete']\n",
      "VALUE: 3.8888888888888893\n",
      "(17,)\n",
      "['nikki' 'greer' 'lindsey' 'whitman' 'colbert' 'mcmahon' 'jonas' 'peyton'\n",
      " 'williamson' 'pete']\n",
      "VALUE: 4.444444444444445\n",
      "(17,)\n",
      "['nikki' 'greer' 'whitman' 'lindsey' 'colbert' 'mcmahon' 'williamson'\n",
      " 'peyton' 'hyde' 'jonas']\n",
      "VALUE: 5.0\n",
      "(17,)\n",
      "['nikki' 'greer' 'whitman' 'lindsey' 'colbert' 'mcmahon' 'williamson'\n",
      " 'hyde' 'peyton' 'carlson']\n",
      "WORD: internet\n",
      "503\n",
      "VALUE: 0.0\n",
      "(17,)\n",
      "['nikki' 'greer' 'lindsey' 'whitman' 'colbert' 'mcmahon' 'jonas' 'peyton'\n",
      " 'pete' 'carlson']\n",
      "VALUE: 0.5555555555555556\n",
      "(17,)\n",
      "['nikki' 'greer' 'lindsey' 'whitman' 'colbert' 'mcmahon' 'jonas' 'peyton'\n",
      " 'pete' 'carlson']\n",
      "VALUE: 1.1111111111111112\n",
      "(17,)\n",
      "['nikki' 'greer' 'lindsey' 'whitman' 'colbert' 'mcmahon' 'jonas' 'carlson'\n",
      " 'pete' 'peyton']\n",
      "VALUE: 1.6666666666666667\n",
      "(17,)\n",
      "['nikki' 'greer' 'lindsey' 'whitman' 'colbert' 'mcmahon' 'jonas' 'carlson'\n",
      " 'pete' 'peyton']\n",
      "VALUE: 2.2222222222222223\n",
      "(17,)\n",
      "['nikki' 'greer' 'lindsey' 'whitman' 'mcmahon' 'colbert' 'jonas' 'carlson'\n",
      " 'pete' 'hyde']\n",
      "VALUE: 2.7777777777777777\n",
      "(17,)\n",
      "['nikki' 'greer' 'lindsey' 'whitman' 'mcmahon' 'colbert' 'jonas' 'carlson'\n",
      " 'pete' 'hyde']\n",
      "VALUE: 3.3333333333333335\n",
      "(17,)\n",
      "['nikki' 'greer' 'lindsey' 'whitman' 'mcmahon' 'colbert' 'jonas' 'carlson'\n",
      " 'clarkson' 'hyde']\n",
      "VALUE: 3.8888888888888893\n",
      "(17,)\n",
      "['nikki' 'greer' 'lindsey' 'whitman' 'mcmahon' 'colbert' 'jonas' 'carlson'\n",
      " 'clarkson' 'hyde']\n",
      "VALUE: 4.444444444444445\n",
      "(17,)\n",
      "['nikki' 'greer' 'lindsey' 'whitman' 'mcmahon' 'colbert' 'jonas' 'carlson'\n",
      " 'hyde' 'clarkson']\n",
      "VALUE: 5.0\n",
      "(17,)\n",
      "['nikki' 'greer' 'lindsey' 'whitman' 'mcmahon' 'carlson' 'colbert' 'jonas'\n",
      " 'hyde' 'williamson']\n",
      "WORD: internet\n",
      "503\n",
      "VALUE: 0.0\n",
      "(17,)\n",
      "['nikki' 'greer' 'lindsey' 'whitman' 'colbert' 'mcmahon' 'jonas' 'peyton'\n",
      " 'pete' 'carlson']\n",
      "VALUE: 0.5555555555555556\n",
      "(17,)\n",
      "['nikki' 'greer' 'lindsey' 'whitman' 'colbert' 'mcmahon' 'jonas' 'peyton'\n",
      " 'pete' 'carlson']\n",
      "VALUE: 1.1111111111111112\n",
      "(17,)\n",
      "['nikki' 'greer' 'lindsey' 'whitman' 'colbert' 'mcmahon' 'jonas' 'peyton'\n",
      " 'carlson' 'pete']\n",
      "VALUE: 1.6666666666666667\n",
      "(17,)\n",
      "['nikki' 'greer' 'lindsey' 'whitman' 'colbert' 'mcmahon' 'jonas' 'peyton'\n",
      " 'carlson' 'pete']\n",
      "VALUE: 2.2222222222222223\n",
      "(17,)\n",
      "['nikki' 'greer' 'lindsey' 'whitman' 'mcmahon' 'colbert' 'peyton'\n",
      " 'carlson' 'jonas' 'hyde']\n",
      "VALUE: 2.7777777777777777\n",
      "(17,)\n",
      "['nikki' 'greer' 'lindsey' 'whitman' 'mcmahon' 'colbert' 'peyton'\n",
      " 'carlson' 'jonas' 'hyde']\n",
      "VALUE: 3.3333333333333335\n",
      "(17,)\n",
      "['nikki' 'greer' 'lindsey' 'whitman' 'mcmahon' 'colbert' 'carlson'\n",
      " 'peyton' 'hyde' 'jonas']\n",
      "VALUE: 3.8888888888888893\n",
      "(17,)\n",
      "['nikki' 'greer' 'lindsey' 'whitman' 'mcmahon' 'colbert' 'carlson'\n",
      " 'peyton' 'hyde' 'jonas']\n",
      "VALUE: 4.444444444444445\n",
      "(17,)\n",
      "['nikki' 'greer' 'lindsey' 'whitman' 'mcmahon' 'colbert' 'carlson' 'hyde'\n",
      " 'peyton' 'jonas']\n",
      "VALUE: 5.0\n",
      "(17,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nikki' 'greer' 'whitman' 'lindsey' 'mcmahon' 'carlson' 'hyde' 'colbert'\n",
      " 'peyton' 'williamson']\n",
      "WORD: internet\n",
      "503\n",
      "VALUE: 0.0\n",
      "(17,)\n",
      "['nikki' 'greer' 'lindsey' 'whitman' 'colbert' 'mcmahon' 'jonas' 'peyton'\n",
      " 'pete' 'carlson']\n",
      "VALUE: 0.5555555555555556\n",
      "(17,)\n",
      "['nikki' 'greer' 'lindsey' 'whitman' 'colbert' 'mcmahon' 'jonas' 'peyton'\n",
      " 'pete' 'carlson']\n",
      "VALUE: 1.1111111111111112\n",
      "(17,)\n",
      "['nikki' 'greer' 'lindsey' 'whitman' 'colbert' 'mcmahon' 'jonas' 'peyton'\n",
      " 'hyde' 'pete']\n",
      "VALUE: 1.6666666666666667\n",
      "(17,)\n",
      "['nikki' 'greer' 'lindsey' 'whitman' 'colbert' 'mcmahon' 'jonas' 'peyton'\n",
      " 'hyde' 'pete']\n",
      "VALUE: 2.2222222222222223\n",
      "(17,)\n",
      "['nikki' 'greer' 'whitman' 'lindsey' 'colbert' 'mcmahon' 'jonas' 'peyton'\n",
      " 'hyde' 'pete']\n",
      "VALUE: 2.7777777777777777\n",
      "(17,)\n",
      "['nikki' 'greer' 'whitman' 'lindsey' 'colbert' 'mcmahon' 'jonas' 'peyton'\n",
      " 'hyde' 'pete']\n",
      "VALUE: 3.3333333333333335\n",
      "(17,)\n",
      "['nikki' 'greer' 'whitman' 'lindsey' 'mcmahon' 'colbert' 'peyton' 'hyde'\n",
      " 'jonas' 'williamson']\n",
      "VALUE: 3.8888888888888893\n",
      "(17,)\n",
      "['nikki' 'greer' 'whitman' 'lindsey' 'mcmahon' 'colbert' 'peyton' 'hyde'\n",
      " 'jonas' 'williamson']\n",
      "VALUE: 4.444444444444445\n",
      "(17,)\n",
      "['nikki' 'greer' 'whitman' 'lindsey' 'mcmahon' 'colbert' 'hyde' 'peyton'\n",
      " 'jonas' 'williamson']\n",
      "VALUE: 5.0\n",
      "(17,)\n",
      "['nikki' 'greer' 'whitman' 'lindsey' 'mcmahon' 'colbert' 'hyde' 'peyton'\n",
      " 'williamson' 'jonas']\n",
      "WORD: internet\n",
      "503\n",
      "VALUE: 0.0\n",
      "(17,)\n",
      "['nikki' 'greer' 'lindsey' 'whitman' 'colbert' 'mcmahon' 'jonas' 'peyton'\n",
      " 'pete' 'carlson']\n",
      "VALUE: 0.5555555555555556\n",
      "(17,)\n",
      "['nikki' 'greer' 'lindsey' 'whitman' 'colbert' 'mcmahon' 'jonas' 'peyton'\n",
      " 'pete' 'carlson']\n",
      "VALUE: 1.1111111111111112\n",
      "(17,)\n",
      "['nikki' 'greer' 'lindsey' 'whitman' 'colbert' 'mcmahon' 'jonas' 'peyton'\n",
      " 'pete' 'carlson']\n",
      "VALUE: 1.6666666666666667\n",
      "(17,)\n",
      "['nikki' 'greer' 'lindsey' 'whitman' 'colbert' 'mcmahon' 'jonas' 'peyton'\n",
      " 'pete' 'carlson']\n",
      "VALUE: 2.2222222222222223\n",
      "(17,)\n",
      "['nikki' 'greer' 'lindsey' 'whitman' 'colbert' 'mcmahon' 'jonas' 'peyton'\n",
      " 'pete' 'carlson']\n",
      "VALUE: 2.7777777777777777\n",
      "(17,)\n",
      "['nikki' 'greer' 'lindsey' 'whitman' 'colbert' 'mcmahon' 'jonas' 'peyton'\n",
      " 'pete' 'carlson']\n",
      "VALUE: 3.3333333333333335\n",
      "(17,)\n",
      "['nikki' 'greer' 'lindsey' 'whitman' 'colbert' 'mcmahon' 'jonas' 'peyton'\n",
      " 'williamson' 'pete']\n",
      "VALUE: 3.8888888888888893\n",
      "(17,)\n",
      "['nikki' 'greer' 'lindsey' 'whitman' 'colbert' 'mcmahon' 'jonas' 'peyton'\n",
      " 'williamson' 'pete']\n",
      "VALUE: 4.444444444444445\n",
      "(17,)\n",
      "['nikki' 'greer' 'whitman' 'lindsey' 'colbert' 'mcmahon' 'williamson'\n",
      " 'peyton' 'hyde' 'jonas']\n",
      "VALUE: 5.0\n",
      "(17,)\n",
      "['nikki' 'greer' 'whitman' 'lindsey' 'colbert' 'mcmahon' 'williamson'\n",
      " 'hyde' 'peyton' 'carlson']\n"
     ]
    }
   ],
   "source": [
    "find_top_words(train_w2v_embed, train_w2v_token, test_w2v_embed, test_w2v_token, w2v_train_entities_cond_matrix_df, \"word2vec\", \"entity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_28 (InputLayer)           (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_29 (InputLayer)           (None, 1000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 1300)         0           input_28[0][0]                   \n",
      "                                                                 input_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_46 (Dense)                (None, 128)          166528      concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_47 (Dense)                (None, 75)           9675        dense_46[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_48 (Dense)                (None, 75)           9675        dense_46[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 75)           0           dense_47[0][0]                   \n",
      "                                                                 dense_48[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 1075)         0           lambda_10[0][0]                  \n",
      "                                                                 input_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_49 (Dense)                (None, 128)          137728      concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_50 (Dense)                (None, 300)          38700       dense_49[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 362,306\n",
      "Trainable params: 362,306\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 12000 samples, validate on 3000 samples\n",
      "Epoch 1/50\n",
      "12000/12000 [==============================] - 7s 601us/step - loss: 0.1405 - val_loss: 0.1363\n",
      "Epoch 2/50\n",
      "12000/12000 [==============================] - 6s 483us/step - loss: 0.1355 - val_loss: 0.1353\n",
      "Epoch 3/50\n",
      "12000/12000 [==============================] - 5s 443us/step - loss: 0.1347 - val_loss: 0.1345\n",
      "Epoch 4/50\n",
      "12000/12000 [==============================] - 5s 419us/step - loss: 0.1337 - val_loss: 0.1336\n",
      "Epoch 5/50\n",
      "12000/12000 [==============================] - 5s 442us/step - loss: 0.1328 - val_loss: 0.1325\n",
      "Epoch 6/50\n",
      "12000/12000 [==============================] - 6s 462us/step - loss: 0.1314 - val_loss: 0.1307\n",
      "Epoch 7/50\n",
      "12000/12000 [==============================] - 5s 450us/step - loss: 0.1295 - val_loss: 0.1290\n",
      "Epoch 8/50\n",
      "12000/12000 [==============================] - 5s 428us/step - loss: 0.1277 - val_loss: 0.1272\n",
      "Epoch 9/50\n",
      "12000/12000 [==============================] - 5s 419us/step - loss: 0.1257 - val_loss: 0.1254\n",
      "Epoch 10/50\n",
      "12000/12000 [==============================] - 5s 420us/step - loss: 0.1239 - val_loss: 0.1238\n",
      "Epoch 11/50\n",
      "12000/12000 [==============================] - 5s 405us/step - loss: 0.1223 - val_loss: 0.1223\n",
      "Epoch 12/50\n",
      "12000/12000 [==============================] - 5s 438us/step - loss: 0.1209 - val_loss: 0.1211\n",
      "Epoch 13/50\n",
      "12000/12000 [==============================] - 5s 431us/step - loss: 0.1196 - val_loss: 0.1199\n",
      "Epoch 14/50\n",
      "12000/12000 [==============================] - 5s 427us/step - loss: 0.1184 - val_loss: 0.1189\n",
      "Epoch 15/50\n",
      "12000/12000 [==============================] - 5s 405us/step - loss: 0.1174 - val_loss: 0.1182\n",
      "Epoch 16/50\n",
      "12000/12000 [==============================] - 5s 384us/step - loss: 0.1166 - val_loss: 0.1174\n",
      "Epoch 17/50\n",
      "12000/12000 [==============================] - 5s 402us/step - loss: 0.1159 - val_loss: 0.1168\n",
      "Epoch 18/50\n",
      "12000/12000 [==============================] - 5s 384us/step - loss: 0.1153 - val_loss: 0.1163\n",
      "Epoch 19/50\n",
      "12000/12000 [==============================] - 5s 388us/step - loss: 0.1148 - val_loss: 0.1159\n",
      "Epoch 20/50\n",
      "12000/12000 [==============================] - 5s 390us/step - loss: 0.1144 - val_loss: 0.1156\n",
      "Epoch 21/50\n",
      "12000/12000 [==============================] - 5s 402us/step - loss: 0.1140 - val_loss: 0.1152\n",
      "Epoch 22/50\n",
      "12000/12000 [==============================] - 5s 420us/step - loss: 0.1136 - val_loss: 0.1148\n",
      "Epoch 23/50\n",
      "12000/12000 [==============================] - 5s 411us/step - loss: 0.1133 - val_loss: 0.1145\n",
      "Epoch 24/50\n",
      "12000/12000 [==============================] - 5s 431us/step - loss: 0.1130 - val_loss: 0.1143\n",
      "Epoch 25/50\n",
      "12000/12000 [==============================] - 6s 462us/step - loss: 0.1127 - val_loss: 0.1141\n",
      "Epoch 26/50\n",
      "12000/12000 [==============================] - 5s 443us/step - loss: 0.1125 - val_loss: 0.1138\n",
      "Epoch 27/50\n",
      "12000/12000 [==============================] - 5s 388us/step - loss: 0.1122 - val_loss: 0.1136\n",
      "Epoch 28/50\n",
      "12000/12000 [==============================] - 5s 379us/step - loss: 0.1120 - val_loss: 0.1135\n",
      "Epoch 29/50\n",
      "12000/12000 [==============================] - 5s 382us/step - loss: 0.1118 - val_loss: 0.1133\n",
      "Epoch 30/50\n",
      "12000/12000 [==============================] - 5s 427us/step - loss: 0.1116 - val_loss: 0.1131\n",
      "Epoch 31/50\n",
      "12000/12000 [==============================] - 5s 444us/step - loss: 0.1114 - val_loss: 0.1130\n",
      "Epoch 32/50\n",
      "12000/12000 [==============================] - 5s 406us/step - loss: 0.1113 - val_loss: 0.1129\n",
      "Epoch 33/50\n",
      "12000/12000 [==============================] - 5s 405us/step - loss: 0.1112 - val_loss: 0.1128\n",
      "Epoch 34/50\n",
      "12000/12000 [==============================] - 5s 407us/step - loss: 0.1110 - val_loss: 0.1127\n",
      "Epoch 35/50\n",
      "12000/12000 [==============================] - 5s 414us/step - loss: 0.1109 - val_loss: 0.1126\n",
      "Epoch 36/50\n",
      "12000/12000 [==============================] - 5s 386us/step - loss: 0.1109 - val_loss: 0.1125\n",
      "Epoch 37/50\n",
      "12000/12000 [==============================] - 5s 402us/step - loss: 0.1107 - val_loss: 0.1124\n",
      "Epoch 38/50\n",
      "12000/12000 [==============================] - 5s 401us/step - loss: 0.1106 - val_loss: 0.1123\n",
      "Epoch 39/50\n",
      "12000/12000 [==============================] - 5s 405us/step - loss: 0.1105 - val_loss: 0.1123\n",
      "Epoch 40/50\n",
      "12000/12000 [==============================] - 5s 423us/step - loss: 0.1105 - val_loss: 0.1123\n",
      "Epoch 41/50\n",
      "12000/12000 [==============================] - 5s 417us/step - loss: 0.1104 - val_loss: 0.1121\n",
      "Epoch 42/50\n",
      "12000/12000 [==============================] - 5s 377us/step - loss: 0.1103 - val_loss: 0.1121\n",
      "Epoch 43/50\n",
      "12000/12000 [==============================] - 4s 362us/step - loss: 0.1102 - val_loss: 0.1121\n",
      "Epoch 44/50\n",
      "12000/12000 [==============================] - 4s 358us/step - loss: 0.1101 - val_loss: 0.1120\n",
      "Epoch 45/50\n",
      "12000/12000 [==============================] - 4s 354us/step - loss: 0.1101 - val_loss: 0.1119\n",
      "Epoch 46/50\n",
      "12000/12000 [==============================] - 4s 374us/step - loss: 0.1099 - val_loss: 0.1118\n",
      "Epoch 47/50\n",
      "12000/12000 [==============================] - 5s 406us/step - loss: 0.1098 - val_loss: 0.1117\n",
      "Epoch 48/50\n",
      "12000/12000 [==============================] - 5s 432us/step - loss: 0.1098 - val_loss: 0.1117\n",
      "Epoch 49/50\n",
      "12000/12000 [==============================] - 5s 411us/step - loss: 0.1097 - val_loss: 0.1116\n",
      "Epoch 50/50\n",
      "12000/12000 [==============================] - 5s 409us/step - loss: 0.1096 - val_loss: 0.1116\n"
     ]
    }
   ],
   "source": [
    "### PARAMETERS ###\n",
    "decoder_out_dim = train_glove_embed.shape[1] # dim of decoder output layer\n",
    "n_x = train_glove_embed.shape[1]\n",
    "n_y = sg_train_word_embed.shape[1]\n",
    "train_embed = train_glove_embed\n",
    "train_word = sg_train_word_embed\n",
    "test_embed = test_glove_embed\n",
    "test_word = sg_test_word_embed\n",
    "### PARAMETERS ###\n",
    "\n",
    "# define encoder\n",
    "X = Input(shape=(n_x,))\n",
    "label = Input(shape=(n_y,))\n",
    "inputs = concat([X, label])\n",
    "encoder_h = Dense(encoder_dim1, activation=activ)(inputs)\n",
    "mu = Dense(n_z, activation='linear')(encoder_h)\n",
    "l_sigma = Dense(n_z, activation='linear')(encoder_h)\n",
    "\n",
    "# sample latent space\n",
    "z = Lambda(sample_z, output_shape = (n_z, ))([mu, l_sigma])\n",
    "zc = concat([z, label])\n",
    "\n",
    "# decoder\n",
    "decoder_hidden = Dense(decoder_dim, activation=activ)\n",
    "decoder_out = Dense(decoder_out_dim, activation='sigmoid')\n",
    "h_p = decoder_hidden(zc)\n",
    "outputs = decoder_out(h_p)\n",
    "\n",
    "# define graphs\n",
    "cvae = Model([X, label], outputs)\n",
    "encoder = Model([X, label], mu)\n",
    "d_in = Input(shape=(n_z+n_y,))\n",
    "d_h = decoder_hidden(d_in)\n",
    "d_out = decoder_out(d_h)\n",
    "decoder = Model(d_in, d_out)\n",
    "\n",
    "# print statistics\n",
    "cvae.compile(optimizer=optim, loss=vae_loss)\n",
    "\n",
    "cvae.summary()\n",
    "\n",
    "cvae_hist = cvae.fit([train_embed, train_word], train_embed, verbose = 1, batch_size=m, \n",
    "                 epochs=n_epoch,\n",
    "                 validation_data = ([test_embed, test_word], test_embed),\n",
    "                 callbacks = [EarlyStopping(patience = 5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORD: mathematics\n",
      "8341\n",
      "VALUE: 0.0\n",
      "(1000,)\n",
      "['disability' 'trouble' 'accident' 'situations' 'thread' 'grenade'\n",
      " 'dragons' 'mistake' 'ricky' 'reeves']\n",
      "VALUE: 0.5555555555555556\n",
      "(1000,)\n",
      "['disability' 'trouble' 'situations' 'accident' 'reeves' 'thread' 'ricky'\n",
      " 'ghost' 'everybody' 'mike']\n",
      "VALUE: 1.1111111111111112\n",
      "(1000,)\n",
      "['situations' 'disability' 'trouble' 'reeves' 'everybody' 'ricky' 'mike'\n",
      " 'accident' 'ghost' 'somebody']\n",
      "VALUE: 1.6666666666666667\n",
      "(1000,)\n",
      "['situations' 'disability' 'trouble' 'reeves' 'everybody' 'somebody'\n",
      " 'mike' 'ricky' 'camera' 'ghost']\n",
      "VALUE: 2.2222222222222223\n",
      "(1000,)\n",
      "['situations' 'trouble' 'disability' 'everybody' 'camera' 'reeves'\n",
      " 'somebody' 'lights' 'mike' 'guy']\n",
      "VALUE: 2.7777777777777777\n",
      "(1000,)\n",
      "['situations' 'camera' 'trouble' 'lights' 'disability' 'somebody'\n",
      " 'everybody' 'guy' 'printer' 'reeves']\n",
      "VALUE: 3.3333333333333335\n",
      "(1000,)\n",
      "['situations' 'camera' 'lights' 'guy' 'trouble' 'somebody' 'everybody'\n",
      " 'disability' 'screen' 'chip']\n",
      "VALUE: 3.8888888888888893\n",
      "(1000,)\n",
      "['camera' 'situations' 'lights' 'guy' 'trouble' 'chip' 'screen' 'somebody'\n",
      " 'bulb' 'everybody']\n",
      "VALUE: 4.444444444444445\n",
      "(1000,)\n",
      "['camera' 'lights' 'situations' 'guy' 'chip' 'screen' 'bulb' 'trouble'\n",
      " 'somebody' 'cobra']\n",
      "VALUE: 5.0\n",
      "(1000,)\n",
      "['camera' 'lights' 'bulb' 'chip' 'guy' 'situations' 'screen' 'trouble'\n",
      " 'somebody' 'cobra']\n",
      "WORD: mathematics\n",
      "8341\n",
      "VALUE: 0.0\n",
      "(1000,)\n",
      "['situations' 'trouble' 'disability' 'accident' 'somebody' 'reeves'\n",
      " 'ghost' 'mike' 'mistake' 'everybody']\n",
      "VALUE: 0.5555555555555556\n",
      "(1000,)\n",
      "['trouble' 'situations' 'disability' 'reeves' 'accident' 'ghost' 'mike'\n",
      " 'everybody' 'somebody' 'ricky']\n",
      "VALUE: 1.1111111111111112\n",
      "(1000,)\n",
      "['disability' 'trouble' 'situations' 'reeves' 'ricky' 'everybody'\n",
      " 'accident' 'mike' 'thread' 'snyder']\n",
      "VALUE: 1.6666666666666667\n",
      "(1000,)\n",
      "['disability' 'trouble' 'situations' 'ricky' 'snyder' 'reeves' 'thread'\n",
      " 'everybody' 'marty' 'jeff']\n",
      "VALUE: 2.2222222222222223\n",
      "(1000,)\n",
      "['disability' 'snyder' 'ricky' 'trouble' 'greenville' 'thread'\n",
      " 'situations' 'jeff' 'kelly' 'reeves']\n",
      "VALUE: 2.7777777777777777\n",
      "(1000,)\n",
      "['disability' 'snyder' 'greenville' 'ricky' 'kelly' 'thread' 'jeff'\n",
      " 'privacy' 'disorder' 'pedro']\n",
      "VALUE: 3.3333333333333335\n",
      "(1000,)\n",
      "['snyder' 'disability' 'greenville' 'kelly' 'ricky' 'privacy' 'thread'\n",
      " 'william' 'disorder' 'jeff']\n",
      "VALUE: 3.8888888888888893\n",
      "(1000,)\n",
      "['snyder' 'disability' 'greenville' 'william' 'kelly' 'privacy' 'ricky'\n",
      " 'disorder' 'thread' 'pedro']\n",
      "VALUE: 4.444444444444445\n",
      "(1000,)\n",
      "['william' 'snyder' 'greenville' 'kelly' 'disability' 'privacy' 'disorder'\n",
      " 'ricky' 'lebanon' 'thread']\n",
      "VALUE: 5.0\n",
      "(1000,)\n",
      "['william' 'snyder' 'greenville' 'lebanon' 'ontario' 'privacy' 'disorder'\n",
      " 'kelly' 'woven' 'disability']\n",
      "WORD: mathematics\n",
      "8341\n",
      "VALUE: 0.0\n",
      "(1000,)\n",
      "['situations' 'reeves' 'disability' 'trouble' 'mike' 'accident' 'ricky'\n",
      " 'camera' 'thread' 'everybody']\n",
      "VALUE: 0.5555555555555556\n",
      "(1000,)\n",
      "['situations' 'disability' 'trouble' 'reeves' 'accident' 'mike' 'ricky'\n",
      " 'everybody' 'thread' 'ghost']\n",
      "VALUE: 1.1111111111111112\n",
      "(1000,)\n",
      "['disability' 'trouble' 'situations' 'everybody' 'ghost' 'reeves' 'ricky'\n",
      " 'somebody' 'thread' 'accident']\n",
      "VALUE: 1.6666666666666667\n",
      "(1000,)\n",
      "['trouble' 'disability' 'everybody' 'ghost' 'disorder' 'printer'\n",
      " 'situations' 'dragons' 'somebody' 'schizophrenia']\n",
      "VALUE: 2.2222222222222223\n",
      "(1000,)\n",
      "['trouble' 'disability' 'schizophrenia' 'printer' 'disorder' 'everybody'\n",
      " 'dragons' 'ghost' 'somebody' 'kid']\n",
      "VALUE: 2.7777777777777777\n",
      "(1000,)\n",
      "['trouble' 'schizophrenia' 'disability' 'printer' 'disorder' 'dragons'\n",
      " 'everybody' 'kid' 'ghost' 'somebody']\n",
      "VALUE: 3.3333333333333335\n",
      "(1000,)\n",
      "['schizophrenia' 'trouble' 'printer' 'disability' 'disorder' 'dragons'\n",
      " 'armed' 'kid' 'gangsters' 'everybody']\n",
      "VALUE: 3.8888888888888893\n",
      "(1000,)\n",
      "['schizophrenia' 'trouble' 'disorder' 'printer' 'armed' 'dragons'\n",
      " 'gangsters' 'disability' 'challenges' 'kid']\n",
      "VALUE: 4.444444444444445\n",
      "(1000,)\n",
      "['schizophrenia' 'trouble' 'armed' 'disorder' 'gangsters' 'dragons'\n",
      " 'printer' 'backgrounds' 'challenges' 'disability']\n",
      "VALUE: 5.0\n",
      "(1000,)\n",
      "['schizophrenia' 'trouble' 'backgrounds' 'armed' 'gangsters' 'disorder'\n",
      " 'challenges' 'dragons' 'buccaneers' 'printer']\n",
      "WORD: remote\n",
      "2616\n",
      "VALUE: 0.0\n",
      "(1000,)\n",
      "['snyder' 'trace' 'mill' 'sawyer' 'clue' 'controller' 'alone' 'arcade'\n",
      " 'division' 'helmet']\n",
      "VALUE: 0.5555555555555556\n",
      "(1000,)\n",
      "['snyder' 'alone' 'trace' 'nightmares' 'mill' 'rooted' 'forever'\n",
      " 'division' 'sawyer' 'arcade']\n",
      "VALUE: 1.1111111111111112\n",
      "(1000,)\n",
      "['alone' 'snyder' 'nightmares' 'trace' 'untouched' 'rooted' 'forever'\n",
      " 'knowing' 'division' 'mom']\n",
      "VALUE: 1.6666666666666667\n",
      "(1000,)\n",
      "['alone' 'nightmares' 'untouched' 'knowing' 'rooted' 'managerial'\n",
      " 'forever' 'snyder' 'trace' 'mom']\n",
      "VALUE: 2.2222222222222223\n",
      "(1000,)\n",
      "['alone' 'managerial' 'knowing' 'nightmares' 'untouched' 'forever'\n",
      " 'rooted' 'pat' 'all' 'mom']\n",
      "VALUE: 2.7777777777777777\n",
      "(1000,)\n",
      "['alone' 'managerial' 'knowing' 'untouched' 'nightmares' 'pat' 'all'\n",
      " 'forever' 'rooted' 'section']\n",
      "VALUE: 3.3333333333333335\n",
      "(1000,)\n",
      "['alone' 'managerial' 'knowing' 'untouched' 'pat' 'all' 'nightmares'\n",
      " 'forever' 'section' 'classroom']\n",
      "VALUE: 3.8888888888888893\n",
      "(1000,)\n",
      "['alone' 'managerial' 'pat' 'all' 'untouched' 'knowing' 'nightmares'\n",
      " 'forever' 'section' 'classroom']\n",
      "VALUE: 4.444444444444445\n",
      "(1000,)\n",
      "['alone' 'managerial' 'all' 'pat' 'untouched' 'knowing' 'nuclear'\n",
      " 'classroom' 'nightmares' 'forever']\n",
      "VALUE: 5.0\n",
      "(1000,)\n",
      "['alone' 'managerial' 'all' 'pat' 'untouched' 'other' 'nuclear'\n",
      " 'classroom' 'administrative' 'section']\n",
      "WORD: remote\n",
      "2616\n",
      "VALUE: 0.0\n",
      "(1000,)\n",
      "['alone' 'trace' 'nightmares' 'snyder' 'arcade' 'untouched' 'division'\n",
      " 'plead' 'kidd' 'table']\n",
      "VALUE: 0.5555555555555556\n",
      "(1000,)\n",
      "['alone' 'snyder' 'trace' 'nightmares' 'rooted' 'untouched' 'forever'\n",
      " 'mill' 'division' 'arcade']\n",
      "VALUE: 1.1111111111111112\n",
      "(1000,)\n",
      "['snyder' 'trace' 'rooted' 'alone' 'mill' 'forever' 'prisoners'\n",
      " 'nightmares' 'literally' 'woods']\n",
      "VALUE: 1.6666666666666667\n",
      "(1000,)\n",
      "['snyder' 'rooted' 'trace' 'mill' 'prisoners' 'woods' 'literally' 'thread'\n",
      " 'forever' 'shadows']\n",
      "VALUE: 2.2222222222222223\n",
      "(1000,)\n",
      "['rooted' 'snyder' 'woods' 'prisoners' 'mill' 'thread' 'trace' 'literally'\n",
      " 'questions' 'shadows']\n",
      "VALUE: 2.7777777777777777\n",
      "(1000,)\n",
      "['rooted' 'prisoners' 'woods' 'snyder' 'mill' 'thread' 'questions'\n",
      " 'literally' 'trace' 'question']\n",
      "VALUE: 3.3333333333333335\n",
      "(1000,)\n",
      "['prisoners' 'rooted' 'woods' 'questions' 'mill' 'snyder' 'thread'\n",
      " 'literally' 'question' 'home']\n",
      "VALUE: 3.8888888888888893\n",
      "(1000,)\n",
      "['prisoners' 'rooted' 'questions' 'woods' 'mill' 'thread' 'question'\n",
      " 'literally' 'snyder' 'home']\n",
      "VALUE: 4.444444444444445\n",
      "(1000,)\n",
      "['prisoners' 'rooted' 'questions' 'question' 'mill' 'woods' 'literally'\n",
      " 'thread' 'home' 'managerial']\n",
      "VALUE: 5.0\n",
      "(1000,)\n",
      "['prisoners' 'questions' 'rooted' 'question' 'literally' 'mill'\n",
      " 'managerial' 'home' 'relevance' 'woods']\n",
      "WORD: remote\n",
      "2616\n",
      "VALUE: 0.0\n",
      "(1000,)\n",
      "['knowing' 'belt' 'trace' 'alone' 'pocket' 'snyder' 'belts' 'write' 'find'\n",
      " 'imaginary']\n",
      "VALUE: 0.5555555555555556\n",
      "(1000,)\n",
      "['alone' 'snyder' 'trace' 'nightmares' 'rooted' 'forever' 'mill'\n",
      " 'untouched' 'division' 'arcade']\n",
      "VALUE: 1.1111111111111112\n",
      "(1000,)\n",
      "['rooted' 'snyder' 'alone' 'nightmares' 'storytelling' 'forever' 'kidd'\n",
      " 'arcade' 'division' 'trace']\n",
      "VALUE: 1.6666666666666667\n",
      "(1000,)\n",
      "['rooted' 'snyder' 'storytelling' 'nightmares' 'kidd' 'alone' 'dinosaurs'\n",
      " 'arcade' 'division' 'void']\n",
      "VALUE: 2.2222222222222223\n",
      "(1000,)\n",
      "['rooted' 'storytelling' 'snyder' 'void' 'dinosaurs' 'arcade' 'nightmares'\n",
      " 'pottery' 'division' 'kidd']\n",
      "VALUE: 2.7777777777777777\n",
      "(1000,)\n",
      "['rooted' 'storytelling' 'void' 'dinosaurs' 'arcade' 'pottery' 'snyder'\n",
      " 'llc' 'division' 'nightmares']\n",
      "VALUE: 3.3333333333333335\n",
      "(1000,)\n",
      "['rooted' 'storytelling' 'void' 'dinosaurs' 'arcade' 'pottery' 'llc'\n",
      " 'division' 'snyder' 'passion']\n",
      "VALUE: 3.8888888888888893\n",
      "(1000,)\n",
      "['rooted' 'void' 'storytelling' 'dinosaurs' 'arcade' 'pottery' 'llc'\n",
      " 'passion' 'division' 'irving']\n",
      "VALUE: 4.444444444444445\n",
      "(1000,)\n",
      "['rooted' 'void' 'storytelling' 'dinosaurs' 'arcade' 'pottery' 'passion'\n",
      " 'heroes' 'llc' 'irving']\n",
      "VALUE: 5.0\n",
      "(1000,)\n",
      "['rooted' 'void' 'storytelling' 'arcade' 'dinosaurs' 'pottery' 'passion'\n",
      " 'heroes' 'irving' 'llc']\n",
      "WORD: internet\n",
      "6647\n",
      "VALUE: 0.0\n",
      "(1000,)\n",
      "['flag' 'swami' 'vital' 'promotion' 'ribbons' 'absorption' 'organizes'\n",
      " 'spot' 'wording' 'participated']\n",
      "VALUE: 0.5555555555555556\n",
      "(1000,)\n",
      "['flag' 'swami' 'ribbons' 'locate' 'revision' 'vital' 'wording' 'share'\n",
      " 'assigned' 'spot']\n",
      "VALUE: 1.1111111111111112\n",
      "(1000,)\n",
      "['flag' 'swami' 'revision' 'locate' 'ribbons' 'picked' 'assigned'\n",
      " 'wording' 'retrieved' 'share']\n",
      "VALUE: 1.6666666666666667\n",
      "(1000,)\n",
      "['flag' 'locate' 'picked' 'revision' 'swami' 'whistle' 'alerted'\n",
      " 'implicated' 'gum' 'assigned']\n",
      "VALUE: 2.2222222222222223\n",
      "(1000,)\n",
      "['flag' 'picked' 'locate' 'whistle' 'revision' 'implicated' 'alerted'\n",
      " 'gum' 'marshal' 'dug']\n",
      "VALUE: 2.7777777777777777\n",
      "(1000,)\n",
      "['flag' 'picked' 'locate' 'whistle' 'implicated' 'gum' 'alerted'\n",
      " 'revision' 'marshal' 'dug']\n",
      "VALUE: 3.3333333333333335\n",
      "(1000,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['flag' 'picked' 'gum' 'whistle' 'implicated' 'locate' 'alerted' 'marshal'\n",
      " 'tagged' 'identified']\n",
      "VALUE: 3.8888888888888893\n",
      "(1000,)\n",
      "['flag' 'picked' 'gum' 'whistle' 'implicated' 'locate' 'marshal' 'alerted'\n",
      " 'tagged' 'find']\n",
      "VALUE: 4.444444444444445\n",
      "(1000,)\n",
      "['flag' 'picked' 'gum' 'whistle' 'find' 'implicated' 'marshal' 'tagged'\n",
      " 'locate' 'identified']\n",
      "VALUE: 5.0\n",
      "(1000,)\n",
      "['flag' 'picked' 'gum' 'find' 'whistle' 'recognize' 'marshal' 'dug'\n",
      " 'tagged' 'identified']\n",
      "WORD: internet\n",
      "6647\n",
      "VALUE: 0.0\n",
      "(1000,)\n",
      "['flag' 'retrieved' 'volunteered' 'ribbons' 'vital' 'gum' 'cigarettes'\n",
      " 'manning' 'cigarette' 'revision']\n",
      "VALUE: 0.5555555555555556\n",
      "(1000,)\n",
      "['flag' 'swami' 'ribbons' 'revision' 'locate' 'vital' 'wording'\n",
      " 'retrieved' 'assigned' 'volunteered']\n",
      "VALUE: 1.1111111111111112\n",
      "(1000,)\n",
      "['flag' 'swami' 'revision' 'locate' 'ribbons' 'refugees' 'krishna' 'share'\n",
      " 'kyoto' 'wording']\n",
      "VALUE: 1.6666666666666667\n",
      "(1000,)\n",
      "['flag' 'swami' 'disciple' 'refugees' 'krishna' 'revision' 'kyoto'\n",
      " 'locate' 'astronomers' 'swimmers']\n",
      "VALUE: 2.2222222222222223\n",
      "(1000,)\n",
      "['disciple' 'swami' 'flag' 'krishna' 'refugees' 'disciples' 'swimmers'\n",
      " 'astronomers' 'jaya' 'kyoto']\n",
      "VALUE: 2.7777777777777777\n",
      "(1000,)\n",
      "['disciple' 'swami' 'krishna' 'refugees' 'swimmers' 'reservoir'\n",
      " 'disciples' 'jaya' 'swimmer' 'filmmaker']\n",
      "VALUE: 3.3333333333333335\n",
      "(1000,)\n",
      "['disciple' 'swimmers' 'krishna' 'swami' 'refugees' 'reservoir'\n",
      " 'freshwater' 'jaya' 'filmmaker' 'lakes']\n",
      "VALUE: 3.8888888888888893\n",
      "(1000,)\n",
      "['disciple' 'swimmers' 'krishna' 'freshwater' 'lakes' 'refugees'\n",
      " 'reservoir' 'filmmaker' 'swami' 'swimming']\n",
      "VALUE: 4.444444444444445\n",
      "(1000,)\n",
      "['disciple' 'swimmers' 'freshwater' 'lakes' 'krishna' 'filmmaker'\n",
      " 'reservoir' 'refugees' 'neo' 'swimming']\n",
      "VALUE: 5.0\n",
      "(1000,)\n",
      "['disciple' 'swimmers' 'lakes' 'freshwater' 'neo' 'krishna' 'filmmaker'\n",
      " 'swimming' 'treatise' 'reservoir']\n",
      "WORD: internet\n",
      "6647\n",
      "VALUE: 0.0\n",
      "(1000,)\n",
      "['flag' 'swami' 'revision' 'ribbons' 'wording' 'ultra' 'krishna'\n",
      " 'refugees' 'physicist' 'locate']\n",
      "VALUE: 0.5555555555555556\n",
      "(1000,)\n",
      "['flag' 'swami' 'revision' 'locate' 'ribbons' 'wording' 'vital' 'assigned'\n",
      " 'share' 'retrieved']\n",
      "VALUE: 1.1111111111111112\n",
      "(1000,)\n",
      "['flag' 'swami' 'locate' 'ribbons' 'vital' 'share' 'retrieved' 'wounded'\n",
      " 'assigned' 'revision']\n",
      "VALUE: 1.6666666666666667\n",
      "(1000,)\n",
      "['flag' 'locate' 'wounded' 'swami' 'share' 'retrieved' 'participated'\n",
      " 'tagged' 'organizes' 'vital']\n",
      "VALUE: 2.2222222222222223\n",
      "(1000,)\n",
      "['flag' 'wounded' 'locate' 'organizes' 'killed' 'tagged' 'share'\n",
      " 'participated' 'retrieved' 'alerted']\n",
      "VALUE: 2.7777777777777777\n",
      "(1000,)\n",
      "['wounded' 'flag' 'killed' 'organizes' 'tagged' 'locate' 'share'\n",
      " 'participated' 'retrieved' 'corner']\n",
      "VALUE: 3.3333333333333335\n",
      "(1000,)\n",
      "['wounded' 'killed' 'organizes' 'flag' 'tagged' 'share' 'participated'\n",
      " 'locate' 'car' 'connected']\n",
      "VALUE: 3.8888888888888893\n",
      "(1000,)\n",
      "['wounded' 'killed' 'organizes' 'tagged' 'share' 'car' 'place' 'flag'\n",
      " 'participated' 'connected']\n",
      "VALUE: 4.444444444444445\n",
      "(1000,)\n",
      "['killed' 'wounded' 'organizes' 'car' 'share' 'all' 'tagged' 'place'\n",
      " 'participated' 'honors']\n",
      "VALUE: 5.0\n",
      "(1000,)\n",
      "['killed' 'wounded' 'car' 'organizes' 'share' 'all' 'place' 'honors'\n",
      " 'fatalities' 'participated']\n"
     ]
    }
   ],
   "source": [
    "find_top_words(train_glove_embed, train_glove_token, test_glove_embed, test_glove_token, sg_train_word_embed, \"glove\",\"spine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wordnet domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_31 (InputLayer)           (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_32 (InputLayer)           (None, 169)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 469)          0           input_31[0][0]                   \n",
      "                                                                 input_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_51 (Dense)                (None, 128)          60160       concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_52 (Dense)                (None, 75)           9675        dense_51[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_53 (Dense)                (None, 75)           9675        dense_51[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 75)           0           dense_52[0][0]                   \n",
      "                                                                 dense_53[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 244)          0           lambda_11[0][0]                  \n",
      "                                                                 input_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_54 (Dense)                (None, 128)          31360       concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_55 (Dense)                (None, 300)          38700       dense_54[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 149,570\n",
      "Trainable params: 149,570\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 12000 samples, validate on 3000 samples\n",
      "Epoch 1/50\n",
      " - 4s - loss: 0.1419 - val_loss: 0.1373\n",
      "Epoch 2/50\n",
      " - 3s - loss: 0.1370 - val_loss: 0.1371\n",
      "Epoch 3/50\n",
      " - 3s - loss: 0.1368 - val_loss: 0.1370\n",
      "Epoch 4/50\n",
      " - 3s - loss: 0.1366 - val_loss: 0.1368\n",
      "Epoch 5/50\n",
      " - 4s - loss: 0.1364 - val_loss: 0.1366\n",
      "Epoch 6/50\n",
      " - 4s - loss: 0.1362 - val_loss: 0.1364\n",
      "Epoch 7/50\n",
      " - 4s - loss: 0.1360 - val_loss: 0.1363\n",
      "Epoch 8/50\n",
      " - 3s - loss: 0.1359 - val_loss: 0.1361\n",
      "Epoch 9/50\n",
      " - 3s - loss: 0.1357 - val_loss: 0.1360\n",
      "Epoch 10/50\n",
      " - 3s - loss: 0.1355 - val_loss: 0.1358\n",
      "Epoch 11/50\n",
      " - 3s - loss: 0.1353 - val_loss: 0.1357\n",
      "Epoch 12/50\n",
      " - 3s - loss: 0.1352 - val_loss: 0.1356\n",
      "Epoch 13/50\n",
      " - 3s - loss: 0.1351 - val_loss: 0.1355\n",
      "Epoch 14/50\n",
      " - 3s - loss: 0.1349 - val_loss: 0.1354\n",
      "Epoch 15/50\n",
      " - 3s - loss: 0.1348 - val_loss: 0.1353\n",
      "Epoch 16/50\n",
      " - 3s - loss: 0.1347 - val_loss: 0.1352\n",
      "Epoch 17/50\n",
      " - 3s - loss: 0.1346 - val_loss: 0.1352\n",
      "Epoch 18/50\n",
      " - 3s - loss: 0.1345 - val_loss: 0.1350\n",
      "Epoch 19/50\n",
      " - 3s - loss: 0.1344 - val_loss: 0.1350\n",
      "Epoch 20/50\n",
      " - 2s - loss: 0.1344 - val_loss: 0.1349\n",
      "Epoch 21/50\n",
      " - 2s - loss: 0.1343 - val_loss: 0.1349\n",
      "Epoch 22/50\n",
      " - 2s - loss: 0.1342 - val_loss: 0.1349\n",
      "Epoch 23/50\n",
      " - 3s - loss: 0.1342 - val_loss: 0.1349\n",
      "Epoch 24/50\n",
      " - 2s - loss: 0.1341 - val_loss: 0.1348\n",
      "Epoch 25/50\n",
      " - 2s - loss: 0.1340 - val_loss: 0.1348\n",
      "Epoch 26/50\n",
      " - 2s - loss: 0.1340 - val_loss: 0.1348\n",
      "Epoch 27/50\n",
      " - 2s - loss: 0.1339 - val_loss: 0.1347\n",
      "Epoch 28/50\n",
      " - 3s - loss: 0.1339 - val_loss: 0.1347\n",
      "Epoch 29/50\n",
      " - 2s - loss: 0.1338 - val_loss: 0.1346\n",
      "Epoch 30/50\n",
      " - 2s - loss: 0.1338 - val_loss: 0.1346\n",
      "Epoch 31/50\n",
      " - 2s - loss: 0.1337 - val_loss: 0.1346\n",
      "Epoch 32/50\n",
      " - 2s - loss: 0.1337 - val_loss: 0.1346\n",
      "Epoch 33/50\n",
      " - 2s - loss: 0.1336 - val_loss: 0.1345\n",
      "Epoch 34/50\n",
      " - 2s - loss: 0.1336 - val_loss: 0.1345\n",
      "Epoch 35/50\n",
      " - 2s - loss: 0.1336 - val_loss: 0.1345\n",
      "Epoch 36/50\n",
      " - 2s - loss: 0.1335 - val_loss: 0.1345\n",
      "Epoch 37/50\n",
      " - 2s - loss: 0.1335 - val_loss: 0.1345\n",
      "Epoch 38/50\n",
      " - 3s - loss: 0.1335 - val_loss: 0.1344\n",
      "Epoch 39/50\n",
      " - 2s - loss: 0.1334 - val_loss: 0.1344\n",
      "Epoch 40/50\n",
      " - 2s - loss: 0.1334 - val_loss: 0.1344\n",
      "Epoch 41/50\n",
      " - 2s - loss: 0.1334 - val_loss: 0.1344\n",
      "Epoch 42/50\n",
      " - 2s - loss: 0.1333 - val_loss: 0.1344\n",
      "Epoch 43/50\n",
      " - 2s - loss: 0.1333 - val_loss: 0.1343\n",
      "Epoch 44/50\n",
      " - 3s - loss: 0.1333 - val_loss: 0.1344\n",
      "Epoch 45/50\n",
      " - 3s - loss: 0.1332 - val_loss: 0.1343\n",
      "Epoch 46/50\n",
      " - 3s - loss: 0.1332 - val_loss: 0.1343\n",
      "Epoch 47/50\n",
      " - 3s - loss: 0.1332 - val_loss: 0.1343\n",
      "Epoch 48/50\n",
      " - 3s - loss: 0.1331 - val_loss: 0.1343\n",
      "Epoch 49/50\n",
      " - 3s - loss: 0.1331 - val_loss: 0.1342\n",
      "Epoch 50/50\n",
      " - 3s - loss: 0.1331 - val_loss: 0.1342\n"
     ]
    }
   ],
   "source": [
    "### PARAMETERS ###\n",
    "decoder_out_dim = train_glove_embed.shape[1] # dim of decoder output layer\n",
    "n_x = train_glove_embed.shape[1]\n",
    "n_y = glove_train_wordnet_cond_matrix_df.shape[1]\n",
    "train_embed = train_glove_embed\n",
    "train_word = glove_train_wordnet_cond_matrix_df\n",
    "test_embed = test_glove_embed\n",
    "test_word = glove_test_wordnet_cond_matrix_df\n",
    "### PARAMETERS ###\n",
    "\n",
    "# define encoder\n",
    "X = Input(shape=(n_x,))\n",
    "label = Input(shape=(n_y,))\n",
    "inputs = concat([X, label])\n",
    "encoder_h = Dense(encoder_dim1, activation=activ)(inputs)\n",
    "mu = Dense(n_z, activation='linear')(encoder_h)\n",
    "l_sigma = Dense(n_z, activation='linear')(encoder_h)\n",
    "\n",
    "# sample latent space\n",
    "z = Lambda(sample_z, output_shape = (n_z, ))([mu, l_sigma])\n",
    "zc = concat([z, label])\n",
    "\n",
    "# decoder\n",
    "decoder_hidden = Dense(decoder_dim, activation=activ)\n",
    "decoder_out = Dense(decoder_out_dim, activation='sigmoid')\n",
    "h_p = decoder_hidden(zc)\n",
    "outputs = decoder_out(h_p)\n",
    "\n",
    "# define graphs\n",
    "cvae = Model([X, label], outputs)\n",
    "encoder = Model([X, label], mu)\n",
    "d_in = Input(shape=(n_z+n_y,))\n",
    "d_h = decoder_hidden(d_in)\n",
    "d_out = decoder_out(d_h)\n",
    "decoder = Model(d_in, d_out)\n",
    "\n",
    "# print statistics\n",
    "cvae.compile(optimizer=optim, loss=vae_loss)\n",
    "\n",
    "cvae.summary()\n",
    "\n",
    "cvae_hist = cvae.fit([train_embed, train_word], train_embed, verbose = 2, batch_size=m, \n",
    "                 epochs=n_epoch,\n",
    "                 validation_data = ([test_embed, test_word], test_embed),\n",
    "                 callbacks = [EarlyStopping(patience = 5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORD: mathematics\n",
      "8341\n",
      "VALUE: 0.0\n",
      "(169,)\n",
      "['lau' 'software' 'expulsion' 'immoral' 'developments' 'cleaning' 'prices'\n",
      " 'freeing' 'freed' 'contamination']\n",
      "VALUE: 0.5555555555555556\n",
      "(169,)\n",
      "['lau' 'software' 'expulsion' 'immoral' 'developments' 'cleaning' 'prices'\n",
      " 'freeing' 'freed' 'contamination']\n",
      "VALUE: 1.1111111111111112\n",
      "(169,)\n",
      "['rumor' 'rumors' 'lectured' 'navigator' 'coding' 'tactical' 'auction'\n",
      " 'generic' 'impaired' 'soon']\n",
      "VALUE: 1.6666666666666667\n",
      "(169,)\n",
      "['rumor' 'rumors' 'lectured' 'navigator' 'coding' 'tactical' 'auction'\n",
      " 'generic' 'impaired' 'soon']\n",
      "VALUE: 2.2222222222222223\n",
      "(169,)\n",
      "['navigator' 'rumor' 'rumors' 'drivers' 'lectured' 'coding' 'astronaut'\n",
      " 'chief' 'supervised' 'competence']\n",
      "VALUE: 2.7777777777777777\n",
      "(169,)\n",
      "['navigator' 'rumor' 'rumors' 'drivers' 'lectured' 'coding' 'astronaut'\n",
      " 'chief' 'supervised' 'competence']\n",
      "VALUE: 3.3333333333333335\n",
      "(169,)\n",
      "['navigator' 'chief' 'drivers' 'astronaut' 'coding' 'supervised'\n",
      " 'commander' 'spelling' 'rumor' 'supervising']\n",
      "VALUE: 3.8888888888888893\n",
      "(169,)\n",
      "['navigator' 'chief' 'drivers' 'astronaut' 'coding' 'supervised'\n",
      " 'commander' 'spelling' 'rumor' 'supervising']\n",
      "VALUE: 4.444444444444445\n",
      "(169,)\n",
      "['navigator' 'chief' 'drivers' 'astronaut' 'spelling' 'coding' 'commander'\n",
      " 'supervised' 'advising' 'supervising']\n",
      "VALUE: 5.0\n",
      "(169,)\n",
      "['navigator' 'chief' 'drivers' 'spelling' 'astronaut' 'advising'\n",
      " 'supervised' 'imprisoned' 'coding' 'commander']\n",
      "WORD: remote\n",
      "2616\n",
      "VALUE: 0.0\n",
      "(169,)\n",
      "['demonstrated' 'focused' 'denote' 'specializing' 'style' 'lean'\n",
      " 'entering' 'newfound' 'specialize' 'utter']\n",
      "VALUE: 0.5555555555555556\n",
      "(169,)\n",
      "['demonstrated' 'focused' 'denote' 'specializing' 'style' 'lean'\n",
      " 'entering' 'newfound' 'specialize' 'utter']\n",
      "VALUE: 1.1111111111111112\n",
      "(169,)\n",
      "['plead' 'ribbon' 'post' 'riding' 'entering' 'heading' 'dash' 'sale'\n",
      " 'mined' 'ribbons']\n",
      "VALUE: 1.6666666666666667\n",
      "(169,)\n",
      "['plead' 'ribbon' 'post' 'riding' 'entering' 'heading' 'dash' 'sale'\n",
      " 'mined' 'ribbons']\n",
      "VALUE: 2.2222222222222223\n",
      "(169,)\n",
      "['plead' 'ribbon' 'dash' 'lawful' 'valuation' 'crashes' 'riding' 'fauna'\n",
      " 'sale' 'fatigue']\n",
      "VALUE: 2.7777777777777777\n",
      "(169,)\n",
      "['plead' 'ribbon' 'dash' 'lawful' 'valuation' 'crashes' 'riding' 'fauna'\n",
      " 'sale' 'fatigue']\n",
      "VALUE: 3.3333333333333335\n",
      "(169,)\n",
      "['plead' 'lawful' 'teachings' 'valuation' 'dash' 'values' 'crashes'\n",
      " 'reduced' 'ribbon' 'sale']\n",
      "VALUE: 3.8888888888888893\n",
      "(169,)\n",
      "['plead' 'lawful' 'teachings' 'valuation' 'dash' 'values' 'crashes'\n",
      " 'reduced' 'ribbon' 'sale']\n",
      "VALUE: 4.444444444444445\n",
      "(169,)\n",
      "['plead' 'lawful' 'teachings' 'valuation' 'values' 'greater' 'dash'\n",
      " 'reduced' 'crashes' 'sale']\n",
      "VALUE: 5.0\n",
      "(169,)\n",
      "['plead' 'lawful' 'valuation' 'greater' 'teachings' 'values' 'dash'\n",
      " 'reduced' 'noble' 'crashes']\n",
      "WORD: remote\n",
      "2616\n",
      "VALUE: 0.0\n",
      "(169,)\n",
      "['proton' 'plead' 'cosmic' 'lobby' 'parishes' 'lacking' 'finish'\n",
      " 'teachings' 'follows' 'rays']\n",
      "VALUE: 0.5555555555555556\n",
      "(169,)\n",
      "['proton' 'plead' 'cosmic' 'lobby' 'parishes' 'lacking' 'finish'\n",
      " 'teachings' 'follows' 'rays']\n",
      "VALUE: 1.1111111111111112\n",
      "(169,)\n",
      "['plead' 'ribbon' 'post' 'riding' 'entering' 'heading' 'dash' 'sale'\n",
      " 'mined' 'ribbons']\n",
      "VALUE: 1.6666666666666667\n",
      "(169,)\n",
      "['plead' 'ribbon' 'post' 'riding' 'entering' 'heading' 'dash' 'sale'\n",
      " 'mined' 'ribbons']\n",
      "VALUE: 2.2222222222222223\n",
      "(169,)\n",
      "['post' 'heading' 'mined' 'during' 'plead' 'style' 'focused' 'focusing'\n",
      " 'oxide' 'woodstock']\n",
      "VALUE: 2.7777777777777777\n",
      "(169,)\n",
      "['post' 'heading' 'mined' 'during' 'plead' 'style' 'focused' 'focusing'\n",
      " 'oxide' 'woodstock']\n",
      "VALUE: 3.3333333333333335\n",
      "(169,)\n",
      "['style' 'post' 'brief' 'during' 'mined' 'heading' 'concentrated'\n",
      " 'schwarzenegger' 'woodstock' 'oxide']\n",
      "VALUE: 3.8888888888888893\n",
      "(169,)\n",
      "['style' 'post' 'brief' 'during' 'mined' 'heading' 'concentrated'\n",
      " 'schwarzenegger' 'woodstock' 'oxide']\n",
      "VALUE: 4.444444444444445\n",
      "(169,)\n",
      "['style' 'brief' 'cite' 'attribute' 'infection' 'schwarzenegger' 'section'\n",
      " 'deal' 'during' 'post']\n",
      "VALUE: 5.0\n",
      "(169,)\n",
      "['cite' 'attribute' 'brief' 'style' 'infection' 'remember'\n",
      " 'schwarzenegger' 'section' 'electronics' 'deal']\n",
      "WORD: remote\n",
      "2616\n",
      "VALUE: 0.0\n",
      "(169,)\n",
      "['unemployed' 'luc' 'thorpe' 'lau' 'ras' 'heading' 'mined' 'crashes'\n",
      " 'focused' 'shirley']\n",
      "VALUE: 0.5555555555555556\n",
      "(169,)\n",
      "['unemployed' 'luc' 'thorpe' 'lau' 'ras' 'heading' 'mined' 'crashes'\n",
      " 'focused' 'shirley']\n",
      "VALUE: 1.1111111111111112\n",
      "(169,)\n",
      "['plead' 'ribbon' 'post' 'riding' 'entering' 'heading' 'dash' 'sale'\n",
      " 'mined' 'ribbons']\n",
      "VALUE: 1.6666666666666667\n",
      "(169,)\n",
      "['plead' 'ribbon' 'post' 'riding' 'entering' 'heading' 'dash' 'sale'\n",
      " 'mined' 'ribbons']\n",
      "VALUE: 2.2222222222222223\n",
      "(169,)\n",
      "['entering' 'plead' 'ribbon' 'display' 'polished' 'post' 'demonstrated'\n",
      " 'ribbons' 'commenting' 'fatigue']\n",
      "VALUE: 2.7777777777777777\n",
      "(169,)\n",
      "['entering' 'plead' 'ribbon' 'display' 'polished' 'post' 'demonstrated'\n",
      " 'ribbons' 'commenting' 'fatigue']\n",
      "VALUE: 3.3333333333333335\n",
      "(169,)\n",
      "['display' 'entering' 'designs' 'semiconductor' 'plead' 'displayed'\n",
      " 'demonstrated' 'commenting' 'clad' 'custom']\n",
      "VALUE: 3.8888888888888893\n",
      "(169,)\n",
      "['display' 'entering' 'designs' 'semiconductor' 'plead' 'displayed'\n",
      " 'demonstrated' 'commenting' 'clad' 'custom']\n",
      "VALUE: 4.444444444444445\n",
      "(169,)\n",
      "['display' 'designs' 'millionaire' 'semiconductor' 'palaces' 'displayed'\n",
      " 'manufactures' 'criticize' 'exhibited' 'ware']\n",
      "VALUE: 5.0\n",
      "(169,)\n",
      "['millionaire' 'display' 'designs' 'palaces' 'semiconductor' 'wonder'\n",
      " 'manufactures' 'fascination' 'ware' 'exhibited']\n",
      "WORD: internet\n",
      "6647\n",
      "VALUE: 0.0\n",
      "(169,)\n",
      "['lau' 'software' 'expulsion' 'immoral' 'developments' 'cleaning' 'prices'\n",
      " 'freeing' 'freed' 'contamination']\n",
      "VALUE: 0.5555555555555556\n",
      "(169,)\n",
      "['lau' 'software' 'expulsion' 'immoral' 'developments' 'cleaning' 'prices'\n",
      " 'freeing' 'freed' 'contamination']\n",
      "VALUE: 1.1111111111111112\n",
      "(169,)\n",
      "['sung' 'electrons' 'price' 'carol' 'forward' 'arbor' 'upward' 'rumors'\n",
      " 'overlooked' 'values']\n",
      "VALUE: 1.6666666666666667\n",
      "(169,)\n",
      "['sung' 'electrons' 'price' 'carol' 'forward' 'arbor' 'upward' 'rumors'\n",
      " 'overlooked' 'values']\n",
      "VALUE: 2.2222222222222223\n",
      "(169,)\n",
      "['nato' 'fast' 'sung' 'ceremonial' 'aggressively' 'publicly' 'abuses'\n",
      " 'forward' 'hearings' 'ultra']\n",
      "VALUE: 2.7777777777777777\n",
      "(169,)\n",
      "['nato' 'fast' 'sung' 'ceremonial' 'aggressively' 'publicly' 'abuses'\n",
      " 'forward' 'hearings' 'ultra']\n",
      "VALUE: 3.3333333333333335\n",
      "(169,)\n",
      "['fast' 'nato' 'abuses' 'aggressively' 'hearings' 'publicly' 'ultra'\n",
      " 'ceremonial' 'knots' 'sexually']\n",
      "VALUE: 3.8888888888888893\n",
      "(169,)\n",
      "['fast' 'nato' 'abuses' 'aggressively' 'hearings' 'publicly' 'ultra'\n",
      " 'ceremonial' 'knots' 'sexually']\n",
      "VALUE: 4.444444444444445\n",
      "(169,)\n",
      "['fast' 'abuses' 'nato' 'aggressively' 'hearings' 'ultra' 'publicly'\n",
      " 'knots' 'sexually' 'ceremonial']\n",
      "VALUE: 5.0\n",
      "(169,)\n",
      "['fast' 'abuses' 'aggressively' 'nato' 'ultra' 'hearings' 'publicly'\n",
      " 'supervising' 'sexually' 'knots']\n"
     ]
    }
   ],
   "source": [
    "find_top_words(train_glove_embed, train_glove_token, test_glove_embed, test_glove_token, glove_train_wordnet_cond_matrix_df, \"glove\", \"wordnet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_34 (InputLayer)           (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_35 (InputLayer)           (None, 19)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 319)          0           input_34[0][0]                   \n",
      "                                                                 input_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_56 (Dense)                (None, 128)          40960       concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_57 (Dense)                (None, 75)           9675        dense_56[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_58 (Dense)                (None, 75)           9675        dense_56[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 75)           0           dense_57[0][0]                   \n",
      "                                                                 dense_58[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 94)           0           lambda_12[0][0]                  \n",
      "                                                                 input_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_59 (Dense)                (None, 128)          12160       concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_60 (Dense)                (None, 300)          38700       dense_59[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 111,170\n",
      "Trainable params: 111,170\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 12000 samples, validate on 3000 samples\n",
      "Epoch 1/50\n",
      " - 3s - loss: 0.1421 - val_loss: 0.1374\n",
      "Epoch 2/50\n",
      " - 2s - loss: 0.1370 - val_loss: 0.1372\n",
      "Epoch 3/50\n",
      " - 2s - loss: 0.1369 - val_loss: 0.1371\n",
      "Epoch 4/50\n",
      " - 2s - loss: 0.1367 - val_loss: 0.1369\n",
      "Epoch 5/50\n",
      " - 2s - loss: 0.1366 - val_loss: 0.1368\n",
      "Epoch 6/50\n",
      " - 2s - loss: 0.1364 - val_loss: 0.1367\n",
      "Epoch 7/50\n",
      " - 2s - loss: 0.1363 - val_loss: 0.1366\n",
      "Epoch 8/50\n",
      " - 2s - loss: 0.1362 - val_loss: 0.1365\n",
      "Epoch 9/50\n",
      " - 3s - loss: 0.1362 - val_loss: 0.1365\n",
      "Epoch 10/50\n",
      " - 2s - loss: 0.1361 - val_loss: 0.1364\n",
      "Epoch 11/50\n",
      " - 2s - loss: 0.1361 - val_loss: 0.1364\n",
      "Epoch 12/50\n",
      " - 2s - loss: 0.1361 - val_loss: 0.1364\n",
      "Epoch 13/50\n",
      " - 2s - loss: 0.1360 - val_loss: 0.1363\n",
      "Epoch 14/50\n",
      " - 3s - loss: 0.1360 - val_loss: 0.1363\n",
      "Epoch 15/50\n",
      " - 3s - loss: 0.1360 - val_loss: 0.1363\n",
      "Epoch 16/50\n",
      " - 2s - loss: 0.1360 - val_loss: 0.1363\n",
      "Epoch 17/50\n",
      " - 2s - loss: 0.1360 - val_loss: 0.1363\n",
      "Epoch 18/50\n",
      " - 2s - loss: 0.1359 - val_loss: 0.1362\n",
      "Epoch 19/50\n",
      " - 2s - loss: 0.1359 - val_loss: 0.1362\n",
      "Epoch 20/50\n",
      " - 2s - loss: 0.1359 - val_loss: 0.1362\n",
      "Epoch 21/50\n",
      " - 3s - loss: 0.1359 - val_loss: 0.1362\n",
      "Epoch 22/50\n",
      " - 3s - loss: 0.1359 - val_loss: 0.1362\n",
      "Epoch 23/50\n",
      " - 3s - loss: 0.1359 - val_loss: 0.1362\n",
      "Epoch 24/50\n",
      " - 4s - loss: 0.1359 - val_loss: 0.1362\n",
      "Epoch 25/50\n",
      " - 3s - loss: 0.1359 - val_loss: 0.1362\n",
      "Epoch 26/50\n",
      " - 4s - loss: 0.1359 - val_loss: 0.1362\n",
      "Epoch 27/50\n",
      " - 3s - loss: 0.1359 - val_loss: 0.1362\n",
      "Epoch 28/50\n",
      " - 2s - loss: 0.1358 - val_loss: 0.1362\n",
      "Epoch 29/50\n",
      " - 3s - loss: 0.1358 - val_loss: 0.1362\n",
      "Epoch 30/50\n",
      " - 2s - loss: 0.1358 - val_loss: 0.1362\n",
      "Epoch 31/50\n",
      " - 2s - loss: 0.1358 - val_loss: 0.1362\n",
      "Epoch 32/50\n",
      " - 3s - loss: 0.1358 - val_loss: 0.1362\n",
      "Epoch 33/50\n",
      " - 3s - loss: 0.1358 - val_loss: 0.1362\n",
      "Epoch 34/50\n",
      " - 3s - loss: 0.1358 - val_loss: 0.1362\n",
      "Epoch 35/50\n",
      " - 3s - loss: 0.1358 - val_loss: 0.1361\n",
      "Epoch 36/50\n",
      " - 2s - loss: 0.1358 - val_loss: 0.1362\n",
      "Epoch 37/50\n",
      " - 2s - loss: 0.1358 - val_loss: 0.1361\n",
      "Epoch 38/50\n",
      " - 2s - loss: 0.1358 - val_loss: 0.1362\n",
      "Epoch 39/50\n",
      " - 2s - loss: 0.1358 - val_loss: 0.1361\n",
      "Epoch 40/50\n",
      " - 3s - loss: 0.1358 - val_loss: 0.1361\n",
      "Epoch 41/50\n",
      " - 3s - loss: 0.1358 - val_loss: 0.1361\n",
      "Epoch 42/50\n",
      " - 2s - loss: 0.1358 - val_loss: 0.1361\n",
      "Epoch 43/50\n",
      " - 2s - loss: 0.1358 - val_loss: 0.1361\n",
      "Epoch 44/50\n",
      " - 2s - loss: 0.1358 - val_loss: 0.1361\n"
     ]
    }
   ],
   "source": [
    "### PARAMETERS ###\n",
    "decoder_out_dim = train_glove_embed.shape[1] # dim of decoder output layer\n",
    "n_x = train_glove_embed.shape[1]\n",
    "n_y = glove_train_pos_cond_matrix_df.shape[1]\n",
    "train_embed = train_glove_embed\n",
    "train_word = glove_train_pos_cond_matrix_df\n",
    "test_embed = test_glove_embed\n",
    "test_word = glove_test_pos_cond_matrix_df\n",
    "### PARAMETERS ###\n",
    "\n",
    "# define encoder\n",
    "X = Input(shape=(n_x,))\n",
    "label = Input(shape=(n_y,))\n",
    "inputs = concat([X, label])\n",
    "encoder_h = Dense(encoder_dim1, activation=activ)(inputs)\n",
    "mu = Dense(n_z, activation='linear')(encoder_h)\n",
    "l_sigma = Dense(n_z, activation='linear')(encoder_h)\n",
    "\n",
    "# sample latent space\n",
    "z = Lambda(sample_z, output_shape = (n_z, ))([mu, l_sigma])\n",
    "zc = concat([z, label])\n",
    "\n",
    "# decoder\n",
    "decoder_hidden = Dense(decoder_dim, activation=activ)\n",
    "decoder_out = Dense(decoder_out_dim, activation='sigmoid')\n",
    "h_p = decoder_hidden(zc)\n",
    "outputs = decoder_out(h_p)\n",
    "\n",
    "# define graphs\n",
    "cvae = Model([X, label], outputs)\n",
    "encoder = Model([X, label], mu)\n",
    "d_in = Input(shape=(n_z+n_y,))\n",
    "d_h = decoder_hidden(d_in)\n",
    "d_out = decoder_out(d_h)\n",
    "decoder = Model(d_in, d_out)\n",
    "\n",
    "# print statistics\n",
    "cvae.compile(optimizer=optim, loss=vae_loss)\n",
    "\n",
    "cvae.summary()\n",
    "\n",
    "cvae_hist = cvae.fit([train_embed, train_word], train_embed, verbose = 2, batch_size=m, \n",
    "                 epochs=n_epoch,\n",
    "                 validation_data = ([test_embed, test_word], test_embed),\n",
    "                 callbacks = [EarlyStopping(patience = 5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORD: mathematics\n",
      "8341\n",
      "VALUE: 0.0\n",
      "(19,)\n",
      "['software' 'condemned' 'pie' 'improve' 'expelled' 'electrons' 'phenomena'\n",
      " 'camp' 'liberation' 'capt']\n",
      "VALUE: 0.5555555555555556\n",
      "(19,)\n",
      "['software' 'condemned' 'pie' 'improve' 'expelled' 'electrons' 'phenomena'\n",
      " 'camp' 'liberation' 'capt']\n",
      "VALUE: 1.1111111111111112\n",
      "(19,)\n",
      "['pie' 'competitive' 'bench' 'shipbuilding' 'auto' 'automotive' 'table'\n",
      " 'massa' 'expertise' 'baker']\n",
      "VALUE: 1.6666666666666667\n",
      "(19,)\n",
      "['pie' 'competitive' 'bench' 'shipbuilding' 'auto' 'automotive' 'table'\n",
      " 'massa' 'expertise' 'baker']\n",
      "VALUE: 2.2222222222222223\n",
      "(19,)\n",
      "['pie' 'massa' 'competitive' 'bench' 'shipbuilding' 'auto' 'automotive'\n",
      " 'mccain' 'baker' 'table']\n",
      "VALUE: 2.7777777777777777\n",
      "(19,)\n",
      "['pie' 'massa' 'competitive' 'bench' 'shipbuilding' 'auto' 'automotive'\n",
      " 'mccain' 'baker' 'table']\n",
      "VALUE: 3.3333333333333335\n",
      "(19,)\n",
      "['massa' 'mccain' 'pie' 'bench' 'competitive' 'fungus' 'shipbuilding'\n",
      " 'obama' 'craft' 'gardening']\n",
      "VALUE: 3.8888888888888893\n",
      "(19,)\n",
      "['massa' 'mccain' 'pie' 'bench' 'competitive' 'fungus' 'shipbuilding'\n",
      " 'obama' 'craft' 'gardening']\n",
      "VALUE: 4.444444444444445\n",
      "(19,)\n",
      "['massa' 'mccain' 'pie' 'fungus' 'bench' 'stein' 'obama' 'gardening'\n",
      " 'danish' 'substances']\n",
      "VALUE: 5.0\n",
      "(19,)\n",
      "['mccain' 'massa' 'bench' 'fungus' 'stein' 'bacterial' 'obama' 'carlo'\n",
      " 'fungi' 'danish']\n",
      "WORD: remote\n",
      "2616\n",
      "VALUE: 0.0\n",
      "(19,)\n",
      "['airplane' 'aircraft' 'exploding' 'arbor' 'aerospace' 'crashes' 'ton'\n",
      " 'building' 'lacking' 'belt']\n",
      "VALUE: 0.5555555555555556\n",
      "(19,)\n",
      "['airplane' 'aircraft' 'exploding' 'arbor' 'aerospace' 'crashes' 'ton'\n",
      " 'building' 'lacking' 'belt']\n",
      "VALUE: 1.1111111111111112\n",
      "(19,)\n",
      "['fireworks' 'marshal' 'jeanne' 'automotive' 'aviation' 'astronaut'\n",
      " 'motorcycles' 'impaired' 'hub' 'aircraft']\n",
      "VALUE: 1.6666666666666667\n",
      "(19,)\n",
      "['fireworks' 'marshal' 'jeanne' 'automotive' 'aviation' 'astronaut'\n",
      " 'motorcycles' 'impaired' 'hub' 'aircraft']\n",
      "VALUE: 2.2222222222222223\n",
      "(19,)\n",
      "['marshal' 'capita' 'aviation' 'jeanne' 'astronaut' 'craft' 'automotive'\n",
      " 'fireworks' 'constable' 'bazaar']\n",
      "VALUE: 2.7777777777777777\n",
      "(19,)\n",
      "['marshal' 'capita' 'aviation' 'jeanne' 'astronaut' 'craft' 'automotive'\n",
      " 'fireworks' 'constable' 'bazaar']\n",
      "VALUE: 3.3333333333333335\n",
      "(19,)\n",
      "['capita' 'marshal' 'librarian' 'constable' 'monument' 'cabinets' 'fiat'\n",
      " 'restore' 'bazaar' 'cabinet']\n",
      "VALUE: 3.8888888888888893\n",
      "(19,)\n",
      "['capita' 'marshal' 'librarian' 'constable' 'monument' 'cabinets' 'fiat'\n",
      " 'restore' 'bazaar' 'cabinet']\n",
      "VALUE: 4.444444444444445\n",
      "(19,)\n",
      "['capita' 'librarian' 'monument' 'marshal' 'cabinets' 'constable'\n",
      " 'restore' 'cardiovascular' 'cabinet' 'fiat']\n",
      "VALUE: 5.0\n",
      "(19,)\n",
      "['librarian' 'intent' 'capita' 'monument' 'recreation' 'cardiovascular'\n",
      " 'cabinets' 'cabinet' 'restore' 'constable']\n",
      "WORD: remote\n",
      "2616\n",
      "VALUE: 0.0\n",
      "(19,)\n",
      "['fireworks' 'marshal' 'jeanne' 'automotive' 'aviation' 'astronaut'\n",
      " 'motorcycles' 'impaired' 'hub' 'aircraft']\n",
      "VALUE: 0.5555555555555556\n",
      "(19,)\n",
      "['fireworks' 'marshal' 'jeanne' 'automotive' 'aviation' 'astronaut'\n",
      " 'motorcycles' 'impaired' 'hub' 'aircraft']\n",
      "VALUE: 1.1111111111111112\n",
      "(19,)\n",
      "['automotive' 'jeanne' 'crying' 'automobiles' 'eileen' 'metropolis'\n",
      " 'toyota' 'kramer' 'textile' 'astronaut']\n",
      "VALUE: 1.6666666666666667\n",
      "(19,)\n",
      "['automotive' 'jeanne' 'crying' 'automobiles' 'eileen' 'metropolis'\n",
      " 'toyota' 'kramer' 'textile' 'astronaut']\n",
      "VALUE: 2.2222222222222223\n",
      "(19,)\n",
      "['crying' 'automotive' 'eileen' 'kramer' 'northward' 'jeanne' 'toyota'\n",
      " 'width' 'economy' 'metropolis']\n",
      "VALUE: 2.7777777777777777\n",
      "(19,)\n",
      "['crying' 'automotive' 'eileen' 'kramer' 'northward' 'jeanne' 'toyota'\n",
      " 'width' 'economy' 'metropolis']\n",
      "VALUE: 3.3333333333333335\n",
      "(19,)\n",
      "['width' 'eileen' 'crying' 'northward' 'kramer' 'economy' 'toyota'\n",
      " 'addressing' 'automotive' 'showers']\n",
      "VALUE: 3.8888888888888893\n",
      "(19,)\n",
      "['width' 'eileen' 'crying' 'northward' 'kramer' 'economy' 'toyota'\n",
      " 'addressing' 'automotive' 'showers']\n",
      "VALUE: 4.444444444444445\n",
      "(19,)\n",
      "['width' 'eileen' 'bacterial' 'bacteria' 'mccain' 'kramer' 'crying' 'ken'\n",
      " 'northward' 'economy']\n",
      "VALUE: 5.0\n",
      "(19,)\n",
      "['bacteria' 'bacterial' 'mccain' 'eileen' 'danish' 'ken' 'levin' 'width'\n",
      " 'kramer' 'kris']\n",
      "WORD: internet\n",
      "6647\n",
      "VALUE: 0.0\n",
      "(19,)\n",
      "['airplane' 'aircraft' 'exploding' 'arbor' 'aerospace' 'crashes' 'ton'\n",
      " 'building' 'lacking' 'belt']\n",
      "VALUE: 0.5555555555555556\n",
      "(19,)\n",
      "['airplane' 'aircraft' 'exploding' 'arbor' 'aerospace' 'crashes' 'ton'\n",
      " 'building' 'lacking' 'belt']\n",
      "VALUE: 1.1111111111111112\n",
      "(19,)\n",
      "['automotive' 'aircraft' 'profession' 'kris' 'crying' 'northward'\n",
      " 'airplane' 'nissan' 'specializing' 'aerospace']\n",
      "VALUE: 1.6666666666666667\n",
      "(19,)\n",
      "['automotive' 'aircraft' 'profession' 'kris' 'crying' 'northward'\n",
      " 'airplane' 'nissan' 'specializing' 'aerospace']\n",
      "VALUE: 2.2222222222222223\n",
      "(19,)\n",
      "['automotive' 'northward' 'crying' 'kris' 'nissan' 'toyota' 'kramer'\n",
      " 'auto' 'width' 'danish']\n",
      "VALUE: 2.7777777777777777\n",
      "(19,)\n",
      "['automotive' 'northward' 'crying' 'kris' 'nissan' 'toyota' 'kramer'\n",
      " 'auto' 'width' 'danish']\n",
      "VALUE: 3.3333333333333335\n",
      "(19,)\n",
      "['northward' 'automotive' 'crying' 'bacterial' 'danish' 'kris' 'massa'\n",
      " 'bacteria' 'width' 'toyota']\n",
      "VALUE: 3.8888888888888893\n",
      "(19,)\n",
      "['northward' 'automotive' 'crying' 'bacterial' 'danish' 'kris' 'massa'\n",
      " 'bacteria' 'width' 'toyota']\n",
      "VALUE: 4.444444444444445\n",
      "(19,)\n",
      "['bacterial' 'bacteria' 'danish' 'mccain' 'massa' 'kris' 'crying' 'ken'\n",
      " 'northward' 'predators']\n",
      "VALUE: 5.0\n",
      "(19,)\n",
      "['bacterial' 'bacteria' 'danish' 'mccain' 'massa' 'ken' 'kris' 'levin'\n",
      " 'bench' 'hilary']\n"
     ]
    }
   ],
   "source": [
    "find_top_words(train_glove_embed, train_glove_token, test_glove_embed, test_glove_token, glove_train_pos_cond_matrix_df, \"glove\", \"pos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_37 (InputLayer)           (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_38 (InputLayer)           (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 304)          0           input_37[0][0]                   \n",
      "                                                                 input_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_61 (Dense)                (None, 128)          39040       concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_62 (Dense)                (None, 75)           9675        dense_61[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_63 (Dense)                (None, 75)           9675        dense_61[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 75)           0           dense_62[0][0]                   \n",
      "                                                                 dense_63[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 79)           0           lambda_13[0][0]                  \n",
      "                                                                 input_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_64 (Dense)                (None, 128)          10240       concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_65 (Dense)                (None, 300)          38700       dense_64[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 107,330\n",
      "Trainable params: 107,330\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 12000 samples, validate on 3000 samples\n",
      "Epoch 1/50\n",
      " - 5s - loss: 0.1421 - val_loss: 0.1374\n",
      "Epoch 2/50\n",
      " - 2s - loss: 0.1371 - val_loss: 0.1373\n",
      "Epoch 3/50\n",
      " - 2s - loss: 0.1370 - val_loss: 0.1372\n",
      "Epoch 4/50\n",
      " - 2s - loss: 0.1369 - val_loss: 0.1371\n",
      "Epoch 5/50\n",
      " - 2s - loss: 0.1369 - val_loss: 0.1371\n",
      "Epoch 6/50\n",
      " - 2s - loss: 0.1368 - val_loss: 0.1371\n",
      "Epoch 7/50\n",
      " - 2s - loss: 0.1368 - val_loss: 0.1370\n",
      "Epoch 8/50\n",
      " - 2s - loss: 0.1367 - val_loss: 0.1370\n",
      "Epoch 9/50\n",
      " - 2s - loss: 0.1367 - val_loss: 0.1370\n",
      "Epoch 10/50\n",
      " - 2s - loss: 0.1367 - val_loss: 0.1369\n",
      "Epoch 11/50\n",
      " - 2s - loss: 0.1367 - val_loss: 0.1369\n",
      "Epoch 12/50\n",
      " - 2s - loss: 0.1367 - val_loss: 0.1369\n",
      "Epoch 13/50\n",
      " - 2s - loss: 0.1367 - val_loss: 0.1369\n",
      "Epoch 14/50\n",
      " - 2s - loss: 0.1367 - val_loss: 0.1369\n",
      "Epoch 15/50\n",
      " - 2s - loss: 0.1366 - val_loss: 0.1369\n",
      "Epoch 16/50\n",
      " - 2s - loss: 0.1366 - val_loss: 0.1369\n",
      "Epoch 17/50\n",
      " - 2s - loss: 0.1366 - val_loss: 0.1368\n",
      "Epoch 18/50\n",
      " - 2s - loss: 0.1366 - val_loss: 0.1369\n",
      "Epoch 19/50\n",
      " - 2s - loss: 0.1366 - val_loss: 0.1369\n",
      "Epoch 20/50\n",
      " - 2s - loss: 0.1366 - val_loss: 0.1368\n",
      "Epoch 21/50\n",
      " - 2s - loss: 0.1366 - val_loss: 0.1369\n",
      "Epoch 22/50\n",
      " - 2s - loss: 0.1366 - val_loss: 0.1368\n",
      "Epoch 23/50\n",
      " - 3s - loss: 0.1366 - val_loss: 0.1368\n",
      "Epoch 24/50\n",
      " - 3s - loss: 0.1366 - val_loss: 0.1368\n",
      "Epoch 25/50\n",
      " - 2s - loss: 0.1365 - val_loss: 0.1368\n",
      "Epoch 26/50\n",
      " - 2s - loss: 0.1365 - val_loss: 0.1368\n",
      "Epoch 27/50\n",
      " - 2s - loss: 0.1365 - val_loss: 0.1368\n",
      "Epoch 28/50\n",
      " - 2s - loss: 0.1365 - val_loss: 0.1368\n",
      "Epoch 29/50\n",
      " - 2s - loss: 0.1365 - val_loss: 0.1368\n",
      "Epoch 30/50\n",
      " - 2s - loss: 0.1365 - val_loss: 0.1368\n",
      "Epoch 31/50\n",
      " - 2s - loss: 0.1365 - val_loss: 0.1368\n",
      "Epoch 32/50\n",
      " - 2s - loss: 0.1365 - val_loss: 0.1368\n",
      "Epoch 33/50\n",
      " - 2s - loss: 0.1365 - val_loss: 0.1368\n",
      "Epoch 34/50\n",
      " - 2s - loss: 0.1365 - val_loss: 0.1368\n",
      "Epoch 35/50\n",
      " - 2s - loss: 0.1365 - val_loss: 0.1368\n",
      "Epoch 36/50\n",
      " - 2s - loss: 0.1365 - val_loss: 0.1368\n",
      "Epoch 37/50\n",
      " - 2s - loss: 0.1365 - val_loss: 0.1368\n",
      "Epoch 38/50\n",
      " - 2s - loss: 0.1365 - val_loss: 0.1367\n",
      "Epoch 39/50\n",
      " - 2s - loss: 0.1365 - val_loss: 0.1368\n",
      "Epoch 40/50\n",
      " - 2s - loss: 0.1365 - val_loss: 0.1368\n",
      "Epoch 41/50\n",
      " - 2s - loss: 0.1365 - val_loss: 0.1368\n",
      "Epoch 42/50\n",
      " - 2s - loss: 0.1365 - val_loss: 0.1368\n",
      "Epoch 43/50\n",
      " - 2s - loss: 0.1365 - val_loss: 0.1367\n",
      "Epoch 44/50\n",
      " - 2s - loss: 0.1365 - val_loss: 0.1367\n",
      "Epoch 45/50\n",
      " - 2s - loss: 0.1365 - val_loss: 0.1367\n",
      "Epoch 46/50\n",
      " - 2s - loss: 0.1365 - val_loss: 0.1367\n",
      "Epoch 47/50\n",
      " - 2s - loss: 0.1365 - val_loss: 0.1367\n",
      "Epoch 48/50\n",
      " - 2s - loss: 0.1365 - val_loss: 0.1367\n",
      "Epoch 49/50\n",
      " - 2s - loss: 0.1365 - val_loss: 0.1367\n",
      "Epoch 50/50\n",
      " - 2s - loss: 0.1365 - val_loss: 0.1367\n"
     ]
    }
   ],
   "source": [
    "### PARAMETERS ###\n",
    "decoder_out_dim = train_glove_embed.shape[1] # dim of decoder output layer\n",
    "n_x = train_glove_embed.shape[1]\n",
    "n_y = glove_train_sentiment_cond_matrix_df.shape[1]\n",
    "train_embed = train_glove_embed\n",
    "train_word = glove_train_sentiment_cond_matrix_df\n",
    "test_embed = test_glove_embed\n",
    "test_word = glove_test_sentiment_cond_matrix_df\n",
    "### PARAMETERS ###\n",
    "\n",
    "# define encoder\n",
    "X = Input(shape=(n_x,))\n",
    "label = Input(shape=(n_y,))\n",
    "inputs = concat([X, label])\n",
    "encoder_h = Dense(encoder_dim1, activation=activ)(inputs)\n",
    "mu = Dense(n_z, activation='linear')(encoder_h)\n",
    "l_sigma = Dense(n_z, activation='linear')(encoder_h)\n",
    "\n",
    "# sample latent space\n",
    "z = Lambda(sample_z, output_shape = (n_z, ))([mu, l_sigma])\n",
    "zc = concat([z, label])\n",
    "\n",
    "# decoder\n",
    "decoder_hidden = Dense(decoder_dim, activation=activ)\n",
    "decoder_out = Dense(decoder_out_dim, activation='sigmoid')\n",
    "h_p = decoder_hidden(zc)\n",
    "outputs = decoder_out(h_p)\n",
    "\n",
    "# define graphs\n",
    "cvae = Model([X, label], outputs)\n",
    "encoder = Model([X, label], mu)\n",
    "d_in = Input(shape=(n_z+n_y,))\n",
    "d_h = decoder_hidden(d_in)\n",
    "d_out = decoder_out(d_h)\n",
    "decoder = Model(d_in, d_out)\n",
    "\n",
    "# print statistics\n",
    "cvae.compile(optimizer=optim, loss=vae_loss)\n",
    "\n",
    "cvae.summary()\n",
    "\n",
    "cvae_hist = cvae.fit([train_embed, train_word], train_embed, verbose = 2, batch_size=m, \n",
    "                 epochs=n_epoch,\n",
    "                 validation_data = ([test_embed, test_word], test_embed),\n",
    "                 callbacks = [EarlyStopping(patience = 5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORD: mathematics\n",
      "8341\n",
      "VALUE: 0.0\n",
      "(4,)\n",
      "['share' 'pie' 'danish' 'kris' 'advanced' 'tim' 'hu' 'jobs' 'automotive'\n",
      " 'ibm']\n",
      "VALUE: 0.5555555555555556\n",
      "(4,)\n",
      "['share' 'kris' 'danish' 'pie' 'automotive' 'tim' 'hu' 'disability'\n",
      " 'profession' 'jobs']\n",
      "VALUE: 1.1111111111111112\n",
      "(4,)\n",
      "['ken' 'profession' 'kris' 'harley' 'stein' 'sophia' 'teaching' 'retiring'\n",
      " 'danish' 'dedication']\n",
      "VALUE: 1.6666666666666667\n",
      "(4,)\n",
      "['ken' 'harley' 'abd' 'sophia' 'kris' 'arabic' 'retiring' 'profession'\n",
      " 'retired' 'teaching']\n",
      "VALUE: 2.2222222222222223\n",
      "(4,)\n",
      "['abd' 'ken' 'arabic' 'harley' 'kris' 'sophia' 'kerr' 'stan' 'kmt'\n",
      " 'mercedes']\n",
      "VALUE: 2.7777777777777777\n",
      "(4,)\n",
      "['abd' 'ken' 'stan' 'syed' 'kerr' 'arabic' 'kmt' 'mercedes' 'hines' 'khan']\n",
      "VALUE: 3.3333333333333335\n",
      "(4,)\n",
      "['abd' 'stan' 'ken' 'syed' 'khan' 'rico' 'excellence' 'kerr' 'mcgee'\n",
      " 'ahmed']\n",
      "VALUE: 3.8888888888888893\n",
      "(4,)\n",
      "['abd' 'stan' 'syed' 'khan' 'ken' 'mcgee' 'rubin' 'excellence' 'rico' 'ko']\n",
      "VALUE: 4.444444444444445\n",
      "(4,)\n",
      "['abd' 'stan' 'khan' 'syed' 'ken' 'mcgee' 'rubin' 'excellence' 'ko' 'rico']\n",
      "VALUE: 5.0\n",
      "(4,)\n",
      "['abd' 'khan' 'syed' 'stan' 'ken' 'rubin' 'mcgee' 'excellence' 'ko'\n",
      " 'legends']\n",
      "WORD: mathematics\n",
      "8341\n",
      "VALUE: 0.0\n",
      "(4,)\n",
      "['arbor' 'ton' 'tasmania' 'building' 'revelations' 'constantine' 'tree'\n",
      " 'fireworks' 'fuse' 'lantern']\n",
      "VALUE: 0.5555555555555556\n",
      "(4,)\n",
      "['share' 'kris' 'pie' 'arbor' 'crashes' 'lacking' 'advanced' 'ibm'\n",
      " 'danish' 'jobs']\n",
      "VALUE: 1.1111111111111112\n",
      "(4,)\n",
      "['share' 'pie' 'danish' 'kris' 'advanced' 'tim' 'hu' 'automotive' 'phd'\n",
      " 'competitive']\n",
      "VALUE: 1.6666666666666667\n",
      "(4,)\n",
      "['pie' 'danish' 'phd' 'carlo' 'surrounds' 'shipbuilding' 'stein' 'massa'\n",
      " 'rumors' 'kris']\n",
      "VALUE: 2.2222222222222223\n",
      "(4,)\n",
      "['carlo' 'stein' 'surrounds' 'phd' 'pie' 'substances' 'danish' 'massa'\n",
      " 'rumor' 'rumors']\n",
      "VALUE: 2.7777777777777777\n",
      "(4,)\n",
      "['stein' 'carlo' 'moth' 'surrounds' 'mccain' 'substances' 'rumor' 'fungus'\n",
      " 'bench' 'massa']\n",
      "VALUE: 3.3333333333333335\n",
      "(4,)\n",
      "['moth' 'stein' 'mccain' 'carlo' 'bench' 'fungus' 'rumor' 'substances'\n",
      " 'surrounds' 'insects']\n",
      "VALUE: 3.8888888888888893\n",
      "(4,)\n",
      "['mccain' 'moth' 'carlo' 'stein' 'bench' 'rumor' 'fungus' 'substances'\n",
      " 'insects' 'dodd']\n",
      "VALUE: 4.444444444444445\n",
      "(4,)\n",
      "['mccain' 'moth' 'carlo' 'stein' 'bench' 'rumor' 'insects' 'fungus'\n",
      " 'substances' 'dodd']\n",
      "VALUE: 5.0\n",
      "(4,)\n",
      "['mccain' 'moth' 'carlo' 'stein' 'bench' 'insects' 'rumor' 'dodd' 'fungus'\n",
      " 'substances']\n",
      "WORD: mathematics\n",
      "8341\n",
      "VALUE: 0.0\n",
      "(4,)\n",
      "['share' 'pie' 'danish' 'kris' 'advanced' 'tim' 'hu' 'jobs' 'automotive'\n",
      " 'ibm']\n",
      "VALUE: 0.5555555555555556\n",
      "(4,)\n",
      "['share' 'kris' 'pie' 'danish' 'automotive' 'hu' 'advanced' 'tim' 'ibm'\n",
      " 'craft']\n",
      "VALUE: 1.1111111111111112\n",
      "(4,)\n",
      "['kris' 'stein' 'ken' 'kidd' 'danish' 'harley' 'automotive' 'competence'\n",
      " 'share' 'superior']\n",
      "VALUE: 1.6666666666666667\n",
      "(4,)\n",
      "['kris' 'stein' 'ken' 'warned' 'kidd' 'competence' 'suggests' 'capita'\n",
      " 'arabic' 'danish']\n",
      "VALUE: 2.2222222222222223\n",
      "(4,)\n",
      "['kris' 'stein' 'ken' 'competence' 'arabic' 'kidd' 'warned' 'putnam'\n",
      " 'trophies' 'mercedes']\n",
      "VALUE: 2.7777777777777777\n",
      "(4,)\n",
      "['kris' 'stein' 'arabic' 'putnam' 'trophies' 'kidd' 'competence'\n",
      " 'supremacy' 'esteem' 'mercedes']\n",
      "VALUE: 3.3333333333333335\n",
      "(4,)\n",
      "['kris' 'groin' 'artificial' 'gong' 'concentration' 'trophies' 'esteem'\n",
      " 'putnam' 'europeans' 'mercedes']\n",
      "VALUE: 3.8888888888888893\n",
      "(4,)\n",
      "['kris' 'groin' 'concentration' 'artificial' 'gong' 'esteem' 'trophies'\n",
      " 'evangelical' 'okay' 'europeans']\n",
      "VALUE: 4.444444444444445\n",
      "(4,)\n",
      "['groin' 'concentration' 'kris' 'okay' 'artificial' 'gong' 'nerve'\n",
      " 'esteem' 'evangelical' 'trophies']\n",
      "VALUE: 5.0\n",
      "(4,)\n",
      "['groin' 'concentration' 'okay' 'nerve' 'gong' 'artificial' 'evangelical'\n",
      " 'esteem' 'kris' 'mick']\n",
      "WORD: mathematics\n",
      "8341\n",
      "VALUE: 0.0\n",
      "(4,)\n",
      "['share' 'pie' 'danish' 'kris' 'advanced' 'tim' 'hu' 'jobs' 'automotive'\n",
      " 'ibm']\n",
      "VALUE: 0.5555555555555556\n",
      "(4,)\n",
      "['shipbuilding' 'kris' 'competitive' 'shipyard' 'carlo' 'pie' 'share'\n",
      " 'massa' 'automotive' 'danish']\n",
      "VALUE: 1.1111111111111112\n",
      "(4,)\n",
      "['shipbuilding' 'carlo' 'massa' 'bench' 'leadership' 'competitive' 'stein'\n",
      " 'kris' 'migratory' 'pie']\n",
      "VALUE: 1.6666666666666667\n",
      "(4,)\n",
      "['shipbuilding' 'leadership' 'carlo' 'massa' 'competence' 'migratory'\n",
      " 'bench' 'competitive' 'pie' 'stein']\n",
      "VALUE: 2.2222222222222223\n",
      "(4,)\n",
      "['leadership' 'competence' 'shipbuilding' 'migratory' 'competitive'\n",
      " 'carlo' 'massa' 'pie' 'healthcare' 'expertise']\n",
      "VALUE: 2.7777777777777777\n",
      "(4,)\n",
      "['competence' 'leadership' 'competent' 'competitive' 'translate'\n",
      " 'shipbuilding' 'migratory' 'expertise' 'healthcare' 'functional']\n",
      "VALUE: 3.3333333333333335\n",
      "(4,)\n",
      "['competent' 'competence' 'translate' 'functional' 'translates' 'literate'\n",
      " 'exit' 'competitive' 'zones' 'leadership']\n",
      "VALUE: 3.8888888888888893\n",
      "(4,)\n",
      "['competent' 'functional' 'competence' 'literate' 'slim' 'translate'\n",
      " 'zones' 'cancellation' 'managerial' 'exit']\n",
      "VALUE: 4.444444444444445\n",
      "(4,)\n",
      "['competent' 'functional' 'competence' 'slim' 'literate' 'zones'\n",
      " 'cancellation' 'managerial' 'hiatus' 'translate']\n",
      "VALUE: 5.0\n",
      "(4,)\n",
      "['functional' 'competent' 'slim' 'hiatus' 'zones' 'competence' 'literate'\n",
      " 'managerial' 'cancellation' 'translate']\n",
      "WORD: remote\n",
      "2616\n",
      "VALUE: 0.0\n",
      "(4,)\n",
      "['share' 'pie' 'danish' 'kris' 'advanced' 'tim' 'hu' 'jobs' 'automotive'\n",
      " 'ibm']\n",
      "VALUE: 0.5555555555555556\n",
      "(4,)\n",
      "['share' 'kris' 'danish' 'pie' 'automotive' 'tim' 'hu' 'disability'\n",
      " 'profession' 'jobs']\n",
      "VALUE: 1.1111111111111112\n",
      "(4,)\n",
      "['ken' 'profession' 'kris' 'harley' 'stein' 'sophia' 'teaching' 'retiring'\n",
      " 'danish' 'dedication']\n",
      "VALUE: 1.6666666666666667\n",
      "(4,)\n",
      "['ken' 'harley' 'abd' 'sophia' 'kris' 'arabic' 'retiring' 'profession'\n",
      " 'retired' 'teaching']\n",
      "VALUE: 2.2222222222222223\n",
      "(4,)\n",
      "['abd' 'ken' 'arabic' 'harley' 'kris' 'sophia' 'kerr' 'stan' 'kmt'\n",
      " 'mercedes']\n",
      "VALUE: 2.7777777777777777\n",
      "(4,)\n",
      "['abd' 'ken' 'stan' 'syed' 'kerr' 'arabic' 'kmt' 'mercedes' 'hines' 'khan']\n",
      "VALUE: 3.3333333333333335\n",
      "(4,)\n",
      "['abd' 'stan' 'ken' 'syed' 'khan' 'rico' 'excellence' 'kerr' 'mcgee'\n",
      " 'ahmed']\n",
      "VALUE: 3.8888888888888893\n",
      "(4,)\n",
      "['abd' 'stan' 'syed' 'khan' 'ken' 'mcgee' 'rubin' 'excellence' 'rico' 'ko']\n",
      "VALUE: 4.444444444444445\n",
      "(4,)\n",
      "['abd' 'stan' 'khan' 'syed' 'ken' 'mcgee' 'rubin' 'excellence' 'ko' 'rico']\n",
      "VALUE: 5.0\n",
      "(4,)\n",
      "['abd' 'khan' 'syed' 'stan' 'ken' 'rubin' 'mcgee' 'excellence' 'ko'\n",
      " 'legends']\n",
      "WORD: remote\n",
      "2616\n",
      "VALUE: 0.0\n",
      "(4,)\n",
      "['arbor' 'ton' 'tasmania' 'building' 'revelations' 'constantine' 'tree'\n",
      " 'fireworks' 'fuse' 'lantern']\n",
      "VALUE: 0.5555555555555556\n",
      "(4,)\n",
      "['share' 'kris' 'pie' 'arbor' 'crashes' 'lacking' 'advanced' 'ibm'\n",
      " 'danish' 'jobs']\n",
      "VALUE: 1.1111111111111112\n",
      "(4,)\n",
      "['share' 'pie' 'danish' 'kris' 'advanced' 'tim' 'hu' 'automotive' 'phd'\n",
      " 'competitive']\n",
      "VALUE: 1.6666666666666667\n",
      "(4,)\n",
      "['pie' 'danish' 'phd' 'carlo' 'surrounds' 'shipbuilding' 'stein' 'massa'\n",
      " 'rumors' 'kris']\n",
      "VALUE: 2.2222222222222223\n",
      "(4,)\n",
      "['carlo' 'stein' 'surrounds' 'phd' 'pie' 'substances' 'danish' 'massa'\n",
      " 'rumor' 'rumors']\n",
      "VALUE: 2.7777777777777777\n",
      "(4,)\n",
      "['stein' 'carlo' 'moth' 'surrounds' 'mccain' 'substances' 'rumor' 'fungus'\n",
      " 'bench' 'massa']\n",
      "VALUE: 3.3333333333333335\n",
      "(4,)\n",
      "['moth' 'stein' 'mccain' 'carlo' 'bench' 'fungus' 'rumor' 'substances'\n",
      " 'surrounds' 'insects']\n",
      "VALUE: 3.8888888888888893\n",
      "(4,)\n",
      "['mccain' 'moth' 'carlo' 'stein' 'bench' 'rumor' 'fungus' 'substances'\n",
      " 'insects' 'dodd']\n",
      "VALUE: 4.444444444444445\n",
      "(4,)\n",
      "['mccain' 'moth' 'carlo' 'stein' 'bench' 'rumor' 'insects' 'fungus'\n",
      " 'substances' 'dodd']\n",
      "VALUE: 5.0\n",
      "(4,)\n",
      "['mccain' 'moth' 'carlo' 'stein' 'bench' 'insects' 'rumor' 'dodd' 'fungus'\n",
      " 'substances']\n",
      "WORD: remote\n",
      "2616\n",
      "VALUE: 0.0\n",
      "(4,)\n",
      "['share' 'pie' 'danish' 'kris' 'advanced' 'tim' 'hu' 'jobs' 'automotive'\n",
      " 'ibm']\n",
      "VALUE: 0.5555555555555556\n",
      "(4,)\n",
      "['share' 'kris' 'pie' 'danish' 'automotive' 'hu' 'advanced' 'tim' 'ibm'\n",
      " 'craft']\n",
      "VALUE: 1.1111111111111112\n",
      "(4,)\n",
      "['kris' 'stein' 'ken' 'kidd' 'danish' 'harley' 'automotive' 'competence'\n",
      " 'share' 'superior']\n",
      "VALUE: 1.6666666666666667\n",
      "(4,)\n",
      "['kris' 'stein' 'ken' 'warned' 'kidd' 'competence' 'suggests' 'capita'\n",
      " 'arabic' 'danish']\n",
      "VALUE: 2.2222222222222223\n",
      "(4,)\n",
      "['kris' 'stein' 'ken' 'competence' 'arabic' 'kidd' 'warned' 'putnam'\n",
      " 'trophies' 'mercedes']\n",
      "VALUE: 2.7777777777777777\n",
      "(4,)\n",
      "['kris' 'stein' 'arabic' 'putnam' 'trophies' 'kidd' 'competence'\n",
      " 'supremacy' 'esteem' 'mercedes']\n",
      "VALUE: 3.3333333333333335\n",
      "(4,)\n",
      "['kris' 'groin' 'artificial' 'gong' 'concentration' 'trophies' 'esteem'\n",
      " 'putnam' 'europeans' 'mercedes']\n",
      "VALUE: 3.8888888888888893\n",
      "(4,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kris' 'groin' 'concentration' 'artificial' 'gong' 'esteem' 'trophies'\n",
      " 'evangelical' 'okay' 'europeans']\n",
      "VALUE: 4.444444444444445\n",
      "(4,)\n",
      "['groin' 'concentration' 'kris' 'okay' 'artificial' 'gong' 'nerve'\n",
      " 'esteem' 'evangelical' 'trophies']\n",
      "VALUE: 5.0\n",
      "(4,)\n",
      "['groin' 'concentration' 'okay' 'nerve' 'gong' 'artificial' 'evangelical'\n",
      " 'esteem' 'kris' 'mick']\n",
      "WORD: remote\n",
      "2616\n",
      "VALUE: 0.0\n",
      "(4,)\n",
      "['share' 'pie' 'danish' 'kris' 'advanced' 'tim' 'hu' 'jobs' 'automotive'\n",
      " 'ibm']\n",
      "VALUE: 0.5555555555555556\n",
      "(4,)\n",
      "['shipbuilding' 'kris' 'competitive' 'shipyard' 'carlo' 'pie' 'share'\n",
      " 'massa' 'automotive' 'danish']\n",
      "VALUE: 1.1111111111111112\n",
      "(4,)\n",
      "['shipbuilding' 'carlo' 'massa' 'bench' 'leadership' 'competitive' 'stein'\n",
      " 'kris' 'migratory' 'pie']\n",
      "VALUE: 1.6666666666666667\n",
      "(4,)\n",
      "['shipbuilding' 'leadership' 'carlo' 'massa' 'competence' 'migratory'\n",
      " 'bench' 'competitive' 'pie' 'stein']\n",
      "VALUE: 2.2222222222222223\n",
      "(4,)\n",
      "['leadership' 'competence' 'shipbuilding' 'migratory' 'competitive'\n",
      " 'carlo' 'massa' 'pie' 'healthcare' 'expertise']\n",
      "VALUE: 2.7777777777777777\n",
      "(4,)\n",
      "['competence' 'leadership' 'competent' 'competitive' 'translate'\n",
      " 'shipbuilding' 'migratory' 'expertise' 'healthcare' 'functional']\n",
      "VALUE: 3.3333333333333335\n",
      "(4,)\n",
      "['competent' 'competence' 'translate' 'functional' 'translates' 'literate'\n",
      " 'exit' 'competitive' 'zones' 'leadership']\n",
      "VALUE: 3.8888888888888893\n",
      "(4,)\n",
      "['competent' 'functional' 'competence' 'literate' 'slim' 'translate'\n",
      " 'zones' 'cancellation' 'managerial' 'exit']\n",
      "VALUE: 4.444444444444445\n",
      "(4,)\n",
      "['competent' 'functional' 'competence' 'slim' 'literate' 'zones'\n",
      " 'cancellation' 'managerial' 'hiatus' 'translate']\n",
      "VALUE: 5.0\n",
      "(4,)\n",
      "['functional' 'competent' 'slim' 'hiatus' 'zones' 'competence' 'literate'\n",
      " 'managerial' 'cancellation' 'translate']\n",
      "WORD: internet\n",
      "6647\n",
      "VALUE: 0.0\n",
      "(4,)\n",
      "['share' 'pie' 'danish' 'kris' 'advanced' 'tim' 'hu' 'jobs' 'automotive'\n",
      " 'ibm']\n",
      "VALUE: 0.5555555555555556\n",
      "(4,)\n",
      "['share' 'kris' 'danish' 'pie' 'automotive' 'tim' 'hu' 'disability'\n",
      " 'profession' 'jobs']\n",
      "VALUE: 1.1111111111111112\n",
      "(4,)\n",
      "['ken' 'profession' 'kris' 'harley' 'stein' 'sophia' 'teaching' 'retiring'\n",
      " 'danish' 'dedication']\n",
      "VALUE: 1.6666666666666667\n",
      "(4,)\n",
      "['ken' 'harley' 'abd' 'sophia' 'kris' 'arabic' 'retiring' 'profession'\n",
      " 'retired' 'teaching']\n",
      "VALUE: 2.2222222222222223\n",
      "(4,)\n",
      "['abd' 'ken' 'arabic' 'harley' 'kris' 'sophia' 'kerr' 'stan' 'kmt'\n",
      " 'mercedes']\n",
      "VALUE: 2.7777777777777777\n",
      "(4,)\n",
      "['abd' 'ken' 'stan' 'syed' 'kerr' 'arabic' 'kmt' 'mercedes' 'hines' 'khan']\n",
      "VALUE: 3.3333333333333335\n",
      "(4,)\n",
      "['abd' 'stan' 'ken' 'syed' 'khan' 'rico' 'excellence' 'kerr' 'mcgee'\n",
      " 'ahmed']\n",
      "VALUE: 3.8888888888888893\n",
      "(4,)\n",
      "['abd' 'stan' 'syed' 'khan' 'ken' 'mcgee' 'rubin' 'excellence' 'rico' 'ko']\n",
      "VALUE: 4.444444444444445\n",
      "(4,)\n",
      "['abd' 'stan' 'khan' 'syed' 'ken' 'mcgee' 'rubin' 'excellence' 'ko' 'rico']\n",
      "VALUE: 5.0\n",
      "(4,)\n",
      "['abd' 'khan' 'syed' 'stan' 'ken' 'rubin' 'mcgee' 'excellence' 'ko'\n",
      " 'legends']\n",
      "WORD: internet\n",
      "6647\n",
      "VALUE: 0.0\n",
      "(4,)\n",
      "['arbor' 'ton' 'tasmania' 'building' 'revelations' 'constantine' 'tree'\n",
      " 'fireworks' 'fuse' 'lantern']\n",
      "VALUE: 0.5555555555555556\n",
      "(4,)\n",
      "['share' 'kris' 'pie' 'arbor' 'crashes' 'lacking' 'advanced' 'ibm'\n",
      " 'danish' 'jobs']\n",
      "VALUE: 1.1111111111111112\n",
      "(4,)\n",
      "['share' 'pie' 'danish' 'kris' 'advanced' 'tim' 'hu' 'automotive' 'phd'\n",
      " 'competitive']\n",
      "VALUE: 1.6666666666666667\n",
      "(4,)\n",
      "['pie' 'danish' 'phd' 'carlo' 'surrounds' 'shipbuilding' 'stein' 'massa'\n",
      " 'rumors' 'kris']\n",
      "VALUE: 2.2222222222222223\n",
      "(4,)\n",
      "['carlo' 'stein' 'surrounds' 'phd' 'pie' 'substances' 'danish' 'massa'\n",
      " 'rumor' 'rumors']\n",
      "VALUE: 2.7777777777777777\n",
      "(4,)\n",
      "['stein' 'carlo' 'moth' 'surrounds' 'mccain' 'substances' 'rumor' 'fungus'\n",
      " 'bench' 'massa']\n",
      "VALUE: 3.3333333333333335\n",
      "(4,)\n",
      "['moth' 'stein' 'mccain' 'carlo' 'bench' 'fungus' 'rumor' 'substances'\n",
      " 'surrounds' 'insects']\n",
      "VALUE: 3.8888888888888893\n",
      "(4,)\n",
      "['mccain' 'moth' 'carlo' 'stein' 'bench' 'rumor' 'fungus' 'substances'\n",
      " 'insects' 'dodd']\n",
      "VALUE: 4.444444444444445\n",
      "(4,)\n",
      "['mccain' 'moth' 'carlo' 'stein' 'bench' 'rumor' 'insects' 'fungus'\n",
      " 'substances' 'dodd']\n",
      "VALUE: 5.0\n",
      "(4,)\n",
      "['mccain' 'moth' 'carlo' 'stein' 'bench' 'insects' 'rumor' 'dodd' 'fungus'\n",
      " 'substances']\n",
      "WORD: internet\n",
      "6647\n",
      "VALUE: 0.0\n",
      "(4,)\n",
      "['share' 'pie' 'danish' 'kris' 'advanced' 'tim' 'hu' 'jobs' 'automotive'\n",
      " 'ibm']\n",
      "VALUE: 0.5555555555555556\n",
      "(4,)\n",
      "['share' 'kris' 'pie' 'danish' 'automotive' 'hu' 'advanced' 'tim' 'ibm'\n",
      " 'craft']\n",
      "VALUE: 1.1111111111111112\n",
      "(4,)\n",
      "['kris' 'stein' 'ken' 'kidd' 'danish' 'harley' 'automotive' 'competence'\n",
      " 'share' 'superior']\n",
      "VALUE: 1.6666666666666667\n",
      "(4,)\n",
      "['kris' 'stein' 'ken' 'warned' 'kidd' 'competence' 'suggests' 'capita'\n",
      " 'arabic' 'danish']\n",
      "VALUE: 2.2222222222222223\n",
      "(4,)\n",
      "['kris' 'stein' 'ken' 'competence' 'arabic' 'kidd' 'warned' 'putnam'\n",
      " 'trophies' 'mercedes']\n",
      "VALUE: 2.7777777777777777\n",
      "(4,)\n",
      "['kris' 'stein' 'arabic' 'putnam' 'trophies' 'kidd' 'competence'\n",
      " 'supremacy' 'esteem' 'mercedes']\n",
      "VALUE: 3.3333333333333335\n",
      "(4,)\n",
      "['kris' 'groin' 'artificial' 'gong' 'concentration' 'trophies' 'esteem'\n",
      " 'putnam' 'europeans' 'mercedes']\n",
      "VALUE: 3.8888888888888893\n",
      "(4,)\n",
      "['kris' 'groin' 'concentration' 'artificial' 'gong' 'esteem' 'trophies'\n",
      " 'evangelical' 'okay' 'europeans']\n",
      "VALUE: 4.444444444444445\n",
      "(4,)\n",
      "['groin' 'concentration' 'kris' 'okay' 'artificial' 'gong' 'nerve'\n",
      " 'esteem' 'evangelical' 'trophies']\n",
      "VALUE: 5.0\n",
      "(4,)\n",
      "['groin' 'concentration' 'okay' 'nerve' 'gong' 'artificial' 'evangelical'\n",
      " 'esteem' 'kris' 'mick']\n",
      "WORD: internet\n",
      "6647\n",
      "VALUE: 0.0\n",
      "(4,)\n",
      "['share' 'pie' 'danish' 'kris' 'advanced' 'tim' 'hu' 'jobs' 'automotive'\n",
      " 'ibm']\n",
      "VALUE: 0.5555555555555556\n",
      "(4,)\n",
      "['shipbuilding' 'kris' 'competitive' 'shipyard' 'carlo' 'pie' 'share'\n",
      " 'massa' 'automotive' 'danish']\n",
      "VALUE: 1.1111111111111112\n",
      "(4,)\n",
      "['shipbuilding' 'carlo' 'massa' 'bench' 'leadership' 'competitive' 'stein'\n",
      " 'kris' 'migratory' 'pie']\n",
      "VALUE: 1.6666666666666667\n",
      "(4,)\n",
      "['shipbuilding' 'leadership' 'carlo' 'massa' 'competence' 'migratory'\n",
      " 'bench' 'competitive' 'pie' 'stein']\n",
      "VALUE: 2.2222222222222223\n",
      "(4,)\n",
      "['leadership' 'competence' 'shipbuilding' 'migratory' 'competitive'\n",
      " 'carlo' 'massa' 'pie' 'healthcare' 'expertise']\n",
      "VALUE: 2.7777777777777777\n",
      "(4,)\n",
      "['competence' 'leadership' 'competent' 'competitive' 'translate'\n",
      " 'shipbuilding' 'migratory' 'expertise' 'healthcare' 'functional']\n",
      "VALUE: 3.3333333333333335\n",
      "(4,)\n",
      "['competent' 'competence' 'translate' 'functional' 'translates' 'literate'\n",
      " 'exit' 'competitive' 'zones' 'leadership']\n",
      "VALUE: 3.8888888888888893\n",
      "(4,)\n",
      "['competent' 'functional' 'competence' 'literate' 'slim' 'translate'\n",
      " 'zones' 'cancellation' 'managerial' 'exit']\n",
      "VALUE: 4.444444444444445\n",
      "(4,)\n",
      "['competent' 'functional' 'competence' 'slim' 'literate' 'zones'\n",
      " 'cancellation' 'managerial' 'hiatus' 'translate']\n",
      "VALUE: 5.0\n",
      "(4,)\n",
      "['functional' 'competent' 'slim' 'hiatus' 'zones' 'competence' 'literate'\n",
      " 'managerial' 'cancellation' 'translate']\n"
     ]
    }
   ],
   "source": [
    "find_top_words(train_glove_embed, train_glove_token, test_glove_embed, test_glove_token, glove_train_sentiment_cond_matrix_df, \"glove\", \"sentiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "named entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_40 (InputLayer)           (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_41 (InputLayer)           (None, 17)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 317)          0           input_40[0][0]                   \n",
      "                                                                 input_41[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_66 (Dense)                (None, 128)          40704       concatenate_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_67 (Dense)                (None, 75)           9675        dense_66[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_68 (Dense)                (None, 75)           9675        dense_66[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 75)           0           dense_67[0][0]                   \n",
      "                                                                 dense_68[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 92)           0           lambda_14[0][0]                  \n",
      "                                                                 input_41[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_69 (Dense)                (None, 128)          11904       concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_70 (Dense)                (None, 300)          38700       dense_69[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 110,658\n",
      "Trainable params: 110,658\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 12000 samples, validate on 3000 samples\n",
      "Epoch 1/50\n",
      " - 3s - loss: 0.1422 - val_loss: 0.1374\n",
      "Epoch 2/50\n",
      " - 2s - loss: 0.1371 - val_loss: 0.1373\n",
      "Epoch 3/50\n",
      " - 2s - loss: 0.1370 - val_loss: 0.1373\n",
      "Epoch 4/50\n",
      " - 2s - loss: 0.1370 - val_loss: 0.1372\n",
      "Epoch 5/50\n",
      " - 2s - loss: 0.1370 - val_loss: 0.1372\n",
      "Epoch 6/50\n",
      " - 2s - loss: 0.1370 - val_loss: 0.1372\n",
      "Epoch 7/50\n",
      " - 2s - loss: 0.1370 - val_loss: 0.1372\n",
      "Epoch 8/50\n",
      " - 2s - loss: 0.1370 - val_loss: 0.1372\n",
      "Epoch 9/50\n",
      " - 2s - loss: 0.1370 - val_loss: 0.1372\n",
      "Epoch 10/50\n",
      " - 2s - loss: 0.1370 - val_loss: 0.1372\n",
      "Epoch 11/50\n",
      " - 2s - loss: 0.1369 - val_loss: 0.1372\n",
      "Epoch 12/50\n",
      " - 2s - loss: 0.1370 - val_loss: 0.1372\n",
      "Epoch 13/50\n",
      " - 2s - loss: 0.1370 - val_loss: 0.1372\n",
      "Epoch 14/50\n",
      " - 2s - loss: 0.1369 - val_loss: 0.1372\n",
      "Epoch 15/50\n",
      " - 2s - loss: 0.1369 - val_loss: 0.1372\n",
      "Epoch 16/50\n",
      " - 2s - loss: 0.1369 - val_loss: 0.1372\n",
      "Epoch 17/50\n",
      " - 2s - loss: 0.1369 - val_loss: 0.1372\n",
      "Epoch 18/50\n",
      " - 2s - loss: 0.1369 - val_loss: 0.1372\n",
      "Epoch 19/50\n",
      " - 2s - loss: 0.1369 - val_loss: 0.1372\n",
      "Epoch 20/50\n",
      " - 2s - loss: 0.1369 - val_loss: 0.1372\n",
      "Epoch 21/50\n",
      " - 2s - loss: 0.1369 - val_loss: 0.1372\n",
      "Epoch 22/50\n",
      " - 2s - loss: 0.1369 - val_loss: 0.1372\n",
      "Epoch 23/50\n",
      " - 2s - loss: 0.1369 - val_loss: 0.1372\n",
      "Epoch 24/50\n",
      " - 2s - loss: 0.1369 - val_loss: 0.1372\n",
      "Epoch 25/50\n",
      " - 2s - loss: 0.1369 - val_loss: 0.1372\n",
      "Epoch 26/50\n",
      " - 2s - loss: 0.1369 - val_loss: 0.1372\n",
      "Epoch 27/50\n",
      " - 2s - loss: 0.1369 - val_loss: 0.1372\n",
      "Epoch 28/50\n",
      " - 2s - loss: 0.1369 - val_loss: 0.1372\n",
      "Epoch 29/50\n",
      " - 2s - loss: 0.1369 - val_loss: 0.1372\n"
     ]
    }
   ],
   "source": [
    "### PARAMETERS ###\n",
    "decoder_out_dim = train_glove_embed.shape[1] # dim of decoder output layer\n",
    "n_x = train_glove_embed.shape[1]\n",
    "n_y = glove_train_entities_cond_matrix_df.shape[1]\n",
    "train_embed = train_glove_embed\n",
    "train_word = glove_train_entities_cond_matrix_df\n",
    "test_embed = test_glove_embed\n",
    "test_word = glove_test_entities_cond_matrix_df\n",
    "### PARAMETERS ###\n",
    "\n",
    "# define encoder\n",
    "X = Input(shape=(n_x,))\n",
    "label = Input(shape=(n_y,))\n",
    "inputs = concat([X, label])\n",
    "encoder_h = Dense(encoder_dim1, activation=activ)(inputs)\n",
    "mu = Dense(n_z, activation='linear')(encoder_h)\n",
    "l_sigma = Dense(n_z, activation='linear')(encoder_h)\n",
    "\n",
    "# sample latent space\n",
    "z = Lambda(sample_z, output_shape = (n_z, ))([mu, l_sigma])\n",
    "zc = concat([z, label])\n",
    "\n",
    "# decoder\n",
    "decoder_hidden = Dense(decoder_dim, activation=activ)\n",
    "decoder_out = Dense(decoder_out_dim, activation='sigmoid')\n",
    "h_p = decoder_hidden(zc)\n",
    "outputs = decoder_out(h_p)\n",
    "\n",
    "# define graphs\n",
    "cvae = Model([X, label], outputs)\n",
    "encoder = Model([X, label], mu)\n",
    "d_in = Input(shape=(n_z+n_y,))\n",
    "d_h = decoder_hidden(d_in)\n",
    "d_out = decoder_out(d_h)\n",
    "decoder = Model(d_in, d_out)\n",
    "\n",
    "# print statistics\n",
    "cvae.compile(optimizer=optim, loss=vae_loss)\n",
    "\n",
    "cvae.summary()\n",
    "\n",
    "cvae_hist = cvae.fit([train_embed, train_word], train_embed, verbose = 2, batch_size=m, \n",
    "                 epochs=n_epoch,\n",
    "                 validation_data = ([test_embed, test_word], test_embed),\n",
    "                 callbacks = [EarlyStopping(patience = 5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORD: mathematics\n",
      "8341\n",
      "VALUE: 0.0\n",
      "(17,)\n",
      "['share' 'lacking' 'kris' 'crashes' 'pie' 'constantine' 'automotive'\n",
      " 'danish' 'arbor' 'aerospace']\n",
      "VALUE: 0.5555555555555556\n",
      "(17,)\n",
      "['share' 'lacking' 'kris' 'crashes' 'pie' 'constantine' 'automotive'\n",
      " 'danish' 'arbor' 'aerospace']\n",
      "VALUE: 1.1111111111111112\n",
      "(17,)\n",
      "['share' 'lacking' 'kris' 'crashes' 'constantine' 'pie' 'automotive'\n",
      " 'aerospace' 'danish' 'arbor']\n",
      "VALUE: 1.6666666666666667\n",
      "(17,)\n",
      "['share' 'lacking' 'kris' 'crashes' 'constantine' 'pie' 'automotive'\n",
      " 'aerospace' 'danish' 'arbor']\n",
      "VALUE: 2.2222222222222223\n",
      "(17,)\n",
      "['share' 'lacking' 'automotive' 'kris' 'constantine' 'crashes' 'pie'\n",
      " 'aerospace' 'ibm' 'arbor']\n",
      "VALUE: 2.7777777777777777\n",
      "(17,)\n",
      "['share' 'lacking' 'automotive' 'kris' 'constantine' 'crashes' 'pie'\n",
      " 'aerospace' 'ibm' 'arbor']\n",
      "VALUE: 3.3333333333333335\n",
      "(17,)\n",
      "['share' 'automotive' 'kris' 'pie' 'lacking' 'constantine' 'aerospace'\n",
      " 'crashes' 'ibm' 'danish']\n",
      "VALUE: 3.8888888888888893\n",
      "(17,)\n",
      "['share' 'automotive' 'kris' 'pie' 'lacking' 'constantine' 'aerospace'\n",
      " 'crashes' 'ibm' 'danish']\n",
      "VALUE: 4.444444444444445\n",
      "(17,)\n",
      "['share' 'automotive' 'pie' 'kris' 'aerospace' 'ibm' 'lacking' 'danish'\n",
      " 'constantine' 'crashes']\n",
      "VALUE: 5.0\n",
      "(17,)\n",
      "['automotive' 'share' 'pie' 'kris' 'aerospace' 'danish' 'ibm' 'lacking'\n",
      " 'semiconductor' 'hu']\n",
      "WORD: mathematics\n",
      "8341\n",
      "VALUE: 0.0\n",
      "(17,)\n",
      "['share' 'lacking' 'kris' 'crashes' 'pie' 'constantine' 'automotive'\n",
      " 'danish' 'arbor' 'aerospace']\n",
      "VALUE: 0.5555555555555556\n",
      "(17,)\n",
      "['share' 'lacking' 'kris' 'crashes' 'pie' 'constantine' 'automotive'\n",
      " 'danish' 'arbor' 'aerospace']\n",
      "VALUE: 1.1111111111111112\n",
      "(17,)\n",
      "['share' 'lacking' 'kris' 'pie' 'crashes' 'constantine' 'danish' 'arbor'\n",
      " 'automotive' 'aerospace']\n",
      "VALUE: 1.6666666666666667\n",
      "(17,)\n",
      "['share' 'lacking' 'kris' 'pie' 'crashes' 'constantine' 'danish' 'arbor'\n",
      " 'automotive' 'aerospace']\n",
      "VALUE: 2.2222222222222223\n",
      "(17,)\n",
      "['share' 'lacking' 'kris' 'pie' 'danish' 'crashes' 'arbor' 'aerospace'\n",
      " 'constantine' 'automotive']\n",
      "VALUE: 2.7777777777777777\n",
      "(17,)\n",
      "['share' 'lacking' 'kris' 'pie' 'danish' 'crashes' 'arbor' 'aerospace'\n",
      " 'constantine' 'automotive']\n",
      "VALUE: 3.3333333333333335\n",
      "(17,)\n",
      "['share' 'lacking' 'kris' 'pie' 'danish' 'aerospace' 'automotive' 'ibm'\n",
      " 'crashes' 'arbor']\n",
      "VALUE: 3.8888888888888893\n",
      "(17,)\n",
      "['share' 'lacking' 'kris' 'pie' 'danish' 'aerospace' 'automotive' 'ibm'\n",
      " 'crashes' 'arbor']\n",
      "VALUE: 4.444444444444445\n",
      "(17,)\n",
      "['share' 'kris' 'pie' 'danish' 'lacking' 'aerospace' 'automotive' 'hu'\n",
      " 'ibm' 'tim']\n",
      "VALUE: 5.0\n",
      "(17,)\n",
      "['share' 'pie' 'kris' 'danish' 'lacking' 'automotive' 'hu' 'aerospace'\n",
      " 'tim' 'ibm']\n",
      "WORD: mathematics\n",
      "8341\n",
      "VALUE: 0.0\n",
      "(17,)\n",
      "['share' 'lacking' 'kris' 'crashes' 'pie' 'constantine' 'automotive'\n",
      " 'danish' 'arbor' 'aerospace']\n",
      "VALUE: 0.5555555555555556\n",
      "(17,)\n",
      "['share' 'lacking' 'kris' 'crashes' 'pie' 'constantine' 'automotive'\n",
      " 'danish' 'arbor' 'aerospace']\n",
      "VALUE: 1.1111111111111112\n",
      "(17,)\n",
      "['share' 'lacking' 'kris' 'crashes' 'pie' 'constantine' 'danish'\n",
      " 'automotive' 'arbor' 'aerospace']\n",
      "VALUE: 1.6666666666666667\n",
      "(17,)\n",
      "['share' 'lacking' 'kris' 'crashes' 'pie' 'constantine' 'danish'\n",
      " 'automotive' 'arbor' 'aerospace']\n",
      "VALUE: 2.2222222222222223\n",
      "(17,)\n",
      "['share' 'lacking' 'kris' 'pie' 'crashes' 'constantine' 'danish'\n",
      " 'automotive' 'aerospace' 'flash']\n",
      "VALUE: 2.7777777777777777\n",
      "(17,)\n",
      "['share' 'lacking' 'kris' 'pie' 'crashes' 'constantine' 'danish'\n",
      " 'automotive' 'aerospace' 'flash']\n",
      "VALUE: 3.3333333333333335\n",
      "(17,)\n",
      "['share' 'lacking' 'pie' 'kris' 'danish' 'crashes' 'constantine'\n",
      " 'automotive' 'aerospace' 'superior']\n",
      "VALUE: 3.8888888888888893\n",
      "(17,)\n",
      "['share' 'lacking' 'pie' 'kris' 'danish' 'crashes' 'constantine'\n",
      " 'automotive' 'aerospace' 'superior']\n",
      "VALUE: 4.444444444444445\n",
      "(17,)\n",
      "['share' 'pie' 'danish' 'kris' 'lacking' 'automotive' 'aerospace'\n",
      " 'superior' 'hu' 'compete']\n",
      "VALUE: 5.0\n",
      "(17,)\n",
      "['share' 'pie' 'danish' 'kris' 'lacking' 'automotive' 'aerospace' 'hu'\n",
      " 'competitive' 'superior']\n",
      "WORD: remote\n",
      "2616\n",
      "VALUE: 0.0\n",
      "(17,)\n",
      "['share' 'lacking' 'kris' 'crashes' 'pie' 'constantine' 'automotive'\n",
      " 'danish' 'arbor' 'aerospace']\n",
      "VALUE: 0.5555555555555556\n",
      "(17,)\n",
      "['share' 'lacking' 'kris' 'crashes' 'pie' 'constantine' 'automotive'\n",
      " 'danish' 'arbor' 'aerospace']\n",
      "VALUE: 1.1111111111111112\n",
      "(17,)\n",
      "['share' 'lacking' 'kris' 'crashes' 'constantine' 'pie' 'automotive'\n",
      " 'aerospace' 'danish' 'arbor']\n",
      "VALUE: 1.6666666666666667\n",
      "(17,)\n",
      "['share' 'lacking' 'kris' 'crashes' 'constantine' 'pie' 'automotive'\n",
      " 'aerospace' 'danish' 'arbor']\n",
      "VALUE: 2.2222222222222223\n",
      "(17,)\n",
      "['share' 'lacking' 'automotive' 'kris' 'constantine' 'crashes' 'pie'\n",
      " 'aerospace' 'ibm' 'arbor']\n",
      "VALUE: 2.7777777777777777\n",
      "(17,)\n",
      "['share' 'lacking' 'automotive' 'kris' 'constantine' 'crashes' 'pie'\n",
      " 'aerospace' 'ibm' 'arbor']\n",
      "VALUE: 3.3333333333333335\n",
      "(17,)\n",
      "['share' 'automotive' 'kris' 'pie' 'lacking' 'constantine' 'aerospace'\n",
      " 'crashes' 'ibm' 'danish']\n",
      "VALUE: 3.8888888888888893\n",
      "(17,)\n",
      "['share' 'automotive' 'kris' 'pie' 'lacking' 'constantine' 'aerospace'\n",
      " 'crashes' 'ibm' 'danish']\n",
      "VALUE: 4.444444444444445\n",
      "(17,)\n",
      "['share' 'automotive' 'pie' 'kris' 'aerospace' 'ibm' 'lacking' 'danish'\n",
      " 'constantine' 'crashes']\n",
      "VALUE: 5.0\n",
      "(17,)\n",
      "['automotive' 'share' 'pie' 'kris' 'aerospace' 'danish' 'ibm' 'lacking'\n",
      " 'semiconductor' 'hu']\n",
      "WORD: remote\n",
      "2616\n",
      "VALUE: 0.0\n",
      "(17,)\n",
      "['share' 'lacking' 'kris' 'crashes' 'pie' 'constantine' 'automotive'\n",
      " 'danish' 'arbor' 'aerospace']\n",
      "VALUE: 0.5555555555555556\n",
      "(17,)\n",
      "['share' 'lacking' 'kris' 'crashes' 'pie' 'constantine' 'automotive'\n",
      " 'danish' 'arbor' 'aerospace']\n",
      "VALUE: 1.1111111111111112\n",
      "(17,)\n",
      "['share' 'lacking' 'kris' 'pie' 'crashes' 'constantine' 'danish' 'arbor'\n",
      " 'automotive' 'aerospace']\n",
      "VALUE: 1.6666666666666667\n",
      "(17,)\n",
      "['share' 'lacking' 'kris' 'pie' 'crashes' 'constantine' 'danish' 'arbor'\n",
      " 'automotive' 'aerospace']\n",
      "VALUE: 2.2222222222222223\n",
      "(17,)\n",
      "['share' 'lacking' 'kris' 'pie' 'danish' 'crashes' 'arbor' 'aerospace'\n",
      " 'constantine' 'automotive']\n",
      "VALUE: 2.7777777777777777\n",
      "(17,)\n",
      "['share' 'lacking' 'kris' 'pie' 'danish' 'crashes' 'arbor' 'aerospace'\n",
      " 'constantine' 'automotive']\n",
      "VALUE: 3.3333333333333335\n",
      "(17,)\n",
      "['share' 'lacking' 'kris' 'pie' 'danish' 'aerospace' 'automotive' 'ibm'\n",
      " 'crashes' 'arbor']\n",
      "VALUE: 3.8888888888888893\n",
      "(17,)\n",
      "['share' 'lacking' 'kris' 'pie' 'danish' 'aerospace' 'automotive' 'ibm'\n",
      " 'crashes' 'arbor']\n",
      "VALUE: 4.444444444444445\n",
      "(17,)\n",
      "['share' 'kris' 'pie' 'danish' 'lacking' 'aerospace' 'automotive' 'hu'\n",
      " 'ibm' 'tim']\n",
      "VALUE: 5.0\n",
      "(17,)\n",
      "['share' 'pie' 'kris' 'danish' 'lacking' 'automotive' 'hu' 'aerospace'\n",
      " 'tim' 'ibm']\n",
      "WORD: internet\n",
      "6647\n",
      "VALUE: 0.0\n",
      "(17,)\n",
      "['share' 'lacking' 'kris' 'crashes' 'pie' 'constantine' 'automotive'\n",
      " 'danish' 'arbor' 'aerospace']\n",
      "VALUE: 0.5555555555555556\n",
      "(17,)\n",
      "['share' 'lacking' 'kris' 'crashes' 'pie' 'constantine' 'automotive'\n",
      " 'danish' 'arbor' 'aerospace']\n",
      "VALUE: 1.1111111111111112\n",
      "(17,)\n",
      "['share' 'lacking' 'kris' 'pie' 'crashes' 'automotive' 'constantine'\n",
      " 'danish' 'aerospace' 'arbor']\n",
      "VALUE: 1.6666666666666667\n",
      "(17,)\n",
      "['share' 'lacking' 'kris' 'pie' 'crashes' 'automotive' 'constantine'\n",
      " 'danish' 'aerospace' 'arbor']\n",
      "VALUE: 2.2222222222222223\n",
      "(17,)\n",
      "['share' 'kris' 'lacking' 'pie' 'automotive' 'danish' 'crashes'\n",
      " 'constantine' 'aerospace' 'arbor']\n",
      "VALUE: 2.7777777777777777\n",
      "(17,)\n",
      "['share' 'kris' 'lacking' 'pie' 'automotive' 'danish' 'crashes'\n",
      " 'constantine' 'aerospace' 'arbor']\n",
      "VALUE: 3.3333333333333335\n",
      "(17,)\n",
      "['share' 'kris' 'pie' 'lacking' 'automotive' 'danish' 'aerospace'\n",
      " 'superior' 'crashes' 'northward']\n",
      "VALUE: 3.8888888888888893\n",
      "(17,)\n",
      "['share' 'kris' 'pie' 'lacking' 'automotive' 'danish' 'aerospace'\n",
      " 'superior' 'crashes' 'northward']\n",
      "VALUE: 4.444444444444445\n",
      "(17,)\n",
      "['share' 'kris' 'pie' 'automotive' 'danish' 'lacking' 'aerospace'\n",
      " 'northward' 'competitive' 'superior']\n",
      "VALUE: 5.0\n",
      "(17,)\n",
      "['kris' 'pie' 'share' 'danish' 'automotive' 'aerospace' 'competitive'\n",
      " 'northward' 'lacking' 'superior']\n",
      "WORD: internet\n",
      "6647\n",
      "VALUE: 0.0\n",
      "(17,)\n",
      "['share' 'lacking' 'kris' 'crashes' 'pie' 'constantine' 'automotive'\n",
      " 'danish' 'arbor' 'aerospace']\n",
      "VALUE: 0.5555555555555556\n",
      "(17,)\n",
      "['share' 'lacking' 'kris' 'crashes' 'pie' 'constantine' 'automotive'\n",
      " 'danish' 'arbor' 'aerospace']\n",
      "VALUE: 1.1111111111111112\n",
      "(17,)\n",
      "['share' 'lacking' 'crashes' 'constantine' 'pie' 'kris' 'automotive'\n",
      " 'aerospace' 'arbor' 'danish']\n",
      "VALUE: 1.6666666666666667\n",
      "(17,)\n",
      "['share' 'lacking' 'crashes' 'constantine' 'pie' 'kris' 'automotive'\n",
      " 'aerospace' 'arbor' 'danish']\n",
      "VALUE: 2.2222222222222223\n",
      "(17,)\n",
      "['share' 'lacking' 'crashes' 'pie' 'constantine' 'kris' 'automotive'\n",
      " 'aerospace' 'jobs' 'danish']\n",
      "VALUE: 2.7777777777777777\n",
      "(17,)\n",
      "['share' 'lacking' 'crashes' 'pie' 'constantine' 'kris' 'automotive'\n",
      " 'aerospace' 'jobs' 'danish']\n",
      "VALUE: 3.3333333333333335\n",
      "(17,)\n",
      "['share' 'pie' 'lacking' 'crashes' 'kris' 'automotive' 'constantine'\n",
      " 'aerospace' 'jobs' 'danish']\n",
      "VALUE: 3.8888888888888893\n",
      "(17,)\n",
      "['share' 'pie' 'lacking' 'crashes' 'kris' 'automotive' 'constantine'\n",
      " 'aerospace' 'jobs' 'danish']\n",
      "VALUE: 4.444444444444445\n",
      "(17,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['share' 'pie' 'automotive' 'kris' 'lacking' 'crashes' 'aerospace' 'jobs'\n",
      " 'danish' 'constantine']\n",
      "VALUE: 5.0\n",
      "(17,)\n",
      "['pie' 'share' 'automotive' 'kris' 'aerospace' 'danish' 'lacking' 'jobs'\n",
      " 'crashes' 'hu']\n",
      "WORD: internet\n",
      "6647\n",
      "VALUE: 0.0\n",
      "(17,)\n",
      "['share' 'lacking' 'kris' 'crashes' 'pie' 'constantine' 'automotive'\n",
      " 'danish' 'arbor' 'aerospace']\n",
      "VALUE: 0.5555555555555556\n",
      "(17,)\n",
      "['share' 'lacking' 'kris' 'crashes' 'pie' 'constantine' 'automotive'\n",
      " 'danish' 'arbor' 'aerospace']\n",
      "VALUE: 1.1111111111111112\n",
      "(17,)\n",
      "['share' 'lacking' 'kris' 'crashes' 'constantine' 'pie' 'automotive'\n",
      " 'aerospace' 'danish' 'arbor']\n",
      "VALUE: 1.6666666666666667\n",
      "(17,)\n",
      "['share' 'lacking' 'kris' 'crashes' 'constantine' 'pie' 'automotive'\n",
      " 'aerospace' 'danish' 'arbor']\n",
      "VALUE: 2.2222222222222223\n",
      "(17,)\n",
      "['share' 'lacking' 'automotive' 'kris' 'constantine' 'crashes' 'pie'\n",
      " 'aerospace' 'ibm' 'arbor']\n",
      "VALUE: 2.7777777777777777\n",
      "(17,)\n",
      "['share' 'lacking' 'automotive' 'kris' 'constantine' 'crashes' 'pie'\n",
      " 'aerospace' 'ibm' 'arbor']\n",
      "VALUE: 3.3333333333333335\n",
      "(17,)\n",
      "['share' 'automotive' 'kris' 'pie' 'lacking' 'constantine' 'aerospace'\n",
      " 'crashes' 'ibm' 'danish']\n",
      "VALUE: 3.8888888888888893\n",
      "(17,)\n",
      "['share' 'automotive' 'kris' 'pie' 'lacking' 'constantine' 'aerospace'\n",
      " 'crashes' 'ibm' 'danish']\n",
      "VALUE: 4.444444444444445\n",
      "(17,)\n",
      "['share' 'automotive' 'pie' 'kris' 'aerospace' 'ibm' 'lacking' 'danish'\n",
      " 'constantine' 'crashes']\n",
      "VALUE: 5.0\n",
      "(17,)\n",
      "['automotive' 'share' 'pie' 'kris' 'aerospace' 'danish' 'ibm' 'lacking'\n",
      " 'semiconductor' 'hu']\n",
      "WORD: internet\n",
      "6647\n",
      "VALUE: 0.0\n",
      "(17,)\n",
      "['share' 'lacking' 'kris' 'crashes' 'pie' 'constantine' 'automotive'\n",
      " 'danish' 'arbor' 'aerospace']\n",
      "VALUE: 0.5555555555555556\n",
      "(17,)\n",
      "['share' 'lacking' 'kris' 'crashes' 'pie' 'constantine' 'automotive'\n",
      " 'danish' 'arbor' 'aerospace']\n",
      "VALUE: 1.1111111111111112\n",
      "(17,)\n",
      "['share' 'lacking' 'kris' 'pie' 'crashes' 'constantine' 'danish' 'arbor'\n",
      " 'automotive' 'aerospace']\n",
      "VALUE: 1.6666666666666667\n",
      "(17,)\n",
      "['share' 'lacking' 'kris' 'pie' 'crashes' 'constantine' 'danish' 'arbor'\n",
      " 'automotive' 'aerospace']\n",
      "VALUE: 2.2222222222222223\n",
      "(17,)\n",
      "['share' 'lacking' 'kris' 'pie' 'danish' 'crashes' 'arbor' 'aerospace'\n",
      " 'constantine' 'automotive']\n",
      "VALUE: 2.7777777777777777\n",
      "(17,)\n",
      "['share' 'lacking' 'kris' 'pie' 'danish' 'crashes' 'arbor' 'aerospace'\n",
      " 'constantine' 'automotive']\n",
      "VALUE: 3.3333333333333335\n",
      "(17,)\n",
      "['share' 'lacking' 'kris' 'pie' 'danish' 'aerospace' 'automotive' 'ibm'\n",
      " 'crashes' 'arbor']\n",
      "VALUE: 3.8888888888888893\n",
      "(17,)\n",
      "['share' 'lacking' 'kris' 'pie' 'danish' 'aerospace' 'automotive' 'ibm'\n",
      " 'crashes' 'arbor']\n",
      "VALUE: 4.444444444444445\n",
      "(17,)\n",
      "['share' 'kris' 'pie' 'danish' 'lacking' 'aerospace' 'automotive' 'hu'\n",
      " 'ibm' 'tim']\n",
      "VALUE: 5.0\n",
      "(17,)\n",
      "['share' 'pie' 'kris' 'danish' 'lacking' 'automotive' 'hu' 'aerospace'\n",
      " 'tim' 'ibm']\n"
     ]
    }
   ],
   "source": [
    "find_top_words(train_glove_embed, train_glove_token, test_glove_embed, test_glove_token, glove_train_entities_cond_matrix_df, \"glove\", \"entity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_closest_word(xhat, train_w2v_embed = train_w2v_embed, train_w2v_token= train_w2v_token, most_similar_n = 1):\n",
    "    \"\"\"Use cosine distance to find the most similar word to the decoder output\"\"\"\n",
    "    # xhat = decoder.predict(sample_word_3)\n",
    "    cos_sim = abs(cosine_similarity(xhat, train_w2v_embed)).flatten() # calculate dist\n",
    "    inx = np.argsort(cos_sim)[::-1][:most_similar_n] # the most similar, index\n",
    "    return train_w2v_token[inx] # most similar word"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
